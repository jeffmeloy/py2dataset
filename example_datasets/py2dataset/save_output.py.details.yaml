file_info:
  file_code: "\"\"\"\nUtility functions for reading the input and saving the output\
    \ of the py2dataset script.\nRequirements:\n[req01] The `read_file` function shall:\n\
    \        a. Accept a file path as an argument.\n        b. Read and return the\
    \ contents of a JSON or YAML file as a dictionary.\n[req02] The `write_file` function\
    \ shall:\n        a. Accept a dictionary and a file path as arguments.\n     \
    \   b. Write the dictionary to a file in either JSON or YAML format.\n[req03]\
    \ The `convert_json_to_html` function shall:\n        a. Convert JSON files within\
    \ a given directory to HTML format.\n        b. Save each converted file with\
    \ a .html extension.\n        c. Preserve spacing and tabs for the 'input' field.\n\
    [req04] The `combine_json_files` function shall:\n        a. Accept a directory\
    \ path as an argument.\n        b. Merge all JSON files in the directory.\n  \
    \      c. Remove duplicates from the combined JSON files.\n        d. Write the\
    \ combined data to 'instruct.json' files.\n        e. Convert the merged JSON\
    \ files to HTML format.\n        f. Return the 'instruct_list' datasets.\n[req05]\
    \ The `create_code_graph` function shall:\n        a. Accept details of a Python\
    \ file, a base name, and an output directory as arguments.\n        b. Generate\
    \ code graphs based on the provided file details.\n        c. Save the graphs\
    \ as PNG images in the specified output directory.\n[req06] The `save_python_data`\
    \ function shall:\n        a. Accept details of a Python file, a base name, and\
    \ an output directory as arguments.\n        b. Save the details of the Python\
    \ file as a YAML file.\n        c. Save the instruction data as JSON files.\n\
    \        d. Generate and save code graphs.\n\"\"\"\nimport json\nimport logging\n\
    from html import escape\nfrom pathlib import Path\nfrom typing import Dict, List\n\
    import matplotlib.pyplot as plt\nimport networkx as nx\nimport yaml\n\n\ndef read_file(file_path:\
    \ Path) -> Dict:\n    \"\"\"\n    Reads a JSON or YAML file and returns its contents\
    \ as a dictionary.\n    Args:\n        file_path (Path): The path to the file.\n\
    \    Returns:\n        The contents of the file as a dictionary.\n    \"\"\"\n\
    \    file_type = file_path.suffix[1:]\n    with file_path.open() as f:\n     \
    \   if file_type == \"json\":\n            return json.load(f)\n        if file_type\
    \ == \"yaml\":\n            return yaml.load(f, Loader=yaml.SafeLoader)\n    \
    \    return {}\n\n\ndef write_file(data: Dict, file_path: Path) -> None:\n   \
    \ \"\"\"\n    Writes a dictionary to a JSON or YAML file.\n    Args:\n       \
    \ data (Dict): The data to write to the file.\n        file_path (Path): The path\
    \ to the file.\n    Returns:\n        None\n    \"\"\"\n    file_type = file_path.suffix[1:]\n\
    \    with file_path.open(\"w\") as f:\n        if file_type == \"json\":\n   \
    \         json.dump(data, f, indent=4)\n        elif file_type == \"yaml\":\n\
    \            yaml.SafeDumper.ignore_aliases = lambda *args: True\n           \
    \ yaml.dump(data, f, Dumper=yaml.SafeDumper, sort_keys=False)\n\n\ndef convert_json_to_html(directory:\
    \ str) -> None:\n    \"\"\"\n    Convert JSON files within a given directory to\
    \ HTML format and save .html file.\n    Args:\n        directory (str): The directory\
    \ where the JSON files are located.\n    Returns:\n        None\n    \"\"\"\n\n\
    \    def preserve_spacing(text: str, tab_width: int = 4) -> str:\n        \"\"\
    \"Preserve spaces and tabs in the provided text.\"\"\"\n        return text.replace(\"\
    \ \", \"&nbsp;\").replace(\"\\t\", \"&nbsp;\" * tab_width)\n\n    for json_file\
    \ in Path(directory).rglob(\"*.json\"):\n        try:\n            dataset = read_file(json_file)\n\
    \            if not dataset:\n                continue\n        except Exception:\n\
    \            continue\n\n        html_content = \"\"\"\n        <html>\n     \
    \   <head>\n            <style>\n                table {border-collapse: collapse;\
    \ width: 100%; table-layout: fixed;}\n                th, td {\n             \
    \       border: 1px solid black;\n                    padding: 8px;\n        \
    \            text-align: left;\n                    white-space: pre-line;\n \
    \                   vertical-align: top;\n                    word-wrap: break-word;\n\
    \                }\n            </style>\n        </head>\n        <body>\n  \
    \          <table>\n                <thead>\n                    <tr>\n      \
    \  \"\"\"\n        column_count = len(dataset[0].keys())\n        column_width\
    \ = round(100 / column_count, 2)\n        for key in dataset[0].keys():\n    \
    \        html_content += f\"<th style='width: {column_width}%;'>{key}</th>\"\n\
    \        html_content += \"\"\"\n                    </tr>\n                </thead>\n\
    \                <tbody>\n        \"\"\"\n        html_rows = []\n        for\
    \ entry in dataset:\n            row_parts = [\"<tr>\"]\n            for key in\
    \ entry:\n                value = escape(str(entry[key]))\n                value\
    \ = preserve_spacing(value)\n                value = value.replace(\"\\n\", \"\
    <br/>\")\n                row_parts.append(f\"<td>{value}</td>\")\n          \
    \  row_parts.append(\"</tr>\")\n            html_rows.append(\"\".join(row_parts))\n\
    \        html_content += \"\".join(html_rows)\n\n        html_content += \"\"\"\
    \n                </tbody>\n            </table>\n        </body>\n        </html>\n\
    \        \"\"\"\n        html_file_path = json_file.with_suffix(\".html\")\n \
    \       try:\n            with open(html_file_path, \"w\", encoding=\"utf-8\"\
    ) as file:\n                file.write(html_content)\n        except Exception:\n\
    \            logging.info(f\"Failed saving: {html_file_path}\")\n\n\ndef combine_json_files(\n\
    \    directory: str, html: bool, questions: Dict\n) -> Dict[str, List[Dict]]:\n\
    \    \"\"\"\n    Combine all JSON files in the output directory into 'instruct.json',\
    \ and\n    then remove duplicates. Also generate a 'training.json' file.\n   \
    \ Args:\n        directory (str): The directory where the output files are located.\n\
    \    Returns:\n        A dictionary containing the 'instruct_list' datasets.\n\
    \    \"\"\"\n    logging.info(f\"Combining JSON files in {directory}\")\n\n  \
    \  # Save instruct.json file\n    combined_data, code_filename = [], []\n    skip_files\
    \ = {\"instruct.json\", \"chat_ml.json\", \"document_code.json\"}\n    for json_file\
    \ in Path(directory).rglob(\"*.json\"):\n        if json_file.name in skip_files:\n\
    \            continue\n        try:\n            file_data = read_file(json_file)\n\
    \            if file_data:\n                combined_data.extend(file_data)\n\
    \                cleaned_name = (\n                    json_file.relative_to(directory)\n\
    \                    .with_suffix(\"\")\n                    .as_posix()\n   \
    \                 .replace(\".instruct\", \"\")\n                )\n         \
    \       code_filename.append(cleaned_name)\n        except Exception as e:\n \
    \           logging.info(f\"Failed reading: {json_file}. Error: {e}\")\n    write_file(combined_data,\
    \ Path(directory) / \"instruct.json\")\n\n    # Generate document_code.json file\n\
    \    purpose_question = [\n        item[\"text\"] for item in questions if item[\"\
    id\"] == \"file_purpose\"\n    ][0]\n    purpose_question = purpose_question.split(\"\
    {filename}\")[0]\n    purpose_data = [\n        item\n        for item in combined_data\n\
    \        if item[\"instruction\"].startswith(purpose_question)\n    ]\n\n    document_code\
    \ = [\n        {\n            \"document\": item[\"output\"],\n            \"\
    code\": item[\"input\"],\n        }\n        for item in purpose_data\n    ]\n\
    \    for i, item in enumerate(document_code):\n        item[\"code filename\"\
    ] = code_filename[i]\n\n    write_file(document_code, Path(directory) / \"document_code.json\"\
    )\n\n    chat_ml = [\n        {\n            \"conversation\": [\n           \
    \     {\"from\": \"system\", \"value\": f\"code documentation: {item['document']}\"\
    },\n                {\n                    \"from\": \"human\",\n            \
    \        \"value\": \"Output the Python code described by the code documentation.\"\
    ,\n                },\n                {\"from\": \"gpt\", \"value\": item[\"\
    code\"]},\n            ],\n            \"nbytes\": \"0\",\n            \"source\"\
    : item[\"code filename\"],\n        }\n        for item in document_code\n   \
    \ ]\n\n    # Compute the number of bytes for each conversation and update the\
    \ nbytes field\n    for item in chat_ml:\n        nbytes = 0\n        for conv\
    \ in item[\"conversation\"]:\n            nbytes += len(conv[\"value\"].encode(\"\
    utf-8\"))\n        item[\"nbytes\"] = nbytes\n\n    write_file(chat_ml, Path(directory)\
    \ / \"chat_ml.json\")\n\n    if html:\n        logging.info(\"Converting JSON\
    \ files to HTML\")\n        convert_json_to_html(directory)\n\n    return {\"\
    instruct_list\": combined_data}\n\n\ndef create_code_graph(file_details: Dict,\
    \ base_name: str, output_subdir: Path) -> None:\n    \"\"\"\n    Generate graphs\
    \ from the file_details and save them as PNG images.\n    Args:\n        file_details\
    \ (dict): The details extracted from the Python file.\n        base_name (str):\
    \ The base name of the output files.\n        output_subdir (Path): The subdirectory\
    \ where the output files will be saved.\n    Returns:\n        None\n    \"\"\"\
    \n    # create graph\n    graph_type = \"entire_code_graph\"\n    G = nx.DiGraph()\n\
    \    G.add_nodes_from(file_details[\"file_info\"][graph_type][\"nodes\"])\n  \
    \  for edge in file_details[\"file_info\"][graph_type][\"edges\"]:\n        source,\
    \ target = edge[\"source\"], edge[\"target\"]\n        if source in G.nodes and\
    \ target in G.nodes:\n            G.add_edge(\n                source,\n     \
    \           target,\n                **{\n                    k: v\n         \
    \           for k, v in edge.items()\n                    if k in [\"target_inputs\"\
    , \"target_returns\"]\n                },\n            )\n\n    # draw graph\n\
    \    plt.figure(figsize=(20, 20))\n    pos = nx.spring_layout(G)\n    nx.draw(\n\
    \        G,\n        pos,\n        with_labels=True,\n        font_weight=\"bold\"\
    ,\n        font_size=8,\n        node_shape=\"s\",\n        node_size=500,\n \
    \       width=1,\n        arrowsize=12,\n    )\n    edge_labels = {}\n    for\
    \ edge in G.edges(data=True):\n        label = []\n        if \"target_inputs\"\
    \ in edge[2] and edge[2][\"target_inputs\"]:\n            label.append(f\"Inputs:\
    \ {', '.join(edge[2]['target_inputs'])}\")\n        if \"target_returns\" in edge[2]\
    \ and edge[2][\"target_returns\"]:\n            label.append(f\"\\nReturns: {',\
    \ '.join(edge[2]['target_returns'])}\")\n        edge_labels[(edge[0], edge[1])]\
    \ = \"\\n\".join(label)\n    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels,\
    \ font_size=6)\n\n    # save graph\n    output_file = output_subdir / f\"{base_name}.{graph_type}.png\"\
    \n    plt.savefig(output_file)\n    plt.close()\n\n\ndef save_python_data(\n \
    \   file_details: dict, instruct_list: list, relative_path: Path, output_dir:\
    \ str\n) -> None:\n    \"\"\"\n    Save the details of the Python file as a YAML\
    \ file, the instruction data as JSON files,\n    and generate and save code graphs.\n\
    \    Args:\n        file_details (dict): The details extracted from the Python\
    \ file.\n        instruct_list (list): The instruction data extracted from the\
    \ Python file.\n        relative_path (Path): The relative path of the Python\
    \ file.\n        output_dir (str): The directory where the output files will be\
    \ saved.\n    Returns:\n        None\n    \"\"\"\n    output_subdir = Path(output_dir)\
    \ / relative_path.parent\n    output_subdir.mkdir(parents=True, exist_ok=True)\n\
    \    base_name = relative_path.name\n    write_file(instruct_list, output_subdir\
    \ / f\"{base_name}.instruct.json\")\n    write_file(file_details, output_subdir\
    \ / f\"{base_name}.details.yaml\")\n\n    # Generating and saving the code graph\n\
    \    try:\n        create_code_graph(file_details, base_name, output_subdir)\n\
    \    except Exception as e:\n        logging.error(f\"Error creating graph for\
    \ {base_name}: {e}\", exc_info=True)\n"
  file_dependencies:
  - yaml
  - networkx
  - logging
  - html
  - json
  - typing
  - matplotlib.pyplot
  - pathlib
  file_functions:
  - read_file
  - write_file
  - convert_json_to_html
  - preserve_spacing
  - combine_json_files
  - create_code_graph
  - save_python_data
  file_classes: []
  file_constants: []
  file_summary: '{dependencies: [yaml, networkx, logging, html, json, typing, matplotlib.pyplot,
    pathlib], function_defs: [{read_file: {inputs: [file_path], calls: [file_path.open,
    json.load, yaml.load], call_inputs: {file_path.open: [], json.load: [f], yaml.load:
    [f]}, returns: [{}, json.load(f), yaml.load(f, Loader=yaml.SafeLoader)]}}, {write_file:
    {inputs: [data, file_path], calls: [file_path.open, json.dump, yaml.dump], call_inputs:
    {file_path.open: [''w''], json.dump: [data, f], yaml.dump: [data, f]}, returns:
    []}}, {convert_json_to_html: {inputs: [directory], calls: [text.replace('' '',
    ''&nbsp;'').replace, text.replace, Path(directory).rglob, Path, read_file, len,
    dataset[0].keys, round, escape, str, preserve_spacing, value.replace, row_parts.append,
    html_rows.append, ''''.join, json_file.with_suffix, open, file.write, logging.info],
    call_inputs: {text.replace('' '', ''&nbsp;'').replace: [''\\t'', ''&nbsp;'' *
    tab_width], text.replace: ['' '', ''&nbsp;''], Path(directory).rglob: [''*.json''],
    Path: [directory], read_file: [json_file], len: [dataset[0].keys()], dataset[0].keys:
    [], round: [100 / column_count, 2], escape: [str(entry[key])], str: [entry[key]],
    preserve_spacing: [value], value.replace: [''\\n'', ''<br/>''], row_parts.append:
    [f''<td>{value}</td>'', ''</tr>''], html_rows.append: [''''.join(row_parts)],
    ''''.join: [row_parts, html_rows], json_file.with_suffix: [''.html''], open: [html_file_path,
    ''w''], file.write: [html_content], logging.info: [f''Failed saving: {html_file_path}'']},
    returns: [text.replace('' '', ''&nbsp;'').replace(''\\t'', ''&nbsp;'' * tab_width)]}},
    {preserve_spacing: {inputs: [text, tab_width], calls: [text.replace('' '', ''&nbsp;'').replace,
    text.replace], call_inputs: {text.replace('' '', ''&nbsp;'').replace: [''\\t'',
    ''&nbsp;'' * tab_width], text.replace: ['' '', ''&nbsp;'']}, returns: [text.replace(''
    '', ''&nbsp;'').replace(''\\t'', ''&nbsp;'' * tab_width)]}}, {combine_json_files:
    {inputs: [directory, html, questions], calls: [logging.info, Path(directory).rglob,
    Path, read_file, combined_data.extend, json_file.relative_to(directory).with_suffix('''').as_posix().replace,
    json_file.relative_to(directory).with_suffix('''').as_posix, json_file.relative_to(directory).with_suffix,
    json_file.relative_to, code_filename.append, write_file, purpose_question.split,
    item[''instruction''].startswith, enumerate, len, conv[''value''].encode, convert_json_to_html],
    call_inputs: {logging.info: [f''Combining JSON files in {directory}'', f''Failed
    reading: {json_file}. Error: {e}'', ''Converting JSON files to HTML''], Path(directory).rglob:
    [''*.json''], Path: [directory, directory, directory, directory], read_file: [json_file],
    combined_data.extend: [file_data], json_file.relative_to(directory).with_suffix('''').as_posix().replace:
    [''.instruct'', ''''], json_file.relative_to(directory).with_suffix('''').as_posix:
    [], json_file.relative_to(directory).with_suffix: [''''], json_file.relative_to:
    [directory], code_filename.append: [cleaned_name], write_file: [combined_data,
    Path(directory) / ''instruct.json'', document_code, Path(directory) / ''document_code.json'',
    chat_ml, Path(directory) / ''chat_ml.json''], purpose_question.split: [''{filename}''],
    item[''instruction''].startswith: [purpose_question], enumerate: [document_code],
    len: [conv[''value''].encode(''utf-8'')], conv[''value''].encode: [''utf-8''],
    convert_json_to_html: [directory]}, returns: [{''instruct_list'': combined_data}]}},
    {create_code_graph: {inputs: [file_details, base_name, output_subdir], calls:
    [nx.DiGraph, G.add_nodes_from, G.add_edge, edge.items, plt.figure, nx.spring_layout,
    nx.draw, G.edges, label.append, '', ''.join, ''\\n''.join, nx.draw_networkx_edge_labels,
    plt.savefig, plt.close], call_inputs: {nx.DiGraph: [], G.add_nodes_from: [file_details[''file_info''][graph_type][''nodes'']],
    G.add_edge: [source, target], edge.items: [], plt.figure: [], nx.spring_layout:
    [G], nx.draw: [G, pos], G.edges: [], label.append: [f\Inputs: {'', ''.join(edge[2][''target_inputs''])}\,
    f\\\nReturns: {'', ''.join(edge[2][''target_returns''])}\], '', ''.join: [edge[2][''target_inputs''],
    edge[2][''target_returns'']], ''\\n''.join: [label], nx.draw_networkx_edge_labels:
    [G, pos], plt.savefig: [output_file], plt.close: []}, returns: []}}, {save_python_data:
    {inputs: [file_details, instruct_list, relative_path, output_dir], calls: [Path,
    output_subdir.mkdir, write_file, create_code_graph, logging.error], call_inputs:
    {Path: [output_dir], output_subdir.mkdir: [], write_file: [instruct_list, output_subdir
    / f''{base_name}.instruct.json'', file_details, output_subdir / f''{base_name}.details.yaml''],
    create_code_graph: [file_details, base_name, output_subdir], logging.error: [f''Error
    creating graph for {base_name}: {e}'']}, returns: []}}], class_defs: []}'
  file_code_simplified: "import json\nimport logging\nfrom html import escape\nfrom\
    \ pathlib import Path\nfrom typing import Dict, List\nimport matplotlib.pyplot\
    \ as plt\nimport networkx as nx\nimport yaml\n\ndef read_file(file_path: Path)\
    \ -> Dict:\n    file_type = file_path.suffix[1:]\n    with file_path.open() as\
    \ f:\n        if file_type == 'json':\n            return json.load(f)\n     \
    \   if file_type == 'yaml':\n            return yaml.load(f, Loader=yaml.SafeLoader)\n\
    \        return {}\n\ndef write_file(data: Dict, file_path: Path) -> None:\n \
    \   file_type = file_path.suffix[1:]\n    with file_path.open('w') as f:\n   \
    \     if file_type == 'json':\n            json.dump(data, f, indent=4)\n    \
    \    elif file_type == 'yaml':\n            yaml.SafeDumper.ignore_aliases = lambda\
    \ *args: True\n            yaml.dump(data, f, Dumper=yaml.SafeDumper, sort_keys=False)\n\
    \ndef convert_json_to_html(directory: str) -> None:\n\n    def preserve_spacing(text:\
    \ str, tab_width: int=4) -> str:\n        return text.replace(' ', '&nbsp;').replace('\\\
    t', '&nbsp;' * tab_width)\n    for json_file in Path(directory).rglob('*.json'):\n\
    \        try:\n            dataset = read_file(json_file)\n            if not\
    \ dataset:\n                continue\n        except Exception:\n            continue\n\
    \        html_content = '\\n        <html>\\n        <head>\\n            <style>\\\
    n                table {border-collapse: collapse; width: 100%; table-layout:\
    \ fixed;}\\n                th, td {\\n                    border: 1px solid black;\\\
    n                    padding: 8px;\\n                    text-align: left;\\n\
    \                    white-space: pre-line;\\n                    vertical-align:\
    \ top;\\n                    word-wrap: break-word;\\n                }\\n   \
    \         </style>\\n        </head>\\n        <body>\\n            <table>\\\
    n                <thead>\\n                    <tr>\\n        '\n        column_count\
    \ = len(dataset[0].keys())\n        column_width = round(100 / column_count, 2)\n\
    \        for key in dataset[0].keys():\n            html_content += f\"<th style='width:\
    \ {column_width}%;'>{key}</th>\"\n        html_content += '\\n               \
    \     </tr>\\n                </thead>\\n                <tbody>\\n        '\n\
    \        html_rows = []\n        for entry in dataset:\n            row_parts\
    \ = ['<tr>']\n            for key in entry:\n                value = escape(str(entry[key]))\n\
    \                value = preserve_spacing(value)\n                value = value.replace('\\\
    n', '<br/>')\n                row_parts.append(f'<td>{value}</td>')\n        \
    \    row_parts.append('</tr>')\n            html_rows.append(''.join(row_parts))\n\
    \        html_content += ''.join(html_rows)\n        html_content += '\\n    \
    \            </tbody>\\n            </table>\\n        </body>\\n        </html>\\\
    n        '\n        html_file_path = json_file.with_suffix('.html')\n        try:\n\
    \            with open(html_file_path, 'w', encoding='utf-8') as file:\n     \
    \           file.write(html_content)\n        except Exception:\n            logging.info(f'Failed\
    \ saving: {html_file_path}')\n\ndef combine_json_files(directory: str, html: bool,\
    \ questions: Dict) -> Dict[str, List[Dict]]:\n    logging.info(f'Combining JSON\
    \ files in {directory}')\n    combined_data, code_filename = ([], [])\n    skip_files\
    \ = {'instruct.json', 'chat_ml.json', 'document_code.json'}\n    for json_file\
    \ in Path(directory).rglob('*.json'):\n        if json_file.name in skip_files:\n\
    \            continue\n        try:\n            file_data = read_file(json_file)\n\
    \            if file_data:\n                combined_data.extend(file_data)\n\
    \                cleaned_name = json_file.relative_to(directory).with_suffix('').as_posix().replace('.instruct',\
    \ '')\n                code_filename.append(cleaned_name)\n        except Exception\
    \ as e:\n            logging.info(f'Failed reading: {json_file}. Error: {e}')\n\
    \    write_file(combined_data, Path(directory) / 'instruct.json')\n    purpose_question\
    \ = [item['text'] for item in questions if item['id'] == 'file_purpose'][0]\n\
    \    purpose_question = purpose_question.split('{filename}')[0]\n    purpose_data\
    \ = [item for item in combined_data if item['instruction'].startswith(purpose_question)]\n\
    \    document_code = [{'document': item['output'], 'code': item['input']} for\
    \ item in purpose_data]\n    for i, item in enumerate(document_code):\n      \
    \  item['code filename'] = code_filename[i]\n    write_file(document_code, Path(directory)\
    \ / 'document_code.json')\n    chat_ml = [{'conversation': [{'from': 'system',\
    \ 'value': f\"code documentation: {item['document']}\"}, {'from': 'human', 'value':\
    \ 'Output the Python code described by the code documentation.'}, {'from': 'gpt',\
    \ 'value': item['code']}], 'nbytes': '0', 'source': item['code filename']} for\
    \ item in document_code]\n    for item in chat_ml:\n        nbytes = 0\n     \
    \   for conv in item['conversation']:\n            nbytes += len(conv['value'].encode('utf-8'))\n\
    \        item['nbytes'] = nbytes\n    write_file(chat_ml, Path(directory) / 'chat_ml.json')\n\
    \    if html:\n        logging.info('Converting JSON files to HTML')\n       \
    \ convert_json_to_html(directory)\n    return {'instruct_list': combined_data}\n\
    \ndef create_code_graph(file_details: Dict, base_name: str, output_subdir: Path)\
    \ -> None:\n    graph_type = 'entire_code_graph'\n    G = nx.DiGraph()\n    G.add_nodes_from(file_details['file_info'][graph_type]['nodes'])\n\
    \    for edge in file_details['file_info'][graph_type]['edges']:\n        source,\
    \ target = (edge['source'], edge['target'])\n        if source in G.nodes and\
    \ target in G.nodes:\n            G.add_edge(source, target, **{k: v for k, v\
    \ in edge.items() if k in ['target_inputs', 'target_returns']})\n    plt.figure(figsize=(20,\
    \ 20))\n    pos = nx.spring_layout(G)\n    nx.draw(G, pos, with_labels=True, font_weight='bold',\
    \ font_size=8, node_shape='s', node_size=500, width=1, arrowsize=12)\n    edge_labels\
    \ = {}\n    for edge in G.edges(data=True):\n        label = []\n        if 'target_inputs'\
    \ in edge[2] and edge[2]['target_inputs']:\n            label.append(f\"Inputs:\
    \ {', '.join(edge[2]['target_inputs'])}\")\n        if 'target_returns' in edge[2]\
    \ and edge[2]['target_returns']:\n            label.append(f\"\\nReturns: {',\
    \ '.join(edge[2]['target_returns'])}\")\n        edge_labels[edge[0], edge[1]]\
    \ = '\\n'.join(label)\n    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels,\
    \ font_size=6)\n    output_file = output_subdir / f'{base_name}.{graph_type}.png'\n\
    \    plt.savefig(output_file)\n    plt.close()\n\ndef save_python_data(file_details:\
    \ dict, instruct_list: list, relative_path: Path, output_dir: str) -> None:\n\
    \    output_subdir = Path(output_dir) / relative_path.parent\n    output_subdir.mkdir(parents=True,\
    \ exist_ok=True)\n    base_name = relative_path.name\n    write_file(instruct_list,\
    \ output_subdir / f'{base_name}.instruct.json')\n    write_file(file_details,\
    \ output_subdir / f'{base_name}.details.yaml')\n    try:\n        create_code_graph(file_details,\
    \ base_name, output_subdir)\n    except Exception as e:\n        logging.error(f'Error\
    \ creating graph for {base_name}: {e}', exc_info=True)"
  entire_code_graph:
    nodes:
    - read_file
    - write_file
    - convert_json_to_html
    - preserve_spacing
    - combine_json_files
    - create_code_graph
    - save_python_data
    - file_path.open
    - json.load
    - yaml.load
    - json.dump
    - yaml.dump
    - text.replace(' ', '&nbsp;').replace
    - text.replace
    - Path(directory).rglob
    - Path
    - len
    - dataset[0].keys
    - round
    - escape
    - str
    - value.replace
    - row_parts.append
    - html_rows.append
    - '''''.join'
    - json_file.with_suffix
    - open
    - file.write
    - logging.info
    - combined_data.extend
    - json_file.relative_to(directory).with_suffix('').as_posix().replace
    - json_file.relative_to(directory).with_suffix('').as_posix
    - json_file.relative_to(directory).with_suffix
    - json_file.relative_to
    - code_filename.append
    - purpose_question.split
    - item['instruction'].startswith
    - enumerate
    - conv['value'].encode
    - nx.DiGraph
    - G.add_nodes_from
    - G.add_edge
    - edge.items
    - plt.figure
    - nx.spring_layout
    - nx.draw
    - G.edges
    - label.append
    - ''', ''.join'
    - '''\n''.join'
    - nx.draw_networkx_edge_labels
    - plt.savefig
    - plt.close
    - output_subdir.mkdir
    - logging.error
    edges:
    - source: read_file
      target: file_path.open
      target_inputs: []
    - source: read_file
      target: json.load
      target_inputs:
      - f
    - source: read_file
      target: yaml.load
      target_inputs:
      - f
    - source: write_file
      target: file_path.open
      target_inputs:
      - '''w'''
    - source: write_file
      target: json.dump
      target_inputs:
      - data
      - f
    - source: write_file
      target: yaml.dump
      target_inputs:
      - data
      - f
    - source: convert_json_to_html
      target: text.replace(' ', '&nbsp;').replace
      target_inputs:
      - '''\t'''
      - '''&nbsp;'' * tab_width'
    - source: convert_json_to_html
      target: text.replace
      target_inputs:
      - ''' '''
      - '''&nbsp;'''
    - source: convert_json_to_html
      target: Path(directory).rglob
      target_inputs:
      - '''*.json'''
    - source: convert_json_to_html
      target: Path
      target_inputs:
      - directory
    - source: convert_json_to_html
      target: read_file
      target_inputs:
      - json_file
      target_returns:
      - '{}'
      - yaml.load(f, Loader=yaml.SafeLoader)
      - json.load(f)
    - source: convert_json_to_html
      target: len
      target_inputs:
      - dataset[0].keys()
    - source: convert_json_to_html
      target: dataset[0].keys
      target_inputs: []
    - source: convert_json_to_html
      target: round
      target_inputs:
      - 100 / column_count
      - '2'
    - source: convert_json_to_html
      target: escape
      target_inputs:
      - str(entry[key])
    - source: convert_json_to_html
      target: str
      target_inputs:
      - entry[key]
    - source: convert_json_to_html
      target: preserve_spacing
      target_inputs:
      - value
      target_returns:
      - text.replace(' ', '&nbsp;').replace('\t', '&nbsp;' * tab_width)
    - source: convert_json_to_html
      target: value.replace
      target_inputs:
      - '''\n'''
      - '''<br/>'''
    - source: convert_json_to_html
      target: row_parts.append
      target_inputs:
      - f'<td>{value}</td>'
      - '''</tr>'''
    - source: convert_json_to_html
      target: html_rows.append
      target_inputs:
      - '''''.join(row_parts)'
    - source: convert_json_to_html
      target: '''''.join'
      target_inputs:
      - row_parts
      - html_rows
    - source: convert_json_to_html
      target: json_file.with_suffix
      target_inputs:
      - '''.html'''
    - source: convert_json_to_html
      target: open
      target_inputs:
      - html_file_path
      - '''w'''
    - source: convert_json_to_html
      target: file.write
      target_inputs:
      - html_content
    - source: convert_json_to_html
      target: logging.info
      target_inputs:
      - 'f''Failed saving: {html_file_path}'''
    - source: preserve_spacing
      target: text.replace(' ', '&nbsp;').replace
      target_inputs:
      - '''\t'''
      - '''&nbsp;'' * tab_width'
    - source: preserve_spacing
      target: text.replace
      target_inputs:
      - ''' '''
      - '''&nbsp;'''
    - source: combine_json_files
      target: logging.info
      target_inputs:
      - f'Combining JSON files in {directory}'
      - 'f''Failed reading: {json_file}. Error: {e}'''
      - '''Converting JSON files to HTML'''
    - source: combine_json_files
      target: Path(directory).rglob
      target_inputs:
      - '''*.json'''
    - source: combine_json_files
      target: Path
      target_inputs:
      - directory
      - directory
      - directory
      - directory
    - source: combine_json_files
      target: read_file
      target_inputs:
      - json_file
      target_returns:
      - '{}'
      - yaml.load(f, Loader=yaml.SafeLoader)
      - json.load(f)
    - source: combine_json_files
      target: combined_data.extend
      target_inputs:
      - file_data
    - source: combine_json_files
      target: json_file.relative_to(directory).with_suffix('').as_posix().replace
      target_inputs:
      - '''.instruct'''
      - ''''''
    - source: combine_json_files
      target: json_file.relative_to(directory).with_suffix('').as_posix
      target_inputs: []
    - source: combine_json_files
      target: json_file.relative_to(directory).with_suffix
      target_inputs:
      - ''''''
    - source: combine_json_files
      target: json_file.relative_to
      target_inputs:
      - directory
    - source: combine_json_files
      target: code_filename.append
      target_inputs:
      - cleaned_name
    - source: combine_json_files
      target: write_file
      target_inputs:
      - combined_data
      - Path(directory) / 'instruct.json'
      - document_code
      - Path(directory) / 'document_code.json'
      - chat_ml
      - Path(directory) / 'chat_ml.json'
      target_returns: []
    - source: combine_json_files
      target: purpose_question.split
      target_inputs:
      - '''{filename}'''
    - source: combine_json_files
      target: item['instruction'].startswith
      target_inputs:
      - purpose_question
    - source: combine_json_files
      target: enumerate
      target_inputs:
      - document_code
    - source: combine_json_files
      target: len
      target_inputs:
      - conv['value'].encode('utf-8')
    - source: combine_json_files
      target: conv['value'].encode
      target_inputs:
      - '''utf-8'''
    - source: combine_json_files
      target: convert_json_to_html
      target_inputs:
      - directory
      target_returns:
      - text.replace(' ', '&nbsp;').replace('\t', '&nbsp;' * tab_width)
    - source: create_code_graph
      target: nx.DiGraph
      target_inputs: []
    - source: create_code_graph
      target: G.add_nodes_from
      target_inputs:
      - file_details['file_info'][graph_type]['nodes']
    - source: create_code_graph
      target: G.add_edge
      target_inputs:
      - source
      - target
    - source: create_code_graph
      target: edge.items
      target_inputs: []
    - source: create_code_graph
      target: plt.figure
      target_inputs: []
    - source: create_code_graph
      target: nx.spring_layout
      target_inputs:
      - G
    - source: create_code_graph
      target: nx.draw
      target_inputs:
      - G
      - pos
    - source: create_code_graph
      target: G.edges
      target_inputs: []
    - source: create_code_graph
      target: label.append
      target_inputs:
      - 'f"Inputs: {'', ''.join(edge[2][''target_inputs''])}"'
      - 'f"\nReturns: {'', ''.join(edge[2][''target_returns''])}"'
    - source: create_code_graph
      target: ''', ''.join'
      target_inputs:
      - edge[2]['target_inputs']
      - edge[2]['target_returns']
    - source: create_code_graph
      target: '''\n''.join'
      target_inputs:
      - label
    - source: create_code_graph
      target: nx.draw_networkx_edge_labels
      target_inputs:
      - G
      - pos
    - source: create_code_graph
      target: plt.savefig
      target_inputs:
      - output_file
    - source: create_code_graph
      target: plt.close
      target_inputs: []
    - source: save_python_data
      target: Path
      target_inputs:
      - output_dir
    - source: save_python_data
      target: output_subdir.mkdir
      target_inputs: []
    - source: save_python_data
      target: write_file
      target_inputs:
      - instruct_list
      - output_subdir / f'{base_name}.instruct.json'
      - file_details
      - output_subdir / f'{base_name}.details.yaml'
      target_returns: []
    - source: save_python_data
      target: create_code_graph
      target_inputs:
      - file_details
      - base_name
      - output_subdir
      target_returns: []
    - source: save_python_data
      target: logging.error
      target_inputs:
      - 'f''Error creating graph for {base_name}: {e}'''
  control_flow_structure:
  - 'def combine_json_files(directory: str, html: bool, questions: Dict)':
    - logging.info(f'Combining JSON files in {directory}')
    - combined_data, code_filename = ([], [])
    - skip_files = {'instruct.json', 'chat_ml.json', 'document_code.json'}
    - for json_file in Path(directory).rglob('*.json'):
      - if json_file.name in skip_files:
        - continue
      - try:
        - file_data = read_file(json_file)
        - if file_data:
          - combined_data.extend(file_data)
          - cleaned_name = json_file.relative_to(directory).with_suffix('').as_posix().replace('.instruct',
            '')
          - code_filename.append(cleaned_name)
        except:
        - 'except Exception as :':
          - 'logging.info(f''Failed reading: {json_file}. Error: {e}'')'
    - write_file(combined_data, Path(directory) / 'instruct.json')
    - purpose_question = [item['text'] for item in questions if item['id'] == 'file_purpose'][0]
    - purpose_question = purpose_question.split('{filename}')[0]
    - purpose_data = [item for item in combined_data if item['instruction'].startswith(purpose_question)]
    - 'document_code = [{''document'': item[''output''], ''code'': item[''input'']}
      for item in purpose_data]'
    - for (i, item) in enumerate(document_code):
      - item['code filename'] = code_filename[i]
    - write_file(document_code, Path(directory) / 'document_code.json')
    - 'chat_ml = [{''conversation'': [{''from'': ''system'', ''value'': f"code documentation:
      {item[''document'']}"}, {''from'': ''human'', ''value'': ''Output the Python
      code described by the code documentation.''}, {''from'': ''gpt'', ''value'':
      item[''code'']}], ''nbytes'': ''0'', ''source'': item[''code filename'']} for
      item in document_code]'
    - for item in chat_ml:
      - nbytes = 0
      - for conv in item['conversation']:
        - nbytes += len(conv['value'].encode('utf-8'))
      - item['nbytes'] = nbytes
    - write_file(chat_ml, Path(directory) / 'chat_ml.json')
    - if html:
      - logging.info('Converting JSON files to HTML')
      - convert_json_to_html(directory)
    - return:
      - '{''instruct_list'': combined_data}'
  - 'def save_python_data(file_details: dict, instruct_list: list, relative_path: Path, output_dir: str)':
    - output_subdir = Path(output_dir) / relative_path.parent
    - output_subdir.mkdir(parents=True, exist_ok=True)
    - base_name = relative_path.name
    - write_file(instruct_list, output_subdir / f'{base_name}.instruct.json')
    - write_file(file_details, output_subdir / f'{base_name}.details.yaml')
    - try:
      - create_code_graph(file_details, base_name, output_subdir)
      except:
      - 'except Exception as :':
        - 'logging.error(f''Error creating graph for {base_name}: {e}'', exc_info=True)'
  - import json
  - import logging
  - from html import escape
  - from pathlib import Path
  - from typing import Dict, List
  - import matplotlib.pyplot as plt
  - import networkx as nx
  - import yaml
  - 'def read_file(file_path: Path)':
    - file_type = file_path.suffix[1:]
    - with file_path.open() as f:
      - if file_type == 'json':
        - return:
          - json.load(f)
      - if file_type == 'yaml':
        - return:
          - yaml.load(f, Loader=yaml.SafeLoader)
      - return:
        - '{}'
  - 'def write_file(data: Dict, file_path: Path)':
    - file_type = file_path.suffix[1:]
    - with file_path.open('w') as f:
      - if file_type == 'json':
        - json.dump(data, f, indent=4)
        elif file_type == 'yaml':
        - 'yaml.SafeDumper.ignore_aliases = lambda *args: True'
        - yaml.dump(data, f, Dumper=yaml.SafeDumper, sort_keys=False)
  - 'def convert_json_to_html(directory: str)':
    - 'def preserve_spacing(text: str, tab_width: int)':
      - return:
        - text.replace(' ', '&nbsp;').replace('\t', '&nbsp;' * tab_width)
    - for json_file in Path(directory).rglob('*.json'):
      - try:
        - dataset = read_file(json_file)
        - if not dataset:
          - continue
        except:
        - 'except Exception as :':
          - continue
      - 'html_content = ''\n        <html>\n        <head>\n            <style>\n                table
        {border-collapse: collapse; width: 100%; table-layout: fixed;}\n                th,
        td {\n                    border: 1px solid black;\n                    padding:
        8px;\n                    text-align: left;\n                    white-space:
        pre-line;\n                    vertical-align: top;\n                    word-wrap:
        break-word;\n                }\n            </style>\n        </head>\n        <body>\n            <table>\n                <thead>\n                    <tr>\n        '''
      - column_count = len(dataset[0].keys())
      - column_width = round(100 / column_count, 2)
      - for key in dataset[0].keys():
        - 'html_content += f"<th style=''width: {column_width}%;''>{key}</th>"'
      - html_content += '\n                    </tr>\n                </thead>\n                <tbody>\n        '
      - html_rows = []
      - for entry in dataset:
        - row_parts = ['<tr>']
        - for key in entry:
          - value = escape(str(entry[key]))
          - value = preserve_spacing(value)
          - value = value.replace('\n', '<br/>')
          - row_parts.append(f'<td>{value}</td>')
        - row_parts.append('</tr>')
        - html_rows.append(''.join(row_parts))
      - html_content += ''.join(html_rows)
      - html_content += '\n                </tbody>\n            </table>\n        </body>\n        </html>\n        '
      - html_file_path = json_file.with_suffix('.html')
      - try:
        - with open(html_file_path, 'w', encoding='utf-8') as file:
          - file.write(html_content)
        except:
        - 'except Exception as :':
          - 'logging.info(f''Failed saving: {html_file_path}'')'
  - 'def create_code_graph(file_details: Dict, base_name: str, output_subdir: Path)':
    - graph_type = 'entire_code_graph'
    - G = nx.DiGraph()
    - G.add_nodes_from(file_details['file_info'][graph_type]['nodes'])
    - for edge in file_details['file_info'][graph_type]['edges']:
      - source, target = (edge['source'], edge['target'])
      - if source in G.nodes and target in G.nodes:
        - 'G.add_edge(source, target, **{k: v for k, v in edge.items() if k in [''target_inputs'',
          ''target_returns'']})'
    - plt.figure(figsize=(20, 20))
    - pos = nx.spring_layout(G)
    - nx.draw(G, pos, with_labels=True, font_weight='bold', font_size=8, node_shape='s',
      node_size=500, width=1, arrowsize=12)
    - edge_labels = {}
    - for edge in G.edges(data=True):
      - label = []
      - if 'target_inputs' in edge[2] and edge[2]['target_inputs']:
        - 'label.append(f"Inputs: {'', ''.join(edge[2][''target_inputs''])}")'
      - if 'target_returns' in edge[2] and edge[2]['target_returns']:
        - 'label.append(f"\nReturns: {'', ''.join(edge[2][''target_returns''])}")'
      - edge_labels[edge[0], edge[1]] = '\n'.join(label)
    - nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)
    - output_file = output_subdir / f'{base_name}.{graph_type}.png'
    - plt.savefig(output_file)
    - plt.close()
  plant_uml: "@startuml\n  def [\"logging.info(f'Combining JSON files in {directory}')\"\
    , 'combined_data, code_filename = ([], [])', \"skip_files = {'instruct.json',\
    \ 'chat_ml.json', 'document_code.json'}\", {\"for json_file in Path(directory).rglob('*.json')\"\
    : [{'if json_file.name in skip_files': ['continue']}, {'try': ['file_data = read_file(json_file)',\
    \ {'if file_data': ['combined_data.extend(file_data)', \"cleaned_name = json_file.relative_to(directory).with_suffix('').as_posix().replace('.instruct',\
    \ '')\", 'code_filename.append(cleaned_name)']}], 'except': [{'except Exception\
    \ as :': [\"logging.info(f'Failed reading: {json_file}. Error: {e}')\"]}]}]},\
    \ \"write_file(combined_data, Path(directory) / 'instruct.json')\", \"purpose_question\
    \ = [item['text'] for item in questions if item['id'] == 'file_purpose'][0]\"\
    , \"purpose_question = purpose_question.split('{filename}')[0]\", \"purpose_data\
    \ = [item for item in combined_data if item['instruction'].startswith(purpose_question)]\"\
    , \"document_code = [{'document': item['output'], 'code': item['input']} for item\
    \ in purpose_data]\", {'for (i, item) in enumerate(document_code)': [\"item['code\
    \ filename'] = code_filename[i]\"]}, \"write_file(document_code, Path(directory)\
    \ / 'document_code.json')\", 'chat_ml = [{\\'conversation\\': [{\\'from\\': \\\
    'system\\', \\'value\\': f\"code documentation: {item[\\'document\\']}\"}, {\\\
    'from\\': \\'human\\', \\'value\\': \\'Output the Python code described by the\
    \ code documentation.\\'}, {\\'from\\': \\'gpt\\', \\'value\\': item[\\'code\\\
    ']}], \\'nbytes\\': \\'0\\', \\'source\\': item[\\'code filename\\']} for item\
    \ in document_code]', {'for item in chat_ml': ['nbytes = 0', {\"for conv in item['conversation']\"\
    : [\"nbytes += len(conv['value'].encode('utf-8'))\"]}, \"item['nbytes'] = nbytes\"\
    ]}, \"write_file(chat_ml, Path(directory) / 'chat_ml.json')\", {'if html': [\"\
    logging.info('Converting JSON files to HTML')\", 'convert_json_to_html(directory)']},\
    \ {'return': [\"{'instruct_list': combined_data}\"]}] {\n    :logging.info(f'Combining\
    \ JSON files in {directory}');\n    :combined_data, code_filename = ([], []);\n\
    \    :skip_files = {'instruct.json', 'chat_ml.json', 'document_code.json'};\n\
    \    while ([{'if json_file.name in skip_files': ['continue']}, {'try': ['file_data\
    \ = read_file(json_file)', {'if file_data': ['combined_data.extend(file_data)',\
    \ \"cleaned_name = json_file.relative_to(directory).with_suffix('').as_posix().replace('.instruct',\
    \ '')\", 'code_filename.append(cleaned_name)']}], 'except': [{'except Exception\
    \ as :': [\"logging.info(f'Failed reading: {json_file}. Error: {e}')\"]}]}]) {\n\
    \      if (['continue']) {\n        :continue;\n      }\n      :try;\n      :file_data\
    \ = read_file(json_file);\n      if (['combined_data.extend(file_data)', \"cleaned_name\
    \ = json_file.relative_to(directory).with_suffix('').as_posix().replace('.instruct',\
    \ '')\", 'code_filename.append(cleaned_name)']) {\n        :combined_data.extend(file_data);\n\
    \        :cleaned_name = json_file.relative_to(directory).with_suffix('').as_posix().replace('.instruct',\
    \ '');\n        :code_filename.append(cleaned_name);\n      }\n    }\n    :write_file(combined_data,\
    \ Path(directory) / 'instruct.json');\n    :purpose_question = [item['text'] for\
    \ item in questions if item['id'] == 'file_purpose'][0];\n    :purpose_question\
    \ = purpose_question.split('{filename}')[0];\n    :purpose_data = [item for item\
    \ in combined_data if item['instruction'].startswith(purpose_question)];\n   \
    \ :document_code = [{'document': item['output'], 'code': item['input']} for item\
    \ in purpose_data];\n    while ([\"item['code filename'] = code_filename[i]\"\
    ]) {\n      :item['code filename'] = code_filename[i];\n    }\n    :write_file(document_code,\
    \ Path(directory) / 'document_code.json');\n    :chat_ml = [{'conversation': [{'from':\
    \ 'system', 'value': f\"code documentation: {item['document']}\"}, {'from': 'human',\
    \ 'value': 'Output the Python code described by the code documentation.'}, {'from':\
    \ 'gpt', 'value': item['code']}], 'nbytes': '0', 'source': item['code filename']}\
    \ for item in document_code];\n    while (['nbytes = 0', {\"for conv in item['conversation']\"\
    : [\"nbytes += len(conv['value'].encode('utf-8'))\"]}, \"item['nbytes'] = nbytes\"\
    ]) {\n      :nbytes = 0;\n      while ([\"nbytes += len(conv['value'].encode('utf-8'))\"\
    ]) {\n        :nbytes += len(conv['value'].encode('utf-8'));\n      }\n      :item['nbytes']\
    \ = nbytes;\n    }\n    :write_file(chat_ml, Path(directory) / 'chat_ml.json');\n\
    \    if ([\"logging.info('Converting JSON files to HTML')\", 'convert_json_to_html(directory)'])\
    \ {\n      :logging.info('Converting JSON files to HTML');\n      :convert_json_to_html(directory);\n\
    \    }\n    :return;\n    :{'instruct_list': combined_data};\n  }\n  def ['output_subdir\
    \ = Path(output_dir) / relative_path.parent', 'output_subdir.mkdir(parents=True,\
    \ exist_ok=True)', 'base_name = relative_path.name', \"write_file(instruct_list,\
    \ output_subdir / f'{base_name}.instruct.json')\", \"write_file(file_details,\
    \ output_subdir / f'{base_name}.details.yaml')\", {'try': ['create_code_graph(file_details,\
    \ base_name, output_subdir)'], 'except': [{'except Exception as :': [\"logging.error(f'Error\
    \ creating graph for {base_name}: {e}', exc_info=True)\"]}]}] {\n    :output_subdir\
    \ = Path(output_dir) / relative_path.parent;\n    :output_subdir.mkdir(parents=True,\
    \ exist_ok=True);\n    :base_name = relative_path.name;\n    :write_file(instruct_list,\
    \ output_subdir / f'{base_name}.instruct.json');\n    :write_file(file_details,\
    \ output_subdir / f'{base_name}.details.yaml');\n    :try;\n    :create_code_graph(file_details,\
    \ base_name, output_subdir);\n  }\n  :import json;\n  :import logging;\n  :from\
    \ html import escape;\n  :from pathlib import Path;\n  :from typing import Dict,\
    \ List;\n  :import matplotlib.pyplot as plt;\n  :import networkx as nx;\n  :import\
    \ yaml;\n  def ['file_type = file_path.suffix[1:]', {'with file_path.open() as\
    \ f': [{\"if file_type == 'json'\": [{'return': ['json.load(f)']}]}, {\"if file_type\
    \ == 'yaml'\": [{'return': ['yaml.load(f, Loader=yaml.SafeLoader)']}]}, {'return':\
    \ ['{}']}]}] {\n    :file_type = file_path.suffix[1:];\n    :with file_path.open()\
    \ as f;\n    if ([{'return': ['json.load(f)']}]) {\n      :return;\n      :json.load(f);\n\
    \    }\n    if ([{'return': ['yaml.load(f, Loader=yaml.SafeLoader)']}]) {\n  \
    \    :return;\n      :yaml.load(f, Loader=yaml.SafeLoader);\n    }\n    :return;\n\
    \    :{};\n  }\n  def ['file_type = file_path.suffix[1:]', {\"with file_path.open('w')\
    \ as f\": [{\"if file_type == 'json'\": ['json.dump(data, f, indent=4)'], \"elif\
    \ file_type == 'yaml'\": ['yaml.SafeDumper.ignore_aliases = lambda *args: True',\
    \ 'yaml.dump(data, f, Dumper=yaml.SafeDumper, sort_keys=False)']}]}] {\n    :file_type\
    \ = file_path.suffix[1:];\n    :with file_path.open('w') as f;\n    if (['json.dump(data,\
    \ f, indent=4)']) {\n      :json.dump(data, f, indent=4);\n    }\n  }\n  def [{'def\
    \ preserve_spacing(text: str, tab_width: int)': [{'return': [\"text.replace('\
    \ ', '&nbsp;').replace('\\\\t', '&nbsp;' * tab_width)\"]}]}, {\"for json_file\
    \ in Path(directory).rglob('*.json')\": [{'try': ['dataset = read_file(json_file)',\
    \ {'if not dataset': ['continue']}], 'except': [{'except Exception as :': ['continue']}]},\
    \ \"html_content = '\\\\n        <html>\\\\n        <head>\\\\n            <style>\\\
    \\n                table {border-collapse: collapse; width: 100%; table-layout:\
    \ fixed;}\\\\n                th, td {\\\\n                    border: 1px solid\
    \ black;\\\\n                    padding: 8px;\\\\n                    text-align:\
    \ left;\\\\n                    white-space: pre-line;\\\\n                  \
    \  vertical-align: top;\\\\n                    word-wrap: break-word;\\\\n  \
    \              }\\\\n            </style>\\\\n        </head>\\\\n        <body>\\\
    \\n            <table>\\\\n                <thead>\\\\n                    <tr>\\\
    \\n        '\", 'column_count = len(dataset[0].keys())', 'column_width = round(100\
    \ / column_count, 2)', {'for key in dataset[0].keys()': ['html_content += f\"\
    <th style=\\'width: {column_width}%;\\'>{key}</th>\"']}, \"html_content += '\\\
    \\n                    </tr>\\\\n                </thead>\\\\n               \
    \ <tbody>\\\\n        '\", 'html_rows = []', {'for entry in dataset': [\"row_parts\
    \ = ['<tr>']\", {'for key in entry': ['value = escape(str(entry[key]))', 'value\
    \ = preserve_spacing(value)', \"value = value.replace('\\\\n', '<br/>')\", \"\
    row_parts.append(f'<td>{value}</td>')\"]}, \"row_parts.append('</tr>')\", \"html_rows.append(''.join(row_parts))\"\
    ]}, \"html_content += ''.join(html_rows)\", \"html_content += '\\\\n         \
    \       </tbody>\\\\n            </table>\\\\n        </body>\\\\n        </html>\\\
    \\n        '\", \"html_file_path = json_file.with_suffix('.html')\", {'try': [{\"\
    with open(html_file_path, 'w', encoding='utf-8') as file\": ['file.write(html_content)']}],\
    \ 'except': [{'except Exception as :': [\"logging.info(f'Failed saving: {html_file_path}')\"\
    ]}]}]}] {\n    def [{'return': [\"text.replace(' ', '&nbsp;').replace('\\\\t',\
    \ '&nbsp;' * tab_width)\"]}] {\n      :return;\n      :text.replace(' ', '&nbsp;').replace('\\\
    t', '&nbsp;' * tab_width);\n    }\n    while ([{'try': ['dataset = read_file(json_file)',\
    \ {'if not dataset': ['continue']}], 'except': [{'except Exception as :': ['continue']}]},\
    \ \"html_content = '\\\\n        <html>\\\\n        <head>\\\\n            <style>\\\
    \\n                table {border-collapse: collapse; width: 100%; table-layout:\
    \ fixed;}\\\\n                th, td {\\\\n                    border: 1px solid\
    \ black;\\\\n                    padding: 8px;\\\\n                    text-align:\
    \ left;\\\\n                    white-space: pre-line;\\\\n                  \
    \  vertical-align: top;\\\\n                    word-wrap: break-word;\\\\n  \
    \              }\\\\n            </style>\\\\n        </head>\\\\n        <body>\\\
    \\n            <table>\\\\n                <thead>\\\\n                    <tr>\\\
    \\n        '\", 'column_count = len(dataset[0].keys())', 'column_width = round(100\
    \ / column_count, 2)', {'for key in dataset[0].keys()': ['html_content += f\"\
    <th style=\\'width: {column_width}%;\\'>{key}</th>\"']}, \"html_content += '\\\
    \\n                    </tr>\\\\n                </thead>\\\\n               \
    \ <tbody>\\\\n        '\", 'html_rows = []', {'for entry in dataset': [\"row_parts\
    \ = ['<tr>']\", {'for key in entry': ['value = escape(str(entry[key]))', 'value\
    \ = preserve_spacing(value)', \"value = value.replace('\\\\n', '<br/>')\", \"\
    row_parts.append(f'<td>{value}</td>')\"]}, \"row_parts.append('</tr>')\", \"html_rows.append(''.join(row_parts))\"\
    ]}, \"html_content += ''.join(html_rows)\", \"html_content += '\\\\n         \
    \       </tbody>\\\\n            </table>\\\\n        </body>\\\\n        </html>\\\
    \\n        '\", \"html_file_path = json_file.with_suffix('.html')\", {'try': [{\"\
    with open(html_file_path, 'w', encoding='utf-8') as file\": ['file.write(html_content)']}],\
    \ 'except': [{'except Exception as :': [\"logging.info(f'Failed saving: {html_file_path}')\"\
    ]}]}]) {\n      :try;\n      :dataset = read_file(json_file);\n      if (['continue'])\
    \ {\n        :continue;\n      }\n      :html_content = '\\n        <html>\\n\
    \        <head>\\n            <style>\\n                table {border-collapse:\
    \ collapse; width: 100%; table-layout: fixed;}\\n                th, td {\\n \
    \                   border: 1px solid black;\\n                    padding: 8px;\\\
    n                    text-align: left;\\n                    white-space: pre-line;\\\
    n                    vertical-align: top;\\n                    word-wrap: break-word;\\\
    n                }\\n            </style>\\n        </head>\\n        <body>\\\
    n            <table>\\n                <thead>\\n                    <tr>\\n \
    \       ';\n      :column_count = len(dataset[0].keys());\n      :column_width\
    \ = round(100 / column_count, 2);\n      while (['html_content += f\"<th style=\\\
    'width: {column_width}%;\\'>{key}</th>\"']) {\n        :html_content += f\"<th\
    \ style='width: {column_width}%;'>{key}</th>\";\n      }\n      :html_content\
    \ += '\\n                    </tr>\\n                </thead>\\n             \
    \   <tbody>\\n        ';\n      :html_rows = [];\n      while ([\"row_parts =\
    \ ['<tr>']\", {'for key in entry': ['value = escape(str(entry[key]))', 'value\
    \ = preserve_spacing(value)', \"value = value.replace('\\\\n', '<br/>')\", \"\
    row_parts.append(f'<td>{value}</td>')\"]}, \"row_parts.append('</tr>')\", \"html_rows.append(''.join(row_parts))\"\
    ]) {\n        :row_parts = ['<tr>'];\n        while (['value = escape(str(entry[key]))',\
    \ 'value = preserve_spacing(value)', \"value = value.replace('\\\\n', '<br/>')\"\
    , \"row_parts.append(f'<td>{value}</td>')\"]) {\n          :value = escape(str(entry[key]));\n\
    \          :value = preserve_spacing(value);\n          :value = value.replace('\\\
    n', '<br/>');\n          :row_parts.append(f'<td>{value}</td>');\n        }\n\
    \        :row_parts.append('</tr>');\n        :html_rows.append(''.join(row_parts));\n\
    \      }\n      :html_content += ''.join(html_rows);\n      :html_content += '\\\
    n                </tbody>\\n            </table>\\n        </body>\\n        </html>\\\
    n        ';\n      :html_file_path = json_file.with_suffix('.html');\n      :try;\n\
    \      :with open(html_file_path, 'w', encoding='utf-8') as file;\n      :file.write(html_content);\n\
    \    }\n  }\n  def [\"graph_type = 'entire_code_graph'\", 'G = nx.DiGraph()',\
    \ \"G.add_nodes_from(file_details['file_info'][graph_type]['nodes'])\", {\"for\
    \ edge in file_details['file_info'][graph_type]['edges']\": [\"source, target\
    \ = (edge['source'], edge['target'])\", {'if source in G.nodes and target in G.nodes':\
    \ [\"G.add_edge(source, target, **{k: v for k, v in edge.items() if k in ['target_inputs',\
    \ 'target_returns']})\"]}]}, 'plt.figure(figsize=(20, 20))', 'pos = nx.spring_layout(G)',\
    \ \"nx.draw(G, pos, with_labels=True, font_weight='bold', font_size=8, node_shape='s',\
    \ node_size=500, width=1, arrowsize=12)\", 'edge_labels = {}', {'for edge in G.edges(data=True)':\
    \ ['label = []', {\"if 'target_inputs' in edge[2] and edge[2]['target_inputs']\"\
    : ['label.append(f\"Inputs: {\\', \\'.join(edge[2][\\'target_inputs\\'])}\")']},\
    \ {\"if 'target_returns' in edge[2] and edge[2]['target_returns']\": ['label.append(f\"\
    \\\\nReturns: {\\', \\'.join(edge[2][\\'target_returns\\'])}\")']}, \"edge_labels[edge[0],\
    \ edge[1]] = '\\\\n'.join(label)\"]}, 'nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels,\
    \ font_size=6)', \"output_file = output_subdir / f'{base_name}.{graph_type}.png'\"\
    , 'plt.savefig(output_file)', 'plt.close()'] {\n    :graph_type = 'entire_code_graph';\n\
    \    :G = nx.DiGraph();\n    :G.add_nodes_from(file_details['file_info'][graph_type]['nodes']);\n\
    \    while ([\"source, target = (edge['source'], edge['target'])\", {'if source\
    \ in G.nodes and target in G.nodes': [\"G.add_edge(source, target, **{k: v for\
    \ k, v in edge.items() if k in ['target_inputs', 'target_returns']})\"]}]) {\n\
    \      :source, target = (edge['source'], edge['target']);\n      if ([\"G.add_edge(source,\
    \ target, **{k: v for k, v in edge.items() if k in ['target_inputs', 'target_returns']})\"\
    ]) {\n        :G.add_edge(source, target, **{k: v for k, v in edge.items() if\
    \ k in ['target_inputs', 'target_returns']});\n      }\n    }\n    :plt.figure(figsize=(20,\
    \ 20));\n    :pos = nx.spring_layout(G);\n    :nx.draw(G, pos, with_labels=True,\
    \ font_weight='bold', font_size=8, node_shape='s', node_size=500, width=1, arrowsize=12);\n\
    \    :edge_labels = {};\n    while (['label = []', {\"if 'target_inputs' in edge[2]\
    \ and edge[2]['target_inputs']\": ['label.append(f\"Inputs: {\\', \\'.join(edge[2][\\\
    'target_inputs\\'])}\")']}, {\"if 'target_returns' in edge[2] and edge[2]['target_returns']\"\
    : ['label.append(f\"\\\\nReturns: {\\', \\'.join(edge[2][\\'target_returns\\'])}\"\
    )']}, \"edge_labels[edge[0], edge[1]] = '\\\\n'.join(label)\"]) {\n      :label\
    \ = [];\n      if (['label.append(f\"Inputs: {\\', \\'.join(edge[2][\\'target_inputs\\\
    '])}\")']) {\n        :label.append(f\"Inputs: {', '.join(edge[2]['target_inputs'])}\"\
    );\n      }\n      if (['label.append(f\"\\\\nReturns: {\\', \\'.join(edge[2][\\\
    'target_returns\\'])}\")']) {\n        :label.append(f\"\\nReturns: {', '.join(edge[2]['target_returns'])}\"\
    );\n      }\n      :edge_labels[edge[0], edge[1]] = '\\n'.join(label);\n    }\n\
    \    :nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6);\n\
    \    :output_file = output_subdir / f'{base_name}.{graph_type}.png';\n    :plt.savefig(output_file);\n\
    \    :plt.close();\n  }\nend\n@enduml"
functions:
  read_file:
    function_name: read_file
    function_code: "def read_file(file_path: Path) -> Dict:\n    \"\"\"\n    Reads\
      \ a JSON or YAML file and returns its contents as a dictionary.\n    Args:\n\
      \        file_path (Path): The path to the file.\n    Returns:\n        The\
      \ contents of the file as a dictionary.\n    \"\"\"\n    file_type = file_path.suffix[1:]\n\
      \    with file_path.open() as f:\n        if file_type == 'json':\n        \
      \    return json.load(f)\n        if file_type == 'yaml':\n            return\
      \ yaml.load(f, Loader=yaml.SafeLoader)\n        return {}"
    function_docstring: "\n    Reads a JSON or YAML file and returns its contents\
      \ as a dictionary.\n    Args:\n        file_path (Path): The path to the file.\n\
      \    Returns:\n        The contents of the file as a dictionary.\n    "
    function_inputs:
    - file_path
    function_defaults: []
    function_returns:
    - '{}'
    - json.load(f)
    - yaml.load(f, Loader=yaml.SafeLoader)
    function_calls:
    - file_path.open
    - json.load
    - yaml.load
    function_call_inputs:
      file_path.open: []
      json.load:
      - f
      yaml.load:
      - f
    function_variables:
    - file_path
    - file_type
    function_decorators: []
    function_annotations: []
    function_properties: []
  write_file:
    function_name: write_file
    function_code: "def write_file(data: Dict, file_path: Path) -> None:\n    \"\"\
      \"\n    Writes a dictionary to a JSON or YAML file.\n    Args:\n        data\
      \ (Dict): The data to write to the file.\n        file_path (Path): The path\
      \ to the file.\n    Returns:\n        None\n    \"\"\"\n    file_type = file_path.suffix[1:]\n\
      \    with file_path.open('w') as f:\n        if file_type == 'json':\n     \
      \       json.dump(data, f, indent=4)\n        elif file_type == 'yaml':\n  \
      \          yaml.SafeDumper.ignore_aliases = lambda *args: True\n           \
      \ yaml.dump(data, f, Dumper=yaml.SafeDumper, sort_keys=False)"
    function_docstring: "\n    Writes a dictionary to a JSON or YAML file.\n    Args:\n\
      \        data (Dict): The data to write to the file.\n        file_path (Path):\
      \ The path to the file.\n    Returns:\n        None\n    "
    function_inputs:
    - data
    - file_path
    function_defaults: []
    function_returns: []
    function_calls:
    - file_path.open
    - json.dump
    - yaml.dump
    function_call_inputs:
      file_path.open:
      - '''w'''
      json.dump:
      - data
      - f
      yaml.dump:
      - data
      - f
    function_variables:
    - file_path
    - data
    - file_type
    function_decorators: []
    function_annotations: []
    function_properties:
    - yaml.SafeDumper.ignore_aliases
  convert_json_to_html:
    function_name: convert_json_to_html
    function_code: "def convert_json_to_html(directory: str) -> None:\n    \"\"\"\n\
      \    Convert JSON files within a given directory to HTML format and save .html\
      \ file.\n    Args:\n        directory (str): The directory where the JSON files\
      \ are located.\n    Returns:\n        None\n    \"\"\"\n\n    def preserve_spacing(text:\
      \ str, tab_width: int=4) -> str:\n        \"\"\"Preserve spaces and tabs in\
      \ the provided text.\"\"\"\n        return text.replace(' ', '&nbsp;').replace('\\\
      t', '&nbsp;' * tab_width)\n    for json_file in Path(directory).rglob('*.json'):\n\
      \        try:\n            dataset = read_file(json_file)\n            if not\
      \ dataset:\n                continue\n        except Exception:\n          \
      \  continue\n        html_content = '\\n        <html>\\n        <head>\\n \
      \           <style>\\n                table {border-collapse: collapse; width:\
      \ 100%; table-layout: fixed;}\\n                th, td {\\n                \
      \    border: 1px solid black;\\n                    padding: 8px;\\n       \
      \             text-align: left;\\n                    white-space: pre-line;\\\
      n                    vertical-align: top;\\n                    word-wrap: break-word;\\\
      n                }\\n            </style>\\n        </head>\\n        <body>\\\
      n            <table>\\n                <thead>\\n                    <tr>\\\
      n        '\n        column_count = len(dataset[0].keys())\n        column_width\
      \ = round(100 / column_count, 2)\n        for key in dataset[0].keys():\n  \
      \          html_content += f\"<th style='width: {column_width}%;'>{key}</th>\"\
      \n        html_content += '\\n                    </tr>\\n                </thead>\\\
      n                <tbody>\\n        '\n        html_rows = []\n        for entry\
      \ in dataset:\n            row_parts = ['<tr>']\n            for key in entry:\n\
      \                value = escape(str(entry[key]))\n                value = preserve_spacing(value)\n\
      \                value = value.replace('\\n', '<br/>')\n                row_parts.append(f'<td>{value}</td>')\n\
      \            row_parts.append('</tr>')\n            html_rows.append(''.join(row_parts))\n\
      \        html_content += ''.join(html_rows)\n        html_content += '\\n  \
      \              </tbody>\\n            </table>\\n        </body>\\n        </html>\\\
      n        '\n        html_file_path = json_file.with_suffix('.html')\n      \
      \  try:\n            with open(html_file_path, 'w', encoding='utf-8') as file:\n\
      \                file.write(html_content)\n        except Exception:\n     \
      \       logging.info(f'Failed saving: {html_file_path}')"
    function_docstring: "\n    Convert JSON files within a given directory to HTML\
      \ format and save .html file.\n    Args:\n        directory (str): The directory\
      \ where the JSON files are located.\n    Returns:\n        None\n    "
    function_inputs:
    - directory
    function_defaults: []
    function_returns:
    - text.replace(' ', '&nbsp;').replace('\t', '&nbsp;' * tab_width)
    function_calls:
    - text.replace(' ', '&nbsp;').replace
    - text.replace
    - Path(directory).rglob
    - Path
    - read_file
    - len
    - dataset[0].keys
    - round
    - escape
    - str
    - preserve_spacing
    - value.replace
    - row_parts.append
    - html_rows.append
    - '''''.join'
    - json_file.with_suffix
    - open
    - file.write
    - logging.info
    function_call_inputs:
      text.replace(' ', '&nbsp;').replace:
      - '''\t'''
      - '''&nbsp;'' * tab_width'
      text.replace:
      - ''' '''
      - '''&nbsp;'''
      Path(directory).rglob:
      - '''*.json'''
      Path:
      - directory
      read_file:
      - json_file
      len:
      - dataset[0].keys()
      dataset[0].keys: []
      round:
      - 100 / column_count
      - '2'
      escape:
      - str(entry[key])
      str:
      - entry[key]
      preserve_spacing:
      - value
      value.replace:
      - '''\n'''
      - '''<br/>'''
      row_parts.append:
      - f'<td>{value}</td>'
      - '''</tr>'''
      html_rows.append:
      - '''''.join(row_parts)'
      '''''.join':
      - row_parts
      - html_rows
      json_file.with_suffix:
      - '''.html'''
      open:
      - html_file_path
      - '''w'''
      file.write:
      - html_content
      logging.info:
      - 'f''Failed saving: {html_file_path}'''
    function_variables:
    - row_parts
    - column_width
    - html_rows
    - value
    - column_count
    - html_content
    - html_file_path
    - dataset
    - directory
    function_decorators: []
    function_annotations: []
    function_properties: []
  preserve_spacing:
    function_name: preserve_spacing
    function_code: "def preserve_spacing(text: str, tab_width: int=4) -> str:\n  \
      \  \"\"\"Preserve spaces and tabs in the provided text.\"\"\"\n    return text.replace('\
      \ ', '&nbsp;').replace('\\t', '&nbsp;' * tab_width)"
    function_docstring: Preserve spaces and tabs in the provided text.
    function_inputs:
    - text
    - tab_width
    function_defaults:
    - '4'
    function_returns:
    - text.replace(' ', '&nbsp;').replace('\t', '&nbsp;' * tab_width)
    function_calls:
    - text.replace(' ', '&nbsp;').replace
    - text.replace
    function_call_inputs:
      text.replace(' ', '&nbsp;').replace:
      - '''\t'''
      - '''&nbsp;'' * tab_width'
      text.replace:
      - ''' '''
      - '''&nbsp;'''
    function_variables:
    - tab_width
    - text
    function_decorators: []
    function_annotations: []
    function_properties: []
  combine_json_files:
    function_name: combine_json_files
    function_code: "def combine_json_files(directory: str, html: bool, questions:\
      \ Dict) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Combine all JSON files in\
      \ the output directory into 'instruct.json', and\n    then remove duplicates.\
      \ Also generate a 'training.json' file.\n    Args:\n        directory (str):\
      \ The directory where the output files are located.\n    Returns:\n        A\
      \ dictionary containing the 'instruct_list' datasets.\n    \"\"\"\n    logging.info(f'Combining\
      \ JSON files in {directory}')\n    combined_data, code_filename = ([], [])\n\
      \    skip_files = {'instruct.json', 'chat_ml.json', 'document_code.json'}\n\
      \    for json_file in Path(directory).rglob('*.json'):\n        if json_file.name\
      \ in skip_files:\n            continue\n        try:\n            file_data\
      \ = read_file(json_file)\n            if file_data:\n                combined_data.extend(file_data)\n\
      \                cleaned_name = json_file.relative_to(directory).with_suffix('').as_posix().replace('.instruct',\
      \ '')\n                code_filename.append(cleaned_name)\n        except Exception\
      \ as e:\n            logging.info(f'Failed reading: {json_file}. Error: {e}')\n\
      \    write_file(combined_data, Path(directory) / 'instruct.json')\n    purpose_question\
      \ = [item['text'] for item in questions if item['id'] == 'file_purpose'][0]\n\
      \    purpose_question = purpose_question.split('{filename}')[0]\n    purpose_data\
      \ = [item for item in combined_data if item['instruction'].startswith(purpose_question)]\n\
      \    document_code = [{'document': item['output'], 'code': item['input']} for\
      \ item in purpose_data]\n    for i, item in enumerate(document_code):\n    \
      \    item['code filename'] = code_filename[i]\n    write_file(document_code,\
      \ Path(directory) / 'document_code.json')\n    chat_ml = [{'conversation': [{'from':\
      \ 'system', 'value': f\"code documentation: {item['document']}\"}, {'from':\
      \ 'human', 'value': 'Output the Python code described by the code documentation.'},\
      \ {'from': 'gpt', 'value': item['code']}], 'nbytes': '0', 'source': item['code\
      \ filename']} for item in document_code]\n    for item in chat_ml:\n       \
      \ nbytes = 0\n        for conv in item['conversation']:\n            nbytes\
      \ += len(conv['value'].encode('utf-8'))\n        item['nbytes'] = nbytes\n \
      \   write_file(chat_ml, Path(directory) / 'chat_ml.json')\n    if html:\n  \
      \      logging.info('Converting JSON files to HTML')\n        convert_json_to_html(directory)\n\
      \    return {'instruct_list': combined_data}"
    function_docstring: "\n    Combine all JSON files in the output directory into\
      \ 'instruct.json', and\n    then remove duplicates. Also generate a 'training.json'\
      \ file.\n    Args:\n        directory (str): The directory where the output\
      \ files are located.\n    Returns:\n        A dictionary containing the 'instruct_list'\
      \ datasets.\n    "
    function_inputs:
    - directory
    - html
    - questions
    function_defaults: []
    function_returns:
    - '{''instruct_list'': combined_data}'
    function_calls:
    - logging.info
    - Path(directory).rglob
    - Path
    - read_file
    - combined_data.extend
    - json_file.relative_to(directory).with_suffix('').as_posix().replace
    - json_file.relative_to(directory).with_suffix('').as_posix
    - json_file.relative_to(directory).with_suffix
    - json_file.relative_to
    - code_filename.append
    - write_file
    - purpose_question.split
    - item['instruction'].startswith
    - enumerate
    - len
    - conv['value'].encode
    - convert_json_to_html
    function_call_inputs:
      logging.info:
      - f'Combining JSON files in {directory}'
      - 'f''Failed reading: {json_file}. Error: {e}'''
      - '''Converting JSON files to HTML'''
      Path(directory).rglob:
      - '''*.json'''
      Path:
      - directory
      - directory
      - directory
      - directory
      read_file:
      - json_file
      combined_data.extend:
      - file_data
      json_file.relative_to(directory).with_suffix('').as_posix().replace:
      - '''.instruct'''
      - ''''''
      json_file.relative_to(directory).with_suffix('').as_posix: []
      json_file.relative_to(directory).with_suffix:
      - ''''''
      json_file.relative_to:
      - directory
      code_filename.append:
      - cleaned_name
      write_file:
      - combined_data
      - Path(directory) / 'instruct.json'
      - document_code
      - Path(directory) / 'document_code.json'
      - chat_ml
      - Path(directory) / 'chat_ml.json'
      purpose_question.split:
      - '''{filename}'''
      item['instruction'].startswith:
      - purpose_question
      enumerate:
      - document_code
      len:
      - conv['value'].encode('utf-8')
      conv['value'].encode:
      - '''utf-8'''
      convert_json_to_html:
      - directory
    function_variables:
    - questions
    - purpose_data
    - html
    - purpose_question
    - cleaned_name
    - skip_files
    - file_data
    - directory
    - nbytes
    - document_code
    - chat_ml
    function_decorators: []
    function_annotations: []
    function_properties: []
  create_code_graph:
    function_name: create_code_graph
    function_code: "def create_code_graph(file_details: Dict, base_name: str, output_subdir:\
      \ Path) -> None:\n    \"\"\"\n    Generate graphs from the file_details and\
      \ save them as PNG images.\n    Args:\n        file_details (dict): The details\
      \ extracted from the Python file.\n        base_name (str): The base name of\
      \ the output files.\n        output_subdir (Path): The subdirectory where the\
      \ output files will be saved.\n    Returns:\n        None\n    \"\"\"\n    graph_type\
      \ = 'entire_code_graph'\n    G = nx.DiGraph()\n    G.add_nodes_from(file_details['file_info'][graph_type]['nodes'])\n\
      \    for edge in file_details['file_info'][graph_type]['edges']:\n        source,\
      \ target = (edge['source'], edge['target'])\n        if source in G.nodes and\
      \ target in G.nodes:\n            G.add_edge(source, target, **{k: v for k,\
      \ v in edge.items() if k in ['target_inputs', 'target_returns']})\n    plt.figure(figsize=(20,\
      \ 20))\n    pos = nx.spring_layout(G)\n    nx.draw(G, pos, with_labels=True,\
      \ font_weight='bold', font_size=8, node_shape='s', node_size=500, width=1, arrowsize=12)\n\
      \    edge_labels = {}\n    for edge in G.edges(data=True):\n        label =\
      \ []\n        if 'target_inputs' in edge[2] and edge[2]['target_inputs']:\n\
      \            label.append(f\"Inputs: {', '.join(edge[2]['target_inputs'])}\"\
      )\n        if 'target_returns' in edge[2] and edge[2]['target_returns']:\n \
      \           label.append(f\"\\nReturns: {', '.join(edge[2]['target_returns'])}\"\
      )\n        edge_labels[edge[0], edge[1]] = '\\n'.join(label)\n    nx.draw_networkx_edge_labels(G,\
      \ pos, edge_labels=edge_labels, font_size=6)\n    output_file = output_subdir\
      \ / f'{base_name}.{graph_type}.png'\n    plt.savefig(output_file)\n    plt.close()"
    function_docstring: "\n    Generate graphs from the file_details and save them\
      \ as PNG images.\n    Args:\n        file_details (dict): The details extracted\
      \ from the Python file.\n        base_name (str): The base name of the output\
      \ files.\n        output_subdir (Path): The subdirectory where the output files\
      \ will be saved.\n    Returns:\n        None\n    "
    function_inputs:
    - file_details
    - base_name
    - output_subdir
    function_defaults: []
    function_returns: []
    function_calls:
    - nx.DiGraph
    - G.add_nodes_from
    - G.add_edge
    - edge.items
    - plt.figure
    - nx.spring_layout
    - nx.draw
    - G.edges
    - label.append
    - ''', ''.join'
    - '''\n''.join'
    - nx.draw_networkx_edge_labels
    - plt.savefig
    - plt.close
    function_call_inputs:
      nx.DiGraph: []
      G.add_nodes_from:
      - file_details['file_info'][graph_type]['nodes']
      G.add_edge:
      - source
      - target
      edge.items: []
      plt.figure: []
      nx.spring_layout:
      - G
      nx.draw:
      - G
      - pos
      G.edges: []
      label.append:
      - 'f"Inputs: {'', ''.join(edge[2][''target_inputs''])}"'
      - 'f"\nReturns: {'', ''.join(edge[2][''target_returns''])}"'
      ''', ''.join':
      - edge[2]['target_inputs']
      - edge[2]['target_returns']
      '''\n''.join':
      - label
      nx.draw_networkx_edge_labels:
      - G
      - pos
      plt.savefig:
      - output_file
      plt.close: []
    function_variables:
    - output_subdir
    - edge_labels
    - pos
    - file_details
    - graph_type
    - label
    - output_file
    - base_name
    - G
    function_decorators: []
    function_annotations: []
    function_properties: []
  save_python_data:
    function_name: save_python_data
    function_code: "def save_python_data(file_details: dict, instruct_list: list,\
      \ relative_path: Path, output_dir: str) -> None:\n    \"\"\"\n    Save the details\
      \ of the Python file as a YAML file, the instruction data as JSON files,\n \
      \   and generate and save code graphs.\n    Args:\n        file_details (dict):\
      \ The details extracted from the Python file.\n        instruct_list (list):\
      \ The instruction data extracted from the Python file.\n        relative_path\
      \ (Path): The relative path of the Python file.\n        output_dir (str): The\
      \ directory where the output files will be saved.\n    Returns:\n        None\n\
      \    \"\"\"\n    output_subdir = Path(output_dir) / relative_path.parent\n \
      \   output_subdir.mkdir(parents=True, exist_ok=True)\n    base_name = relative_path.name\n\
      \    write_file(instruct_list, output_subdir / f'{base_name}.instruct.json')\n\
      \    write_file(file_details, output_subdir / f'{base_name}.details.yaml')\n\
      \    try:\n        create_code_graph(file_details, base_name, output_subdir)\n\
      \    except Exception as e:\n        logging.error(f'Error creating graph for\
      \ {base_name}: {e}', exc_info=True)"
    function_docstring: "\n    Save the details of the Python file as a YAML file,\
      \ the instruction data as JSON files,\n    and generate and save code graphs.\n\
      \    Args:\n        file_details (dict): The details extracted from the Python\
      \ file.\n        instruct_list (list): The instruction data extracted from the\
      \ Python file.\n        relative_path (Path): The relative path of the Python\
      \ file.\n        output_dir (str): The directory where the output files will\
      \ be saved.\n    Returns:\n        None\n    "
    function_inputs:
    - file_details
    - instruct_list
    - relative_path
    - output_dir
    function_defaults: []
    function_returns: []
    function_calls:
    - Path
    - output_subdir.mkdir
    - write_file
    - create_code_graph
    - logging.error
    function_call_inputs:
      Path:
      - output_dir
      output_subdir.mkdir: []
      write_file:
      - instruct_list
      - output_subdir / f'{base_name}.instruct.json'
      - file_details
      - output_subdir / f'{base_name}.details.yaml'
      create_code_graph:
      - file_details
      - base_name
      - output_subdir
      logging.error:
      - 'f''Error creating graph for {base_name}: {e}'''
    function_variables:
    - output_subdir
    - output_dir
    - instruct_list
    - file_details
    - relative_path
    - base_name
    function_decorators: []
    function_annotations: []
    function_properties: []
classes: {}
