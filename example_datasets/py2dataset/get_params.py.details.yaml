file_info:
  file_code: "\"\"\"\nObtain data parameter and model from the py2dataset functions.\n\
    Requirements:\n[req01] The `get_default_questions` function shall:\n        a.\
    \ Return a list of default questions.\n        b. Ensure each question in the\
    \ list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text,\
    \ and type.\n[req02] The `get_default_model_config` function shall:\n        a.\
    \ Return a dictionary representing the default model configuration.\n[req03] The\
    \ `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n\
    \        b. Return the absolute path of the provided output_dir if it exists or\
    \ can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir\
    \ argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n\
    \        a. Accept an optional questions_pathname argument.\n        b. Validate\
    \ the question file provided by the questions_pathname.\n        c. Return the\
    \ questions from the provided questions_pathname if valid.\n        d. Return\
    \ default questions if the questions_pathname is not provided or invalid.\n[req05]\
    \ The `instantiate_model` function shall:\n        a. Accept a model_config dictionary\
    \ as an argument.\n        b. Import the specified module and class from the model_config.\n\
    \        c. Instantiate and return the model using the provided configuration.\n\
    [req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname\
    \ argument.\n        b. Validate the model config file provided by the model_config_pathname.\n\
    \        c. Return an instantiated model and a prompt template based on the provided\
    \ configuration.\n        d. Return an instantiated model and a prompt template\
    \ based on the default model configuration if the model_config_pathname is not\
    \ provided or invalid.\n[req07] The `write_questions_file` function shall:\n \
    \       a. Accept an optional output_dir argument.\n        b. Write the default\
    \ questions to the QUESTIONS_FILE in the specified directory.\n        c. Write\
    \ the default questions to the QUESTIONS_FILE in the current working directory\
    \ if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file`\
    \ function shall:\n        a. Accept an optional output_dir argument.\n      \
    \  b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified\
    \ directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE\
    \ in the current working directory if the output_dir argument is not provided\
    \ or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport importlib\n\
    from typing import Dict, List\nfrom pathlib import Path\nimport yaml\n\n# Setting\
    \ up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\n# defaults if\
    \ provided inputs fail\nQUESTIONS_FILE = \"py2dataset_questions.json\"\nMODEL_CONFIG_FILE\
    \ = \"py2dataset_model_config.yaml\"\nOUTPUT_DIR = \"datasets\"\n\n\ndef get_default_questions()\
    \ -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n\
    \    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n   \
    \ questions = [\n        {\n            \"id\": \"file_dependencies\",\n     \
    \       \"text\": \"Dependencies in Python file: `{filename}`?\",\n          \
    \  \"type\": \"file\",\n        },\n        {\n            \"id\": \"entire_code_graph\"\
    ,\n            \"text\": \"Call code graph in Python file: `{filename}`?\",\n\
    \            \"type\": \"file\",\n        },\n        {\n            \"id\": \"\
    file_functions\",\n            \"text\": \"Functions in Python file: `{filename}`?\"\
    ,\n            \"type\": \"file\",\n        },\n        {\n            \"id\"\
    : \"file_classes\",\n            \"text\": \"Classes in Python file: `{filename}`?\"\
    ,\n            \"type\": \"file\",\n        },\n        {\n            \"id\"\
    : \"function_inputs\",\n            \"text\": \"Inputs to `{function_name}` in\
    \ Python file: `{filename}`?\",\n            \"type\": \"function\",\n       \
    \ },\n        {\n            \"id\": \"function_docstring\",\n            \"text\"\
    : \"Docstring of `{function_name}` in Python file: `{filename}`?\",\n        \
    \    \"type\": \"function\",\n        },\n        {\n            \"id\": \"function_calls\"\
    ,\n            \"text\": \"Calls made in `{function_name}` in Python file: `{filename}`?\"\
    ,\n            \"type\": \"function\",\n        },\n        {\n            \"\
    id\": \"function_variables\",\n            \"text\": \"Variables in `{function_name}`\
    \ in Python file: `{filename}`?\",\n            \"type\": \"function\",\n    \
    \    },\n        {\n            \"id\": \"function_returns\",\n            \"\
    text\": \"Returns from `{function_name}` in Python file: `{filename}`?\",\n  \
    \          \"type\": \"function\",\n        },\n        {\n            \"id\"\
    : \"class_methods\",\n            \"text\": \"Methods in `{class_name}` in Python\
    \ file: `{filename}`?\",\n            \"type\": \"class\",\n        },\n     \
    \   {\n            \"id\": \"class_docstring\",\n            \"text\": \"Docstring\
    \ of `{class_name}` in Python file: `{filename}`?\",\n            \"type\": \"\
    class\",\n        },\n        {\n            \"id\": \"class_attributes\",\n \
    \           \"text\": \"Attributes of `{class_name}` in Python file: `{filename}`?\"\
    ,\n            \"type\": \"class\",\n        },\n        {\n            \"id\"\
    : \"class_inheritance\",\n            \"text\": \"Inheritance of `{class_name}`\
    \ in Python file: `{filename}`?\",\n            \"type\": \"class\",\n       \
    \ },\n        {\n            \"id\": \"method_inputs\",\n            \"text\"\
    : \"Inputs to `{method_name}` in Python file: `{filename}`?\",\n            \"\
    type\": \"method\",\n        },\n        {\n            \"id\": \"method_docstring\"\
    ,\n            \"text\": \"Docstring of `{method_name}` in Python file: `{filename}`?\"\
    ,\n            \"type\": \"method\",\n        },\n        {\n            \"id\"\
    : \"method_calls\",\n            \"text\": \"Calls made in `{method_name}` in\
    \ Python file: `{filename}`?\",\n            \"type\": \"method\",\n        },\n\
    \        {\n            \"id\": \"method_variables\",\n            \"text\": \"\
    Variables in `{method_name}` in Python file: `{filename}`?\",\n            \"\
    type\": \"method\",\n        },\n        {\n            \"id\": \"method_returns\"\
    ,\n            \"text\": \"Returns from `{method_name}` in Python file: `{filename}`?\"\
    ,\n            \"type\": \"method\",\n        },\n        {\n            \"id\"\
    : \"file_purpose\",\n            \"text\": \"1) Describe the Purpose and Processing\
    \ summary of Python file: `{filename}`; 2) Summarize the Significance of applicable\
    \ Function, Class, and Method; 3) Explain what each Input, Output, and Variable\
    \ does in the code.\",\n            \"type\": \"file\",\n        },\n    ]\n \
    \   return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"\
    Return default model config dict\n    Args:\n        None\n    Returns:\n    \
    \    Dict: The default model config dictionary\n    \"\"\"\n    model_config =\
    \ {\n        \"system_prompt\": \"Provide complete structured response for a formal\
    \ software audit, given this Context:\\n'{context}'\\n\",\n        \"instruction_prompt\"\
    : \"\\nPlease provide a very detailed, accurate, and insightful Response to this\
    \ Instruction and include your reasoning step by step.\\n{query}\\n\",\n     \
    \   \"prompt_template\": \"{system_prompt} ### Instruction: {instruction_prompt}\
    \ ### Response: \",\n        \"inference_model\": {\n            \"model_import_path\"\
    : \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\"\
    : \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\"\
    : \"TheBloke/WizardCoder-Python-13B-V1.0-GGUF\",\n                \"model_file\"\
    : \"wizardcoder-python-13b-v1.0.Q5_K_S.gguf\",\n                \"model_type\"\
    : \"llama\",\n                \"local_files_only\": False,\n                ##\
    \ MODEL CONFIGURATION PARAMETERS (set for current model with: GPU 4090-24GB VRAM,\
    \ CPU 5950x-32 threads, 64GB RAM)\n                # avx2 and gpu_layers are not\
    \ compatible\n                # \"lib\": \"avx2\",\n                \"threads\"\
    : 16,\n                \"batch_size\": 128,\n                \"context_length\"\
    : 12000,\n                \"max_new_tokens\": 12000,\n                \"gpu_layers\"\
    : 100,\n                \"reset\": True,\n            },\n        },\n    }\n\
    \    return model_config\n\n\ndef get_start_dir(start_dir: str = \"\") -> str:\n\
    \    \"\"\"\n    Returns the appropriate start directory.\n    Args:\n       \
    \ start_dir (str): The directory to start the search from.\n    Returns:\n   \
    \     str: The absolute path of the provided start_dir if it exists or can be\
    \ created.\n    \"\"\"\n    if start_dir and not Path(start_dir).is_dir():\n \
    \       logging.info(f\"Setting Start Dir : {start_dir}\")\n        start_dir\
    \ = os.getcwd()\n    else:\n        start_dir = os.path.abspath(start_dir)\n \
    \   return start_dir\n\n\ndef get_output_dir(output_dir: str = \"\") -> str:\n\
    \    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir\
    \ (str): The directory to write the output to.\n    Returns:\n        str: The\
    \ absolute path of the provided output_dir if it exists or can be created.\n \
    \   \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir,\
    \ exist_ok=True)\n    logging.info(f\"Using output directory: {output_dir}\")\n\
    \    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n\
    \    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname\
    \ (str): The pathname of the questions file\n    Returns:\n        List[Dict]:\
    \ The list of questions\n    \"\"\"\n    try:  # get questions from provided or\
    \ default configuration file\n        if not questions_pathname:\n           \
    \ questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with\
    \ open(questions_pathname, \"r\") as f:\n            questions = json.load(f)\n\
    \        logging.info(f\"Using questions from file: {questions_pathname}\")\n\
    \    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(\n\
    \            f\"Questions file not valid: {questions_pathname} Using default questions\"\
    \n        )\n        questions = get_default_questions()\n    return questions\n\
    \n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports\
    \ and instantiates a model based on the provided configuration.\n    Args:\n \
    \       model_config (dict): model configuration dictionary.\n    Returns:\n \
    \       object: An instance of the specified model class, or None if error.\n\
    \    \"\"\"\n    try:\n        module_name, class_name = model_config[\"model_import_path\"\
    ].rsplit(\".\", 1)\n        ModelClass = getattr(importlib.import_module(module_name),\
    \ class_name)\n        model_params = model_config[\"model_params\"]\n       \
    \ inference_function_name = model_config[\"model_inference_function\"]\n     \
    \   if inference_function_name != \"\":\n            inference_function = getattr(ModelClass,\
    \ inference_function_name)\n            llm = inference_function(model_params.pop(\"\
    model_path\"), **model_params)\n        else:\n            llm = ModelClass(model_params.pop(\"\
    model_path\"), **model_params)\n        return llm\n    except (ImportError, AttributeError,\
    \ Exception) as e:\n        logging.info(f\"Failed to instantiate the model. Error:\
    \ {e}\")\n        return None\n\n\ndef get_model(model_config_pathname: str) ->\
    \ object:\n    \"\"\"\n    Returns an instantiated model and prompt template based\
    \ on the model configuration.\n    Agrs:\n        model_config_pathname (str):\
    \ The pathname of the model config file\n    Returns:\n        Tuple[object, str]:\
    \ The instantiated model\n    \"\"\"\n    try:\n        if not model_config_pathname:\n\
    \            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n\
    \        with open(model_config_pathname, \"r\") as config_file:\n           \
    \ model_config = yaml.safe_load(config_file)\n        logging.info(f\"Using model\
    \ config from file: {model_config_pathname}\")\n    except (FileNotFoundError,\
    \ yaml.YAMLError):\n        logging.info(\n            f\"Model config file not\
    \ valid: {model_config_pathname} Using default model config\"\n        )\n   \
    \     model_config = get_default_model_config()\n    model_config[\"model\"] =\
    \ instantiate_model(model_config[\"inference_model\"])\n\n    return model_config\n\
    \n\ndef write_questions_file(output_dir: str = \"\") -> None:\n    \"\"\"\n  \
    \  Writes the default questions to a file in JSON format.\n    Args:\n       \
    \ output_dir (str): The directory to write the questions file to.\n    Returns:\n\
    \        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir\
    \ = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n\
    \    with open(os.path.join(output_dir, QUESTIONS_FILE), \"w\") as file:\n   \
    \     json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir:\
    \ str = \"\") -> None:\n    \"\"\"\n    Writes the default model config to a file\
    \ in YAML format.\n    Args:\n        output_dir (str): The directory to write\
    \ the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config\
    \ = get_default_model_config()\n    output_dir = output_dir if output_dir and\
    \ Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir,\
    \ MODEL_CONFIG_FILE), \"w\") as file:\n        yaml.dump(model_config, file)\n"
  file_dependencies:
  - importlib
  - typing
  - pathlib
  - logging
  - yaml
  - json
  - os
  file_functions:
  - get_default_questions
  - get_default_model_config
  - get_start_dir
  - get_output_dir
  - get_questions
  - instantiate_model
  - get_model
  - write_questions_file
  - write_model_config_file
  file_classes: []
  file_constants:
  - QUESTIONS_FILE='py2dataset_questions.json'
  - MODEL_CONFIG_FILE='py2dataset_model_config.yaml'
  - OUTPUT_DIR='datasets'
  file_summary: '{dependencies: [importlib, typing, pathlib, logging, yaml, json,
    os], function_defs: [{get_default_questions: {inputs: [], calls: [], call_inputs:
    {}, returns: [questions]}}, {get_default_model_config: {inputs: [], calls: [],
    call_inputs: {}, returns: [model_config]}}, {get_start_dir: {inputs: [start_dir],
    calls: [Path(start_dir).is_dir, Path, logging.info, os.getcwd, os.path.abspath],
    call_inputs: {Path(start_dir).is_dir: [], Path: [start_dir], logging.info: [f''Setting
    Start Dir : {start_dir}''], os.getcwd: [], os.path.abspath: [start_dir]}, returns:
    [start_dir]}}, {get_output_dir: {inputs: [output_dir], calls: [os.path.abspath,
    os.makedirs, logging.info], call_inputs: {os.path.abspath: [output_dir or OUTPUT_DIR],
    os.makedirs: [output_dir], logging.info: [f''Using output directory: {output_dir}'']},
    returns: [output_dir]}}, {get_questions: {inputs: [questions_pathname], calls:
    [os.path.join, os.getcwd, open, json.load, logging.info, get_default_questions],
    call_inputs: {os.path.join: [os.getcwd(), QUESTIONS_FILE], os.getcwd: [], open:
    [questions_pathname, ''r''], json.load: [f], logging.info: [f''Using questions
    from file: {questions_pathname}'', f''Questions file not valid: {questions_pathname}
    Using default questions''], get_default_questions: []}, returns: [questions]}},
    {instantiate_model: {inputs: [model_config], calls: [model_config[''model_import_path''].rsplit,
    getattr, importlib.import_module, inference_function, model_params.pop, ModelClass,
    logging.info], call_inputs: {model_config[''model_import_path''].rsplit: [''.'',
    1], getattr: [importlib.import_module(module_name), class_name, ModelClass, inference_function_name],
    importlib.import_module: [module_name], inference_function: [model_params.pop(''model_path'')],
    model_params.pop: [''model_path'', ''model_path''], ModelClass: [model_params.pop(''model_path'')],
    logging.info: [f''Failed to instantiate the model. Error: {e}'']}, returns: [llm,
    None]}}, {get_model: {inputs: [model_config_pathname], calls: [os.path.join, os.getcwd,
    open, yaml.safe_load, logging.info, get_default_model_config, instantiate_model],
    call_inputs: {os.path.join: [os.getcwd(), MODEL_CONFIG_FILE], os.getcwd: [], open:
    [model_config_pathname, ''r''], yaml.safe_load: [config_file], logging.info: [f''Using
    model config from file: {model_config_pathname}'', f''Model config file not valid:
    {model_config_pathname} Using default model config''], get_default_model_config:
    [], instantiate_model: [model_config[''inference_model'']]}, returns: [model_config]}},
    {write_questions_file: {inputs: [output_dir], calls: [get_default_questions, Path(output_dir).is_dir,
    Path, os.getcwd, open, os.path.join, json.dump], call_inputs: {get_default_questions:
    [], Path(output_dir).is_dir: [], Path: [output_dir], os.getcwd: [], open: [os.path.join(output_dir,
    QUESTIONS_FILE), ''w''], os.path.join: [output_dir, QUESTIONS_FILE], json.dump:
    [questions, file]}, returns: []}}, {write_model_config_file: {inputs: [output_dir],
    calls: [get_default_model_config, Path(output_dir).is_dir, Path, os.getcwd, open,
    os.path.join, yaml.dump], call_inputs: {get_default_model_config: [], Path(output_dir).is_dir:
    [], Path: [output_dir], os.getcwd: [], open: [os.path.join(output_dir, MODEL_CONFIG_FILE),
    ''w''], os.path.join: [output_dir, MODEL_CONFIG_FILE], yaml.dump: [model_config,
    file]}, returns: []}}], class_defs: []}'
  file_code_simplified: "import os\nimport json\nimport logging\nimport importlib\n\
    from typing import Dict, List\nfrom pathlib import Path\nimport yaml\nlogging.basicConfig(level=logging.INFO)\n\
    QUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\n\
    OUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    questions\
    \ = [{'id': 'file_dependencies', 'text': 'Dependencies in Python file: `{filename}`?',\
    \ 'type': 'file'}, {'id': 'entire_code_graph', 'text': 'Call code graph in Python\
    \ file: `{filename}`?', 'type': 'file'}, {'id': 'file_functions', 'text': 'Functions\
    \ in Python file: `{filename}`?', 'type': 'file'}, {'id': 'file_classes', 'text':\
    \ 'Classes in Python file: `{filename}`?', 'type': 'file'}, {'id': 'function_inputs',\
    \ 'text': 'Inputs to `{function_name}` in Python file: `{filename}`?', 'type':\
    \ 'function'}, {'id': 'function_docstring', 'text': 'Docstring of `{function_name}`\
    \ in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_calls',\
    \ 'text': 'Calls made in `{function_name}` in Python file: `{filename}`?', 'type':\
    \ 'function'}, {'id': 'function_variables', 'text': 'Variables in `{function_name}`\
    \ in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_returns',\
    \ 'text': 'Returns from `{function_name}` in Python file: `{filename}`?', 'type':\
    \ 'function'}, {'id': 'class_methods', 'text': 'Methods in `{class_name}` in Python\
    \ file: `{filename}`?', 'type': 'class'}, {'id': 'class_docstring', 'text': 'Docstring\
    \ of `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id': 'class_attributes',\
    \ 'text': 'Attributes of `{class_name}` in Python file: `{filename}`?', 'type':\
    \ 'class'}, {'id': 'class_inheritance', 'text': 'Inheritance of `{class_name}`\
    \ in Python file: `{filename}`?', 'type': 'class'}, {'id': 'method_inputs', 'text':\
    \ 'Inputs to `{method_name}` in Python file: `{filename}`?', 'type': 'method'},\
    \ {'id': 'method_docstring', 'text': 'Docstring of `{method_name}` in Python file:\
    \ `{filename}`?', 'type': 'method'}, {'id': 'method_calls', 'text': 'Calls made\
    \ in `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id':\
    \ 'method_variables', 'text': 'Variables in `{method_name}` in Python file: `{filename}`?',\
    \ 'type': 'method'}, {'id': 'method_returns', 'text': 'Returns from `{method_name}`\
    \ in Python file: `{filename}`?', 'type': 'method'}, {'id': 'file_purpose', 'text':\
    \ '1) Describe the Purpose and Processing summary of Python file: `{filename}`;\
    \ 2) Summarize the Significance of applicable Function, Class, and Method; 3)\
    \ Explain what each Input, Output, and Variable does in the code.', 'type': 'file'}]\n\
    \    return questions\n\ndef get_default_model_config() -> Dict:\n    model_config\
    \ = {'system_prompt': \"Provide complete structured response for a formal software\
    \ audit, given this Context:\\n'{context}'\\n\", 'instruction_prompt': '\\nPlease\
    \ provide a very detailed, accurate, and insightful Response to this Instruction\
    \ and include your reasoning step by step.\\n{query}\\n', 'prompt_template': '{system_prompt}\
    \ ### Instruction: {instruction_prompt} ### Response: ', 'inference_model': {'model_import_path':\
    \ 'ctransformers.AutoModelForCausalLM', 'model_inference_function': 'from_pretrained',\
    \ 'model_params': {'model_path': 'TheBloke/WizardCoder-Python-13B-V1.0-GGUF',\
    \ 'model_file': 'wizardcoder-python-13b-v1.0.Q5_K_S.gguf', 'model_type': 'llama',\
    \ 'local_files_only': False, 'threads': 16, 'batch_size': 128, 'context_length':\
    \ 12000, 'max_new_tokens': 12000, 'gpu_layers': 100, 'reset': True}}}\n    return\
    \ model_config\n\ndef get_start_dir(start_dir: str='') -> str:\n    if start_dir\
    \ and (not Path(start_dir).is_dir()):\n        logging.info(f'Setting Start Dir\
    \ : {start_dir}')\n        start_dir = os.getcwd()\n    else:\n        start_dir\
    \ = os.path.abspath(start_dir)\n    return start_dir\n\ndef get_output_dir(output_dir:\
    \ str='') -> str:\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n\
    \    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory:\
    \ {output_dir}')\n    return output_dir\n\ndef get_questions(questions_pathname:\
    \ str) -> List[Dict]:\n    try:\n        if not questions_pathname:\n        \
    \    questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with\
    \ open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n\
    \        logging.info(f'Using questions from file: {questions_pathname}')\n  \
    \  except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions\
    \ file not valid: {questions_pathname} Using default questions')\n        questions\
    \ = get_default_questions()\n    return questions\n\ndef instantiate_model(model_config:\
    \ Dict) -> object:\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.',\
    \ 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n\
    \        model_params = model_config['model_params']\n        inference_function_name\
    \ = model_config['model_inference_function']\n        if inference_function_name\
    \ != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n\
    \            llm = inference_function(model_params.pop('model_path'), **model_params)\n\
    \        else:\n            llm = ModelClass(model_params.pop('model_path'), **model_params)\n\
    \        return llm\n    except (ImportError, AttributeError, Exception) as e:\n\
    \        logging.info(f'Failed to instantiate the model. Error: {e}')\n      \
    \  return None\n\ndef get_model(model_config_pathname: str) -> object:\n    try:\n\
    \        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(),\
    \ MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n\
    \            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using\
    \ model config from file: {model_config_pathname}')\n    except (FileNotFoundError,\
    \ yaml.YAMLError):\n        logging.info(f'Model config file not valid: {model_config_pathname}\
    \ Using default model config')\n        model_config = get_default_model_config()\n\
    \    model_config['model'] = instantiate_model(model_config['inference_model'])\n\
    \    return model_config\n\ndef write_questions_file(output_dir: str='') -> None:\n\
    \    questions = get_default_questions()\n    output_dir = output_dir if output_dir\
    \ and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir,\
    \ QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\
    \ndef write_model_config_file(output_dir: str='') -> None:\n    model_config =\
    \ get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir()\
    \ else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE),\
    \ 'w') as file:\n        yaml.dump(model_config, file)"
  entire_code_graph:
    nodes:
    - get_default_questions
    - get_default_model_config
    - get_start_dir
    - get_output_dir
    - get_questions
    - instantiate_model
    - get_model
    - write_questions_file
    - write_model_config_file
    - Path(start_dir).is_dir
    - Path
    - logging.info
    - os.getcwd
    - os.path.abspath
    - os.makedirs
    - os.path.join
    - open
    - json.load
    - model_config['model_import_path'].rsplit
    - getattr
    - importlib.import_module
    - inference_function
    - model_params.pop
    - ModelClass
    - yaml.safe_load
    - Path(output_dir).is_dir
    - json.dump
    - yaml.dump
    edges:
    - source: get_start_dir
      target: Path(start_dir).is_dir
      target_inputs: []
    - source: get_start_dir
      target: Path
      target_inputs:
      - start_dir
    - source: get_start_dir
      target: logging.info
      target_inputs:
      - 'f''Setting Start Dir : {start_dir}'''
    - source: get_start_dir
      target: os.getcwd
      target_inputs: []
    - source: get_start_dir
      target: os.path.abspath
      target_inputs:
      - start_dir
    - source: get_output_dir
      target: os.path.abspath
      target_inputs:
      - output_dir or OUTPUT_DIR
    - source: get_output_dir
      target: os.makedirs
      target_inputs:
      - output_dir
    - source: get_output_dir
      target: logging.info
      target_inputs:
      - 'f''Using output directory: {output_dir}'''
    - source: get_questions
      target: os.path.join
      target_inputs:
      - os.getcwd()
      - QUESTIONS_FILE
    - source: get_questions
      target: os.getcwd
      target_inputs: []
    - source: get_questions
      target: open
      target_inputs:
      - questions_pathname
      - '''r'''
    - source: get_questions
      target: json.load
      target_inputs:
      - f
    - source: get_questions
      target: logging.info
      target_inputs:
      - 'f''Using questions from file: {questions_pathname}'''
      - 'f''Questions file not valid: {questions_pathname} Using default questions'''
    - source: get_questions
      target: get_default_questions
      target_inputs: []
      target_returns:
      - questions
    - source: instantiate_model
      target: model_config['model_import_path'].rsplit
      target_inputs:
      - '''.'''
      - '1'
    - source: instantiate_model
      target: getattr
      target_inputs:
      - importlib.import_module(module_name)
      - class_name
      - ModelClass
      - inference_function_name
    - source: instantiate_model
      target: importlib.import_module
      target_inputs:
      - module_name
    - source: instantiate_model
      target: inference_function
      target_inputs:
      - model_params.pop('model_path')
    - source: instantiate_model
      target: model_params.pop
      target_inputs:
      - '''model_path'''
      - '''model_path'''
    - source: instantiate_model
      target: ModelClass
      target_inputs:
      - model_params.pop('model_path')
    - source: instantiate_model
      target: logging.info
      target_inputs:
      - 'f''Failed to instantiate the model. Error: {e}'''
    - source: get_model
      target: os.path.join
      target_inputs:
      - os.getcwd()
      - MODEL_CONFIG_FILE
    - source: get_model
      target: os.getcwd
      target_inputs: []
    - source: get_model
      target: open
      target_inputs:
      - model_config_pathname
      - '''r'''
    - source: get_model
      target: yaml.safe_load
      target_inputs:
      - config_file
    - source: get_model
      target: logging.info
      target_inputs:
      - 'f''Using model config from file: {model_config_pathname}'''
      - 'f''Model config file not valid: {model_config_pathname} Using default model
        config'''
    - source: get_model
      target: get_default_model_config
      target_inputs: []
      target_returns:
      - model_config
    - source: get_model
      target: instantiate_model
      target_inputs:
      - model_config['inference_model']
      target_returns:
      - llm
      - None
    - source: write_questions_file
      target: get_default_questions
      target_inputs: []
      target_returns:
      - questions
    - source: write_questions_file
      target: Path(output_dir).is_dir
      target_inputs: []
    - source: write_questions_file
      target: Path
      target_inputs:
      - output_dir
    - source: write_questions_file
      target: os.getcwd
      target_inputs: []
    - source: write_questions_file
      target: open
      target_inputs:
      - os.path.join(output_dir, QUESTIONS_FILE)
      - '''w'''
    - source: write_questions_file
      target: os.path.join
      target_inputs:
      - output_dir
      - QUESTIONS_FILE
    - source: write_questions_file
      target: json.dump
      target_inputs:
      - questions
      - file
    - source: write_model_config_file
      target: get_default_model_config
      target_inputs: []
      target_returns:
      - model_config
    - source: write_model_config_file
      target: Path(output_dir).is_dir
      target_inputs: []
    - source: write_model_config_file
      target: Path
      target_inputs:
      - output_dir
    - source: write_model_config_file
      target: os.getcwd
      target_inputs: []
    - source: write_model_config_file
      target: open
      target_inputs:
      - os.path.join(output_dir, MODEL_CONFIG_FILE)
      - '''w'''
    - source: write_model_config_file
      target: os.path.join
      target_inputs:
      - output_dir
      - MODEL_CONFIG_FILE
    - source: write_model_config_file
      target: yaml.dump
      target_inputs:
      - model_config
      - file
  control_flow_structure:
  - 'def get_start_dir(start_dir: str)':
    - if start_dir and (not Path(start_dir).is_dir()):
      - 'logging.info(f''Setting Start Dir : {start_dir}'')'
      - start_dir = os.getcwd()
      else:
      - start_dir = os.path.abspath(start_dir)
    - return:
      - start_dir
  - 'def get_output_dir(output_dir: str)':
    - output_dir = os.path.abspath(output_dir or OUTPUT_DIR)
    - os.makedirs(output_dir, exist_ok=True)
    - 'logging.info(f''Using output directory: {output_dir}'')'
    - return:
      - output_dir
  - 'def get_questions(questions_pathname: str)':
    - try:
      - if not questions_pathname:
        - questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)
      - with open(questions_pathname, 'r') as f:
        - questions = json.load(f)
      - 'logging.info(f''Using questions from file: {questions_pathname}'')'
      except:
      - 'except (FileNotFoundError, json.decoder.JSONDecodeError) as :':
        - 'logging.info(f''Questions file not valid: {questions_pathname} Using default
          questions'')'
        - questions = get_default_questions()
    - return:
      - questions
  - 'def get_model(model_config_pathname: str)':
    - try:
      - if not model_config_pathname:
        - model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)
      - with open(model_config_pathname, 'r') as config_file:
        - model_config = yaml.safe_load(config_file)
      - 'logging.info(f''Using model config from file: {model_config_pathname}'')'
      except:
      - 'except (FileNotFoundError, yaml.YAMLError) as :':
        - 'logging.info(f''Model config file not valid: {model_config_pathname} Using
          default model config'')'
        - model_config = get_default_model_config()
    - model_config['model'] = instantiate_model(model_config['inference_model'])
    - return:
      - model_config
  - 'def write_questions_file(output_dir: str)':
    - questions = get_default_questions()
    - output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()
    - with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:
      - json.dump(questions, file, indent=4)
  - 'def write_model_config_file(output_dir: str)':
    - model_config = get_default_model_config()
    - output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()
    - with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:
      - yaml.dump(model_config, file)
  - import os
  - import json
  - import logging
  - import importlib
  - from typing import Dict, List
  - from pathlib import Path
  - import yaml
  - logging.basicConfig(level=logging.INFO)
  - QUESTIONS_FILE = 'py2dataset_questions.json'
  - MODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'
  - OUTPUT_DIR = 'datasets'
  - def get_default_questions():
    - 'questions = [{''id'': ''file_dependencies'', ''text'': ''Dependencies in Python
      file: `{filename}`?'', ''type'': ''file''}, {''id'': ''entire_code_graph'',
      ''text'': ''Call code graph in Python file: `{filename}`?'', ''type'': ''file''},
      {''id'': ''file_functions'', ''text'': ''Functions in Python file: `{filename}`?'',
      ''type'': ''file''}, {''id'': ''file_classes'', ''text'': ''Classes in Python
      file: `{filename}`?'', ''type'': ''file''}, {''id'': ''function_inputs'', ''text'':
      ''Inputs to `{function_name}` in Python file: `{filename}`?'', ''type'': ''function''},
      {''id'': ''function_docstring'', ''text'': ''Docstring of `{function_name}`
      in Python file: `{filename}`?'', ''type'': ''function''}, {''id'': ''function_calls'',
      ''text'': ''Calls made in `{function_name}` in Python file: `{filename}`?'',
      ''type'': ''function''}, {''id'': ''function_variables'', ''text'': ''Variables
      in `{function_name}` in Python file: `{filename}`?'', ''type'': ''function''},
      {''id'': ''function_returns'', ''text'': ''Returns from `{function_name}` in
      Python file: `{filename}`?'', ''type'': ''function''}, {''id'': ''class_methods'',
      ''text'': ''Methods in `{class_name}` in Python file: `{filename}`?'', ''type'':
      ''class''}, {''id'': ''class_docstring'', ''text'': ''Docstring of `{class_name}`
      in Python file: `{filename}`?'', ''type'': ''class''}, {''id'': ''class_attributes'',
      ''text'': ''Attributes of `{class_name}` in Python file: `{filename}`?'', ''type'':
      ''class''}, {''id'': ''class_inheritance'', ''text'': ''Inheritance of `{class_name}`
      in Python file: `{filename}`?'', ''type'': ''class''}, {''id'': ''method_inputs'',
      ''text'': ''Inputs to `{method_name}` in Python file: `{filename}`?'', ''type'':
      ''method''}, {''id'': ''method_docstring'', ''text'': ''Docstring of `{method_name}`
      in Python file: `{filename}`?'', ''type'': ''method''}, {''id'': ''method_calls'',
      ''text'': ''Calls made in `{method_name}` in Python file: `{filename}`?'', ''type'':
      ''method''}, {''id'': ''method_variables'', ''text'': ''Variables in `{method_name}`
      in Python file: `{filename}`?'', ''type'': ''method''}, {''id'': ''method_returns'',
      ''text'': ''Returns from `{method_name}` in Python file: `{filename}`?'', ''type'':
      ''method''}, {''id'': ''file_purpose'', ''text'': ''1) Describe the Purpose
      and Processing summary of Python file: `{filename}`; 2) Summarize the Significance
      of applicable Function, Class, and Method; 3) Explain what each Input, Output,
      and Variable does in the code.'', ''type'': ''file''}]'
    - return:
      - questions
  - def get_default_model_config():
    - 'model_config = {''system_prompt'': "Provide complete structured response for
      a formal software audit, given this Context:\n''{context}''\n", ''instruction_prompt'':
      ''\nPlease provide a very detailed, accurate, and insightful Response to this
      Instruction and include your reasoning step by step.\n{query}\n'', ''prompt_template'':
      ''{system_prompt} ### Instruction: {instruction_prompt} ### Response: '', ''inference_model'':
      {''model_import_path'': ''ctransformers.AutoModelForCausalLM'', ''model_inference_function'':
      ''from_pretrained'', ''model_params'': {''model_path'': ''TheBloke/WizardCoder-Python-13B-V1.0-GGUF'',
      ''model_file'': ''wizardcoder-python-13b-v1.0.Q5_K_S.gguf'', ''model_type'':
      ''llama'', ''local_files_only'': False, ''threads'': 16, ''batch_size'': 128,
      ''context_length'': 12000, ''max_new_tokens'': 12000, ''gpu_layers'': 100, ''reset'':
      True}}}'
    - return:
      - model_config
  - 'def instantiate_model(model_config: Dict)':
    - try:
      - module_name, class_name = model_config['model_import_path'].rsplit('.', 1)
      - ModelClass = getattr(importlib.import_module(module_name), class_name)
      - model_params = model_config['model_params']
      - inference_function_name = model_config['model_inference_function']
      - if inference_function_name != '':
        - inference_function = getattr(ModelClass, inference_function_name)
        - llm = inference_function(model_params.pop('model_path'), **model_params)
        else:
        - llm = ModelClass(model_params.pop('model_path'), **model_params)
      - return:
        - llm
      except:
      - 'except (ImportError, AttributeError, Exception) as :':
        - 'logging.info(f''Failed to instantiate the model. Error: {e}'')'
        - return:
          - None
  plant_uml: "@startuml\n  def [{'if start_dir and (not Path(start_dir).is_dir())':\
    \ [\"logging.info(f'Setting Start Dir : {start_dir}')\", 'start_dir = os.getcwd()'],\
    \ 'else': ['start_dir = os.path.abspath(start_dir)']}, {'return': ['start_dir']}]\
    \ {\n    if ([\"logging.info(f'Setting Start Dir : {start_dir}')\", 'start_dir\
    \ = os.getcwd()']) {\n      :logging.info(f'Setting Start Dir : {start_dir}');\n\
    \      :start_dir = os.getcwd();\n    }\n    :return;\n    :start_dir;\n  }\n\
    \  def ['output_dir = os.path.abspath(output_dir or OUTPUT_DIR)', 'os.makedirs(output_dir,\
    \ exist_ok=True)', \"logging.info(f'Using output directory: {output_dir}')\",\
    \ {'return': ['output_dir']}] {\n    :output_dir = os.path.abspath(output_dir\
    \ or OUTPUT_DIR);\n    :os.makedirs(output_dir, exist_ok=True);\n    :logging.info(f'Using\
    \ output directory: {output_dir}');\n    :return;\n    :output_dir;\n  }\n  def\
    \ [{'try': [{'if not questions_pathname': ['questions_pathname = os.path.join(os.getcwd(),\
    \ QUESTIONS_FILE)']}, {\"with open(questions_pathname, 'r') as f\": ['questions\
    \ = json.load(f)']}, \"logging.info(f'Using questions from file: {questions_pathname}')\"\
    ], 'except': [{'except (FileNotFoundError, json.decoder.JSONDecodeError) as :':\
    \ [\"logging.info(f'Questions file not valid: {questions_pathname} Using default\
    \ questions')\", 'questions = get_default_questions()']}]}, {'return': ['questions']}]\
    \ {\n    :try;\n    if (['questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)'])\
    \ {\n      :questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE);\n\
    \    }\n    :with open(questions_pathname, 'r') as f;\n    :questions = json.load(f);\n\
    \    :logging.info(f'Using questions from file: {questions_pathname}');\n    :return;\n\
    \    :questions;\n  }\n  def [{'try': [{'if not model_config_pathname': ['model_config_pathname\
    \ = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)']}, {\"with open(model_config_pathname,\
    \ 'r') as config_file\": ['model_config = yaml.safe_load(config_file)']}, \"logging.info(f'Using\
    \ model config from file: {model_config_pathname}')\"], 'except': [{'except (FileNotFoundError,\
    \ yaml.YAMLError) as :': [\"logging.info(f'Model config file not valid: {model_config_pathname}\
    \ Using default model config')\", 'model_config = get_default_model_config()']}]},\
    \ \"model_config['model'] = instantiate_model(model_config['inference_model'])\"\
    , {'return': ['model_config']}] {\n    :try;\n    if (['model_config_pathname\
    \ = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)']) {\n      :model_config_pathname\
    \ = os.path.join(os.getcwd(), MODEL_CONFIG_FILE);\n    }\n    :with open(model_config_pathname,\
    \ 'r') as config_file;\n    :model_config = yaml.safe_load(config_file);\n   \
    \ :logging.info(f'Using model config from file: {model_config_pathname}');\n \
    \   :model_config['model'] = instantiate_model(model_config['inference_model']);\n\
    \    :return;\n    :model_config;\n  }\n  def ['questions = get_default_questions()',\
    \ 'output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()',\
    \ {\"with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file\": ['json.dump(questions,\
    \ file, indent=4)']}] {\n    :questions = get_default_questions();\n    :output_dir\
    \ = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd();\n\
    \    :with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file;\n    :json.dump(questions,\
    \ file, indent=4);\n  }\n  def ['model_config = get_default_model_config()', 'output_dir\
    \ = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()',\
    \ {\"with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file\": ['yaml.dump(model_config,\
    \ file)']}] {\n    :model_config = get_default_model_config();\n    :output_dir\
    \ = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd();\n\
    \    :with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file;\n \
    \   :yaml.dump(model_config, file);\n  }\n  :import os;\n  :import json;\n  :import\
    \ logging;\n  :import importlib;\n  :from typing import Dict, List;\n  :from pathlib\
    \ import Path;\n  :import yaml;\n  :logging.basicConfig(level=logging.INFO);\n\
    \  :QUESTIONS_FILE = 'py2dataset_questions.json';\n  :MODEL_CONFIG_FILE = 'py2dataset_model_config.yaml';\n\
    \  :OUTPUT_DIR = 'datasets';\n  def [\"questions = [{'id': 'file_dependencies',\
    \ 'text': 'Dependencies in Python file: `{filename}`?', 'type': 'file'}, {'id':\
    \ 'entire_code_graph', 'text': 'Call code graph in Python file: `{filename}`?',\
    \ 'type': 'file'}, {'id': 'file_functions', 'text': 'Functions in Python file:\
    \ `{filename}`?', 'type': 'file'}, {'id': 'file_classes', 'text': 'Classes in\
    \ Python file: `{filename}`?', 'type': 'file'}, {'id': 'function_inputs', 'text':\
    \ 'Inputs to `{function_name}` in Python file: `{filename}`?', 'type': 'function'},\
    \ {'id': 'function_docstring', 'text': 'Docstring of `{function_name}` in Python\
    \ file: `{filename}`?', 'type': 'function'}, {'id': 'function_calls', 'text':\
    \ 'Calls made in `{function_name}` in Python file: `{filename}`?', 'type': 'function'},\
    \ {'id': 'function_variables', 'text': 'Variables in `{function_name}` in Python\
    \ file: `{filename}`?', 'type': 'function'}, {'id': 'function_returns', 'text':\
    \ 'Returns from `{function_name}` in Python file: `{filename}`?', 'type': 'function'},\
    \ {'id': 'class_methods', 'text': 'Methods in `{class_name}` in Python file: `{filename}`?',\
    \ 'type': 'class'}, {'id': 'class_docstring', 'text': 'Docstring of `{class_name}`\
    \ in Python file: `{filename}`?', 'type': 'class'}, {'id': 'class_attributes',\
    \ 'text': 'Attributes of `{class_name}` in Python file: `{filename}`?', 'type':\
    \ 'class'}, {'id': 'class_inheritance', 'text': 'Inheritance of `{class_name}`\
    \ in Python file: `{filename}`?', 'type': 'class'}, {'id': 'method_inputs', 'text':\
    \ 'Inputs to `{method_name}` in Python file: `{filename}`?', 'type': 'method'},\
    \ {'id': 'method_docstring', 'text': 'Docstring of `{method_name}` in Python file:\
    \ `{filename}`?', 'type': 'method'}, {'id': 'method_calls', 'text': 'Calls made\
    \ in `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id':\
    \ 'method_variables', 'text': 'Variables in `{method_name}` in Python file: `{filename}`?',\
    \ 'type': 'method'}, {'id': 'method_returns', 'text': 'Returns from `{method_name}`\
    \ in Python file: `{filename}`?', 'type': 'method'}, {'id': 'file_purpose', 'text':\
    \ '1) Describe the Purpose and Processing summary of Python file: `{filename}`;\
    \ 2) Summarize the Significance of applicable Function, Class, and Method; 3)\
    \ Explain what each Input, Output, and Variable does in the code.', 'type': 'file'}]\"\
    , {'return': ['questions']}] {\n    :questions = [{'id': 'file_dependencies',\
    \ 'text': 'Dependencies in Python file: `{filename}`?', 'type': 'file'}, {'id':\
    \ 'entire_code_graph', 'text': 'Call code graph in Python file: `{filename}`?',\
    \ 'type': 'file'}, {'id': 'file_functions', 'text': 'Functions in Python file:\
    \ `{filename}`?', 'type': 'file'}, {'id': 'file_classes', 'text': 'Classes in\
    \ Python file: `{filename}`?', 'type': 'file'}, {'id': 'function_inputs', 'text':\
    \ 'Inputs to `{function_name}` in Python file: `{filename}`?', 'type': 'function'},\
    \ {'id': 'function_docstring', 'text': 'Docstring of `{function_name}` in Python\
    \ file: `{filename}`?', 'type': 'function'}, {'id': 'function_calls', 'text':\
    \ 'Calls made in `{function_name}` in Python file: `{filename}`?', 'type': 'function'},\
    \ {'id': 'function_variables', 'text': 'Variables in `{function_name}` in Python\
    \ file: `{filename}`?', 'type': 'function'}, {'id': 'function_returns', 'text':\
    \ 'Returns from `{function_name}` in Python file: `{filename}`?', 'type': 'function'},\
    \ {'id': 'class_methods', 'text': 'Methods in `{class_name}` in Python file: `{filename}`?',\
    \ 'type': 'class'}, {'id': 'class_docstring', 'text': 'Docstring of `{class_name}`\
    \ in Python file: `{filename}`?', 'type': 'class'}, {'id': 'class_attributes',\
    \ 'text': 'Attributes of `{class_name}` in Python file: `{filename}`?', 'type':\
    \ 'class'}, {'id': 'class_inheritance', 'text': 'Inheritance of `{class_name}`\
    \ in Python file: `{filename}`?', 'type': 'class'}, {'id': 'method_inputs', 'text':\
    \ 'Inputs to `{method_name}` in Python file: `{filename}`?', 'type': 'method'},\
    \ {'id': 'method_docstring', 'text': 'Docstring of `{method_name}` in Python file:\
    \ `{filename}`?', 'type': 'method'}, {'id': 'method_calls', 'text': 'Calls made\
    \ in `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id':\
    \ 'method_variables', 'text': 'Variables in `{method_name}` in Python file: `{filename}`?',\
    \ 'type': 'method'}, {'id': 'method_returns', 'text': 'Returns from `{method_name}`\
    \ in Python file: `{filename}`?', 'type': 'method'}, {'id': 'file_purpose', 'text':\
    \ '1) Describe the Purpose and Processing summary of Python file: `{filename}`;\
    \ 2) Summarize the Significance of applicable Function, Class, and Method; 3)\
    \ Explain what each Input, Output, and Variable does in the code.', 'type': 'file'}];\n\
    \    :return;\n    :questions;\n  }\n  def ['model_config = {\\'system_prompt\\\
    ': \"Provide complete structured response for a formal software audit, given this\
    \ Context:\\\\n\\'{context}\\'\\\\n\", \\'instruction_prompt\\': \\'\\\\nPlease\
    \ provide a very detailed, accurate, and insightful Response to this Instruction\
    \ and include your reasoning step by step.\\\\n{query}\\\\n\\', \\'prompt_template\\\
    ': \\'{system_prompt} ### Instruction: {instruction_prompt} ### Response: \\',\
    \ \\'inference_model\\': {\\'model_import_path\\': \\'ctransformers.AutoModelForCausalLM\\\
    ', \\'model_inference_function\\': \\'from_pretrained\\', \\'model_params\\':\
    \ {\\'model_path\\': \\'TheBloke/WizardCoder-Python-13B-V1.0-GGUF\\', \\'model_file\\\
    ': \\'wizardcoder-python-13b-v1.0.Q5_K_S.gguf\\', \\'model_type\\': \\'llama\\\
    ', \\'local_files_only\\': False, \\'threads\\': 16, \\'batch_size\\': 128, \\\
    'context_length\\': 12000, \\'max_new_tokens\\': 12000, \\'gpu_layers\\': 100,\
    \ \\'reset\\': True}}}', {'return': ['model_config']}] {\n    :model_config =\
    \ {'system_prompt': \"Provide complete structured response for a formal software\
    \ audit, given this Context:\\n'{context}'\\n\", 'instruction_prompt': '\\nPlease\
    \ provide a very detailed, accurate, and insightful Response to this Instruction\
    \ and include your reasoning step by step.\\n{query}\\n', 'prompt_template': '{system_prompt}\
    \ ### Instruction: {instruction_prompt} ### Response: ', 'inference_model': {'model_import_path':\
    \ 'ctransformers.AutoModelForCausalLM', 'model_inference_function': 'from_pretrained',\
    \ 'model_params': {'model_path': 'TheBloke/WizardCoder-Python-13B-V1.0-GGUF',\
    \ 'model_file': 'wizardcoder-python-13b-v1.0.Q5_K_S.gguf', 'model_type': 'llama',\
    \ 'local_files_only': False, 'threads': 16, 'batch_size': 128, 'context_length':\
    \ 12000, 'max_new_tokens': 12000, 'gpu_layers': 100, 'reset': True}}};\n    :return;\n\
    \    :model_config;\n  }\n  def [{'try': [\"module_name, class_name = model_config['model_import_path'].rsplit('.',\
    \ 1)\", 'ModelClass = getattr(importlib.import_module(module_name), class_name)',\
    \ \"model_params = model_config['model_params']\", \"inference_function_name =\
    \ model_config['model_inference_function']\", {\"if inference_function_name !=\
    \ ''\": ['inference_function = getattr(ModelClass, inference_function_name)',\
    \ \"llm = inference_function(model_params.pop('model_path'), **model_params)\"\
    ], 'else': [\"llm = ModelClass(model_params.pop('model_path'), **model_params)\"\
    ]}, {'return': ['llm']}], 'except': [{'except (ImportError, AttributeError, Exception)\
    \ as :': [\"logging.info(f'Failed to instantiate the model. Error: {e}')\", {'return':\
    \ ['None']}]}]}] {\n    :try;\n    :module_name, class_name = model_config['model_import_path'].rsplit('.',\
    \ 1);\n    :ModelClass = getattr(importlib.import_module(module_name), class_name);\n\
    \    :model_params = model_config['model_params'];\n    :inference_function_name\
    \ = model_config['model_inference_function'];\n    if (['inference_function =\
    \ getattr(ModelClass, inference_function_name)', \"llm = inference_function(model_params.pop('model_path'),\
    \ **model_params)\"]) {\n      :inference_function = getattr(ModelClass, inference_function_name);\n\
    \      :llm = inference_function(model_params.pop('model_path'), **model_params);\n\
    \    }\n    :return;\n    :llm;\n  }\nend\n@enduml"
functions:
  get_default_questions:
    function_name: get_default_questions
    function_code: "def get_default_questions() -> List[Dict]:\n    \"\"\"Return default\
      \ question list\n    Args:\n        None\n    Returns:\n        List[Dict]:\
      \ The default question list\n    \"\"\"\n    questions = [{'id': 'file_dependencies',\
      \ 'text': 'Dependencies in Python file: `{filename}`?', 'type': 'file'}, {'id':\
      \ 'entire_code_graph', 'text': 'Call code graph in Python file: `{filename}`?',\
      \ 'type': 'file'}, {'id': 'file_functions', 'text': 'Functions in Python file:\
      \ `{filename}`?', 'type': 'file'}, {'id': 'file_classes', 'text': 'Classes in\
      \ Python file: `{filename}`?', 'type': 'file'}, {'id': 'function_inputs', 'text':\
      \ 'Inputs to `{function_name}` in Python file: `{filename}`?', 'type': 'function'},\
      \ {'id': 'function_docstring', 'text': 'Docstring of `{function_name}` in Python\
      \ file: `{filename}`?', 'type': 'function'}, {'id': 'function_calls', 'text':\
      \ 'Calls made in `{function_name}` in Python file: `{filename}`?', 'type': 'function'},\
      \ {'id': 'function_variables', 'text': 'Variables in `{function_name}` in Python\
      \ file: `{filename}`?', 'type': 'function'}, {'id': 'function_returns', 'text':\
      \ 'Returns from `{function_name}` in Python file: `{filename}`?', 'type': 'function'},\
      \ {'id': 'class_methods', 'text': 'Methods in `{class_name}` in Python file:\
      \ `{filename}`?', 'type': 'class'}, {'id': 'class_docstring', 'text': 'Docstring\
      \ of `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id':\
      \ 'class_attributes', 'text': 'Attributes of `{class_name}` in Python file:\
      \ `{filename}`?', 'type': 'class'}, {'id': 'class_inheritance', 'text': 'Inheritance\
      \ of `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id':\
      \ 'method_inputs', 'text': 'Inputs to `{method_name}` in Python file: `{filename}`?',\
      \ 'type': 'method'}, {'id': 'method_docstring', 'text': 'Docstring of `{method_name}`\
      \ in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_calls',\
      \ 'text': 'Calls made in `{method_name}` in Python file: `{filename}`?', 'type':\
      \ 'method'}, {'id': 'method_variables', 'text': 'Variables in `{method_name}`\
      \ in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_returns',\
      \ 'text': 'Returns from `{method_name}` in Python file: `{filename}`?', 'type':\
      \ 'method'}, {'id': 'file_purpose', 'text': '1) Describe the Purpose and Processing\
      \ summary of Python file: `{filename}`; 2) Summarize the Significance of applicable\
      \ Function, Class, and Method; 3) Explain what each Input, Output, and Variable\
      \ does in the code.', 'type': 'file'}]\n    return questions"
    function_docstring: "Return default question list\n    Args:\n        None\n \
      \   Returns:\n        List[Dict]: The default question list\n    "
    function_inputs: []
    function_defaults: []
    function_returns:
    - questions
    function_calls: []
    function_call_inputs: {}
    function_variables:
    - questions
    function_decorators: []
    function_annotations: []
    function_properties: []
  get_default_model_config:
    function_name: get_default_model_config
    function_code: "def get_default_model_config() -> Dict:\n    \"\"\"Return default\
      \ model config dict\n    Args:\n        None\n    Returns:\n        Dict: The\
      \ default model config dictionary\n    \"\"\"\n    model_config = {'system_prompt':\
      \ \"Provide complete structured response for a formal software audit, given\
      \ this Context:\\n'{context}'\\n\", 'instruction_prompt': '\\nPlease provide\
      \ a very detailed, accurate, and insightful Response to this Instruction and\
      \ include your reasoning step by step.\\n{query}\\n', 'prompt_template': '{system_prompt}\
      \ ### Instruction: {instruction_prompt} ### Response: ', 'inference_model':\
      \ {'model_import_path': 'ctransformers.AutoModelForCausalLM', 'model_inference_function':\
      \ 'from_pretrained', 'model_params': {'model_path': 'TheBloke/WizardCoder-Python-13B-V1.0-GGUF',\
      \ 'model_file': 'wizardcoder-python-13b-v1.0.Q5_K_S.gguf', 'model_type': 'llama',\
      \ 'local_files_only': False, 'threads': 16, 'batch_size': 128, 'context_length':\
      \ 12000, 'max_new_tokens': 12000, 'gpu_layers': 100, 'reset': True}}}\n    return\
      \ model_config"
    function_docstring: "Return default model config dict\n    Args:\n        None\n\
      \    Returns:\n        Dict: The default model config dictionary\n    "
    function_inputs: []
    function_defaults: []
    function_returns:
    - model_config
    function_calls: []
    function_call_inputs: {}
    function_variables:
    - model_config
    function_decorators: []
    function_annotations: []
    function_properties: []
  get_start_dir:
    function_name: get_start_dir
    function_code: "def get_start_dir(start_dir: str='') -> str:\n    \"\"\"\n   \
      \ Returns the appropriate start directory.\n    Args:\n        start_dir (str):\
      \ The directory to start the search from.\n    Returns:\n        str: The absolute\
      \ path of the provided start_dir if it exists or can be created.\n    \"\"\"\
      \n    if start_dir and (not Path(start_dir).is_dir()):\n        logging.info(f'Setting\
      \ Start Dir : {start_dir}')\n        start_dir = os.getcwd()\n    else:\n  \
      \      start_dir = os.path.abspath(start_dir)\n    return start_dir"
    function_docstring: "\n    Returns the appropriate start directory.\n    Args:\n\
      \        start_dir (str): The directory to start the search from.\n    Returns:\n\
      \        str: The absolute path of the provided start_dir if it exists or can\
      \ be created.\n    "
    function_inputs:
    - start_dir
    function_defaults:
    - ''''''
    function_returns:
    - start_dir
    function_calls:
    - Path(start_dir).is_dir
    - Path
    - logging.info
    - os.getcwd
    - os.path.abspath
    function_call_inputs:
      Path(start_dir).is_dir: []
      Path:
      - start_dir
      logging.info:
      - 'f''Setting Start Dir : {start_dir}'''
      os.getcwd: []
      os.path.abspath:
      - start_dir
    function_variables:
    - start_dir
    function_decorators: []
    function_annotations: []
    function_properties: []
  get_output_dir:
    function_name: get_output_dir
    function_code: "def get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns\
      \ the appropriate output directory.\n    Args:\n        output_dir (str): The\
      \ directory to write the output to.\n    Returns:\n        str: The absolute\
      \ path of the provided output_dir if it exists or can be created.\n    \"\"\"\
      \n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir,\
      \ exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n\
      \    return output_dir"
    function_docstring: "Returns the appropriate output directory.\n    Args:\n  \
      \      output_dir (str): The directory to write the output to.\n    Returns:\n\
      \        str: The absolute path of the provided output_dir if it exists or can\
      \ be created.\n    "
    function_inputs:
    - output_dir
    function_defaults:
    - ''''''
    function_returns:
    - output_dir
    function_calls:
    - os.path.abspath
    - os.makedirs
    - logging.info
    function_call_inputs:
      os.path.abspath:
      - output_dir or OUTPUT_DIR
      os.makedirs:
      - output_dir
      logging.info:
      - 'f''Using output directory: {output_dir}'''
    function_variables:
    - output_dir
    function_decorators: []
    function_annotations: []
    function_properties: []
  get_questions:
    function_name: get_questions
    function_code: "def get_questions(questions_pathname: str) -> List[Dict]:\n  \
      \  \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname\
      \ (str): The pathname of the questions file\n    Returns:\n        List[Dict]:\
      \ The list of questions\n    \"\"\"\n    try:\n        if not questions_pathname:\n\
      \            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n\
      \        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n\
      \        logging.info(f'Using questions from file: {questions_pathname}')\n\
      \    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions\
      \ file not valid: {questions_pathname} Using default questions')\n        questions\
      \ = get_default_questions()\n    return questions"
    function_docstring: "\n    Get questions from file or default\n    Args:\n   \
      \     questions_pathname (str): The pathname of the questions file\n    Returns:\n\
      \        List[Dict]: The list of questions\n    "
    function_inputs:
    - questions_pathname
    function_defaults: []
    function_returns:
    - questions
    function_calls:
    - os.path.join
    - os.getcwd
    - open
    - json.load
    - logging.info
    - get_default_questions
    function_call_inputs:
      os.path.join:
      - os.getcwd()
      - QUESTIONS_FILE
      os.getcwd: []
      open:
      - questions_pathname
      - '''r'''
      json.load:
      - f
      logging.info:
      - 'f''Using questions from file: {questions_pathname}'''
      - 'f''Questions file not valid: {questions_pathname} Using default questions'''
      get_default_questions: []
    function_variables:
    - questions_pathname
    - questions
    function_decorators: []
    function_annotations: []
    function_properties: []
  instantiate_model:
    function_name: instantiate_model
    function_code: "def instantiate_model(model_config: Dict) -> object:\n    \"\"\
      \"\n    Imports and instantiates a model based on the provided configuration.\n\
      \    Args:\n        model_config (dict): model configuration dictionary.\n \
      \   Returns:\n        object: An instance of the specified model class, or None\
      \ if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.',\
      \ 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n\
      \        model_params = model_config['model_params']\n        inference_function_name\
      \ = model_config['model_inference_function']\n        if inference_function_name\
      \ != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n\
      \            llm = inference_function(model_params.pop('model_path'), **model_params)\n\
      \        else:\n            llm = ModelClass(model_params.pop('model_path'),\
      \ **model_params)\n        return llm\n    except (ImportError, AttributeError,\
      \ Exception) as e:\n        logging.info(f'Failed to instantiate the model.\
      \ Error: {e}')\n        return None"
    function_docstring: "\n    Imports and instantiates a model based on the provided\
      \ configuration.\n    Args:\n        model_config (dict): model configuration\
      \ dictionary.\n    Returns:\n        object: An instance of the specified model\
      \ class, or None if error.\n    "
    function_inputs:
    - model_config
    function_defaults: []
    function_returns:
    - llm
    - None
    function_calls:
    - model_config['model_import_path'].rsplit
    - getattr
    - importlib.import_module
    - inference_function
    - model_params.pop
    - ModelClass
    - logging.info
    function_call_inputs:
      model_config['model_import_path'].rsplit:
      - '''.'''
      - '1'
      getattr:
      - importlib.import_module(module_name)
      - class_name
      - ModelClass
      - inference_function_name
      importlib.import_module:
      - module_name
      inference_function:
      - model_params.pop('model_path')
      model_params.pop:
      - '''model_path'''
      - '''model_path'''
      ModelClass:
      - model_params.pop('model_path')
      logging.info:
      - 'f''Failed to instantiate the model. Error: {e}'''
    function_variables:
    - model_config
    - ModelClass
    - inference_function
    - inference_function_name
    - llm
    - model_params
    function_decorators: []
    function_annotations: []
    function_properties: []
  get_model:
    function_name: get_model
    function_code: "def get_model(model_config_pathname: str) -> object:\n    \"\"\
      \"\n    Returns an instantiated model and prompt template based on the model\
      \ configuration.\n    Agrs:\n        model_config_pathname (str): The pathname\
      \ of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated\
      \ model\n    \"\"\"\n    try:\n        if not model_config_pathname:\n     \
      \       model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n\
      \        with open(model_config_pathname, 'r') as config_file:\n           \
      \ model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model\
      \ config from file: {model_config_pathname}')\n    except (FileNotFoundError,\
      \ yaml.YAMLError):\n        logging.info(f'Model config file not valid: {model_config_pathname}\
      \ Using default model config')\n        model_config = get_default_model_config()\n\
      \    model_config['model'] = instantiate_model(model_config['inference_model'])\n\
      \    return model_config"
    function_docstring: "\n    Returns an instantiated model and prompt template based\
      \ on the model configuration.\n    Agrs:\n        model_config_pathname (str):\
      \ The pathname of the model config file\n    Returns:\n        Tuple[object,\
      \ str]: The instantiated model\n    "
    function_inputs:
    - model_config_pathname
    function_defaults: []
    function_returns:
    - model_config
    function_calls:
    - os.path.join
    - os.getcwd
    - open
    - yaml.safe_load
    - logging.info
    - get_default_model_config
    - instantiate_model
    function_call_inputs:
      os.path.join:
      - os.getcwd()
      - MODEL_CONFIG_FILE
      os.getcwd: []
      open:
      - model_config_pathname
      - '''r'''
      yaml.safe_load:
      - config_file
      logging.info:
      - 'f''Using model config from file: {model_config_pathname}'''
      - 'f''Model config file not valid: {model_config_pathname} Using default model
        config'''
      get_default_model_config: []
      instantiate_model:
      - model_config['inference_model']
    function_variables:
    - model_config
    - model_config_pathname
    function_decorators: []
    function_annotations: []
    function_properties: []
  write_questions_file:
    function_name: write_questions_file
    function_code: "def write_questions_file(output_dir: str='') -> None:\n    \"\"\
      \"\n    Writes the default questions to a file in JSON format.\n    Args:\n\
      \        output_dir (str): The directory to write the questions file to.\n \
      \   Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n\
      \    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else\
      \ os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w')\
      \ as file:\n        json.dump(questions, file, indent=4)"
    function_docstring: "\n    Writes the default questions to a file in JSON format.\n\
      \    Args:\n        output_dir (str): The directory to write the questions file\
      \ to.\n    Returns:\n        None\n    "
    function_inputs:
    - output_dir
    function_defaults:
    - ''''''
    function_returns: []
    function_calls:
    - get_default_questions
    - Path(output_dir).is_dir
    - Path
    - os.getcwd
    - open
    - os.path.join
    - json.dump
    function_call_inputs:
      get_default_questions: []
      Path(output_dir).is_dir: []
      Path:
      - output_dir
      os.getcwd: []
      open:
      - os.path.join(output_dir, QUESTIONS_FILE)
      - '''w'''
      os.path.join:
      - output_dir
      - QUESTIONS_FILE
      json.dump:
      - questions
      - file
    function_variables:
    - output_dir
    - questions
    function_decorators: []
    function_annotations: []
    function_properties: []
  write_model_config_file:
    function_name: write_model_config_file
    function_code: "def write_model_config_file(output_dir: str='') -> None:\n   \
      \ \"\"\"\n    Writes the default model config to a file in YAML format.\n  \
      \  Args:\n        output_dir (str): The directory to write the model config\
      \ file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n\
      \    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else\
      \ os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w')\
      \ as file:\n        yaml.dump(model_config, file)"
    function_docstring: "\n    Writes the default model config to a file in YAML format.\n\
      \    Args:\n        output_dir (str): The directory to write the model config\
      \ file to.\n    Returns:\n        None\n    "
    function_inputs:
    - output_dir
    function_defaults:
    - ''''''
    function_returns: []
    function_calls:
    - get_default_model_config
    - Path(output_dir).is_dir
    - Path
    - os.getcwd
    - open
    - os.path.join
    - yaml.dump
    function_call_inputs:
      get_default_model_config: []
      Path(output_dir).is_dir: []
      Path:
      - output_dir
      os.getcwd: []
      open:
      - os.path.join(output_dir, MODEL_CONFIG_FILE)
      - '''w'''
      os.path.join:
      - output_dir
      - MODEL_CONFIG_FILE
      yaml.dump:
      - model_config
      - file
    function_variables:
    - output_dir
    - model_config
    function_decorators: []
    function_annotations: []
    function_properties: []
classes: {}
