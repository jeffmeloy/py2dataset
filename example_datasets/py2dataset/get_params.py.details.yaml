file_info:
    file_code: "\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport importlib\nfrom typing import Dict, List\nfrom pathlib import Path\nimport yaml\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\n# defaults if provided inputs fail\nQUESTIONS_FILE = \"py2dataset_questions.json\"\nMODEL_CONFIG_FILE = \"py2dataset_model_config.yaml\"\nOUTPUT_DIR = \"datasets\"\n\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"Dependencies in Python file: `{filename}`?\",\n            \"type\": \"file\",\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"Call code graph in Python file: `{filename}`?\",\n            \"type\": \"file\",\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"Functions in Python file: `{filename}`?\",\n            \"type\": \"file\",\n        },\n        {\n            \"id\": \"file_classes\",\n            \"text\": \"Classes in Python file: `{filename}`?\",\n            \"type\": \"file\",\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"Inputs to `{function_name}` in Python file: `{filename}`?\",\n            \"type\": \"function\",\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"Docstring of `{function_name}` in Python file: `{filename}`?\",\n            \"type\": \"function\",\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"Calls made in `{function_name}` in Python file: `{filename}`?\",\n            \"type\": \"function\",\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"Variables in `{function_name}` in Python file: `{filename}`?\",\n            \"type\": \"function\",\n        },\n        {\n            \"id\": \"function_returns\",\n            \"text\": \"Returns from `{function_name}` in Python file: `{filename}`?\",\n            \"type\": \"function\",\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"Methods in `{class_name}` in Python file: `{filename}`?\",\n            \"type\": \"class\",\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"Docstring of `{class_name}` in Python file: `{filename}`?\",\n            \"type\": \"class\",\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"Attributes of `{class_name}` in Python file: `{filename}`?\",\n            \"type\": \"class\",\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"Inheritance of `{class_name}` in Python file: `{filename}`?\",\n            \"type\": \"class\",\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"Inputs to `{method_name}` in Python file: `{filename}`?\",\n            \"type\": \"method\",\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"Docstring of `{method_name}` in Python file: `{filename}`?\",\n            \"type\": \"method\",\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"Calls made in `{method_name}` in Python file: `{filename}`?\",\n            \"type\": \"method\",\n        },\n        {\n            \"id\": \"method_variables\",\n            \"text\": \"Variables in `{method_name}` in Python file: `{filename}`?\",\n            \"type\": \"method\",\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"Returns from `{method_name}` in Python file: `{filename}`?\",\n            \"type\": \"method\",\n        },\n        {\n            \"id\": \"file_purpose\",\n            \"text\": \"I) Describe the Purpose and Processing Approach for Python file: `{filename}`; II) Define detailed Requirements and API Signatures for all Functions and Class Methods and explain their logic and purpose of the inputs, outputs, variables, returns, and calls.\",\n            \"type\": \"file\",\n        },\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"system_prompt\": \"Lang: English. Output Format: unformatted, outline. Task: Create software documentation for an advanced computer science course using this code Context:\\n'{context}'\\n\",\n        \"instruction_prompt\": \"Analyze Context to comprehensively describe the purpose and functions of these objects:\\n'{code_objects}'\\n to comply with this instruction:\\n'{query}'\\n\", \n        \"prompt_template\": \"system:\\n{system_prompt}\\n\\ninstruction:n{instruction_prompt}\\n\\ndocumentation:\\n\", \n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"jeffmeloy/WestLake-7B-v2.Q8_0.gguf\",\n                \"model_type\": \"mistral\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (params set for model with this HW: GPU: 4090-24GB VRAM, CPU: 5950x-64GB RAM)\n                # avx2 and gpu_layers are not compatible\n                # \"lib\": \"avx2\",\n                \"threads\": 16,\n                \"batch_size\": 512,\n                \"context_length\": 28000,\n                \"max_new_tokens\": 16000,\n                \"gpu_layers\": 100,\n                \"reset\": True,\n            },\n        },\n    }\n    return model_config\n\n\ndef get_start_dir(start_dir: str = \"\") -> str:\n    \"\"\"\n    Returns the appropriate start directory.\n    Args:\n        start_dir (str): The directory to start the search from.\n    Returns:\n        str: The absolute path of the provided start_dir if it exists or can be created.\n    \"\"\"\n    if start_dir and not Path(start_dir).is_dir():\n        logging.info(f\"Setting Start Dir : {start_dir}\")\n        start_dir = os.getcwd()\n    else:\n        start_dir = os.path.abspath(start_dir)\n    return start_dir\n\n\ndef get_output_dir(output_dir: str = \"\") -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f\"Using output directory: {output_dir}\")\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try:  # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, \"r\") as f:\n            questions = json.load(f)\n        logging.info(f\"Using questions from file: {questions_pathname}\")\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(\n            f\"Questions file not valid: {questions_pathname} Using default questions\"\n        )\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config[\"model_import_path\"].rsplit(\".\", 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config[\"model_params\"]\n        inference_function_name = model_config[\"model_inference_function\"]\n        if inference_function_name != \"\":\n            inference_function = getattr(ModelClass, inference_function_name)\n            llm = inference_function(model_params.pop(\"model_path\"), **model_params)\n        else:\n            llm = ModelClass(model_params.pop(\"model_path\"), **model_params)\n        return llm\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")\n        return None\n\n\ndef get_model(model_config_pathname: str) -> object:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model\n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, \"r\") as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f\"Using model config from file: {model_config_pathname}\")\n    except (FileNotFoundError, yaml.YAMLError):\n        logging.info(\n            f\"Model config file not valid: {model_config_pathname} Using default model config\"\n        )\n        model_config = get_default_model_config()\n    model_config[\"model\"] = instantiate_model(model_config[\"inference_model\"])\n\n    return model_config\n\n\ndef write_questions_file(output_dir: str = \"\") -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), \"w\") as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str = \"\") -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), \"w\") as file:\n        yaml.dump(model_config, file)\n"
    file_dependencies:
    - typing
    - pathlib
    - os
    - json
    - importlib
    - yaml
    - logging
    file_functions:
    - get_default_questions
    - get_default_model_config
    - get_start_dir
    - get_output_dir
    - get_questions
    - instantiate_model
    - get_model
    - write_questions_file
    - write_model_config_file
    file_classes: []
    file_constants:
    - QUESTIONS_FILE='py2dataset_questions.json'
    - MODEL_CONFIG_FILE='py2dataset_model_config.yaml'
    - OUTPUT_DIR='datasets'
    file_summary: '{dependencies: [typing, pathlib, os, json, importlib, yaml, logging], function_defs: [{get_default_questions: {inputs: [], calls: [], call_inputs: {}, returns: [questions]}}, {get_default_model_config: {inputs: [], calls: [], call_inputs: {}, returns: [model_config]}}, {get_start_dir: {inputs: [start_dir], calls: [Path(start_dir).is_dir, Path, logging.info, os.getcwd, os.path.abspath], call_inputs: {Path(start_dir).is_dir: [], Path: [start_dir], logging.info: [f''Setting Start Dir : {start_dir}''], os.getcwd: [], os.path.abspath: [start_dir]}, returns: [start_dir]}}, {get_output_dir: {inputs: [output_dir], calls: [os.path.abspath, os.makedirs, logging.info], call_inputs: {os.path.abspath: [output_dir or OUTPUT_DIR], os.makedirs: [output_dir], logging.info: [f''Using output directory: {output_dir}'']}, returns: [output_dir]}}, {get_questions: {inputs: [questions_pathname], calls: [os.path.join, os.getcwd, open, json.load, logging.info, get_default_questions], call_inputs: {os.path.join: [os.getcwd(), QUESTIONS_FILE], os.getcwd: [], open: [questions_pathname, ''r''], json.load: [f], logging.info: [f''Using questions from file: {questions_pathname}'', f''Questions file not valid: {questions_pathname} Using default questions''], get_default_questions: []}, returns: [questions]}}, {instantiate_model: {inputs: [model_config], calls: [model_config[''model_import_path''].rsplit, getattr, importlib.import_module, inference_function, model_params.pop, ModelClass, logging.info], call_inputs: {model_config[''model_import_path''].rsplit: [''.'', 1], getattr: [importlib.import_module(module_name), class_name, ModelClass, inference_function_name], importlib.import_module: [module_name], inference_function: [model_params.pop(''model_path'')], model_params.pop: [''model_path'', ''model_path''], ModelClass: [model_params.pop(''model_path'')], logging.info: [f''Failed to instantiate the model. Error: {e}'']}, returns: [llm, None]}}, {get_model: {inputs: [model_config_pathname], calls: [os.path.join, os.getcwd, open, yaml.safe_load, logging.info, get_default_model_config, instantiate_model], call_inputs: {os.path.join: [os.getcwd(), MODEL_CONFIG_FILE], os.getcwd: [], open: [model_config_pathname, ''r''], yaml.safe_load: [config_file], logging.info: [f''Using model config from file: {model_config_pathname}'', f''Model config file not valid: {model_config_pathname} Using default model config''], get_default_model_config: [], instantiate_model: [model_config[''inference_model'']]}, returns: [model_config]}}, {write_questions_file: {inputs: [output_dir], calls: [get_default_questions, Path(output_dir).is_dir, Path, os.getcwd, open, os.path.join, json.dump], call_inputs: {get_default_questions: [], Path(output_dir).is_dir: [], Path: [output_dir], os.getcwd: [], open: [os.path.join(output_dir, QUESTIONS_FILE), ''w''], os.path.join: [output_dir, QUESTIONS_FILE], json.dump: [questions, file]}, returns: []}}, {write_model_config_file: {inputs: [output_dir], calls: [get_default_model_config, Path(output_dir).is_dir, Path, os.getcwd, open, os.path.join, yaml.dump], call_inputs: {get_default_model_config: [], Path(output_dir).is_dir: [], Path: [output_dir], os.getcwd: [], open: [os.path.join(output_dir, MODEL_CONFIG_FILE), ''w''], os.path.join: [output_dir, MODEL_CONFIG_FILE], yaml.dump: [model_config, file]}, returns: []}}], class_defs: []}'
    file_code_simplified: "import os\nimport json\nimport logging\nimport importlib\nfrom typing import Dict, List\nfrom pathlib import Path\nimport yaml\nlogging.basicConfig(level=logging.INFO)\nQUESTIONS_FILE = 'py2dataset_questions.json'\nMODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'\nOUTPUT_DIR = 'datasets'\n\ndef get_default_questions() -> List[Dict]:\n    questions = [{'id': 'file_dependencies', 'text': 'Dependencies in Python file: `{filename}`?', 'type': 'file'}, {'id': 'entire_code_graph', 'text': 'Call code graph in Python file: `{filename}`?', 'type': 'file'}, {'id': 'file_functions', 'text': 'Functions in Python file: `{filename}`?', 'type': 'file'}, {'id': 'file_classes', 'text': 'Classes in Python file: `{filename}`?', 'type': 'file'}, {'id': 'function_inputs', 'text': 'Inputs to `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_docstring', 'text': 'Docstring of `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_calls', 'text': 'Calls made in `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_variables', 'text': 'Variables in `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_returns', 'text': 'Returns from `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'class_methods', 'text': 'Methods in `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id': 'class_docstring', 'text': 'Docstring of `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id': 'class_attributes', 'text': 'Attributes of `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id': 'class_inheritance', 'text': 'Inheritance of `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id': 'method_inputs', 'text': 'Inputs to `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_docstring', 'text': 'Docstring of `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_calls', 'text': 'Calls made in `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_variables', 'text': 'Variables in `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_returns', 'text': 'Returns from `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'file_purpose', 'text': 'I) Describe the Purpose and Processing Approach for Python file: `{filename}`; II) Define detailed Requirements and API Signatures for all Functions and Class Methods and explain their logic and purpose of the inputs, outputs, variables, returns, and calls.', 'type': 'file'}]\n    return questions\n\ndef get_default_model_config() -> Dict:\n    model_config = {'system_prompt': \"Lang: English. Output Format: unformatted, outline. Task: Create software documentation for an advanced computer science course using this code Context:\\n'{context}'\\n\", 'instruction_prompt': \"Analyze Context to comprehensively describe the purpose and functions of these objects:\\n'{code_objects}'\\n to comply with this instruction:\\n'{query}'\\n\", 'prompt_template': 'system:\\n{system_prompt}\\n\\ninstruction:n{instruction_prompt}\\n\\ndocumentation:\\n', 'inference_model': {'model_import_path': 'ctransformers.AutoModelForCausalLM', 'model_inference_function': 'from_pretrained', 'model_params': {'model_path': 'jeffmeloy/WestLake-7B-v2.Q8_0.gguf', 'model_type': 'mistral', 'local_files_only': False, 'threads': 16, 'batch_size': 512, 'context_length': 28000, 'max_new_tokens': 16000, 'gpu_layers': 100, 'reset': True}}}\n    return model_config\n\ndef get_start_dir(start_dir: str='') -> str:\n    if start_dir and (not Path(start_dir).is_dir()):\n        logging.info(f'Setting Start Dir : {start_dir}')\n        start_dir = os.getcwd()\n    else:\n        start_dir = os.path.abspath(start_dir)\n    return start_dir\n\ndef get_output_dir(output_dir: str='') -> str:\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    try:\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions\n\ndef instantiate_model(model_config: Dict) -> object:\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n            llm = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            llm = ModelClass(model_params.pop('model_path'), **model_params)\n        return llm\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f'Failed to instantiate the model. Error: {e}')\n        return None\n\ndef get_model(model_config_pathname: str) -> object:\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except (FileNotFoundError, yaml.YAMLError):\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    model_config['model'] = instantiate_model(model_config['inference_model'])\n    return model_config\n\ndef write_questions_file(output_dir: str='') -> None:\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)\n\ndef write_model_config_file(output_dir: str='') -> None:\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)"
    entire_code_graph:
        nodes:
        - get_default_questions
        - get_default_model_config
        - get_start_dir
        - get_output_dir
        - get_questions
        - instantiate_model
        - get_model
        - write_questions_file
        - write_model_config_file
        - Path(start_dir).is_dir
        - Path
        - logging.info
        - os.getcwd
        - os.path.abspath
        - os.makedirs
        - os.path.join
        - open
        - json.load
        - model_config['model_import_path'].rsplit
        - getattr
        - importlib.import_module
        - inference_function
        - model_params.pop
        - ModelClass
        - yaml.safe_load
        - Path(output_dir).is_dir
        - json.dump
        - yaml.dump
        edges:
        -   source: get_start_dir
            target: Path(start_dir).is_dir
            target_inputs: []
        -   source: get_start_dir
            target: Path
            target_inputs:
            - start_dir
        -   source: get_start_dir
            target: logging.info
            target_inputs:
            - 'f''Setting Start Dir : {start_dir}'''
        -   source: get_start_dir
            target: os.getcwd
            target_inputs: []
        -   source: get_start_dir
            target: os.path.abspath
            target_inputs:
            - start_dir
        -   source: get_output_dir
            target: os.path.abspath
            target_inputs:
            - output_dir or OUTPUT_DIR
        -   source: get_output_dir
            target: os.makedirs
            target_inputs:
            - output_dir
        -   source: get_output_dir
            target: logging.info
            target_inputs:
            - 'f''Using output directory: {output_dir}'''
        -   source: get_questions
            target: os.path.join
            target_inputs:
            - os.getcwd()
            - QUESTIONS_FILE
        -   source: get_questions
            target: os.getcwd
            target_inputs: []
        -   source: get_questions
            target: open
            target_inputs:
            - questions_pathname
            - '''r'''
        -   source: get_questions
            target: json.load
            target_inputs:
            - f
        -   source: get_questions
            target: logging.info
            target_inputs:
            - 'f''Using questions from file: {questions_pathname}'''
            - 'f''Questions file not valid: {questions_pathname} Using default questions'''
        -   source: get_questions
            target: get_default_questions
            target_inputs: []
            target_returns:
            - questions
        -   source: instantiate_model
            target: model_config['model_import_path'].rsplit
            target_inputs:
            - '''.'''
            - '1'
        -   source: instantiate_model
            target: getattr
            target_inputs:
            - importlib.import_module(module_name)
            - class_name
            - ModelClass
            - inference_function_name
        -   source: instantiate_model
            target: importlib.import_module
            target_inputs:
            - module_name
        -   source: instantiate_model
            target: inference_function
            target_inputs:
            - model_params.pop('model_path')
        -   source: instantiate_model
            target: model_params.pop
            target_inputs:
            - '''model_path'''
            - '''model_path'''
        -   source: instantiate_model
            target: ModelClass
            target_inputs:
            - model_params.pop('model_path')
        -   source: instantiate_model
            target: logging.info
            target_inputs:
            - 'f''Failed to instantiate the model. Error: {e}'''
        -   source: get_model
            target: os.path.join
            target_inputs:
            - os.getcwd()
            - MODEL_CONFIG_FILE
        -   source: get_model
            target: os.getcwd
            target_inputs: []
        -   source: get_model
            target: open
            target_inputs:
            - model_config_pathname
            - '''r'''
        -   source: get_model
            target: yaml.safe_load
            target_inputs:
            - config_file
        -   source: get_model
            target: logging.info
            target_inputs:
            - 'f''Using model config from file: {model_config_pathname}'''
            - 'f''Model config file not valid: {model_config_pathname} Using default model config'''
        -   source: get_model
            target: get_default_model_config
            target_inputs: []
            target_returns:
            - model_config
        -   source: get_model
            target: instantiate_model
            target_inputs:
            - model_config['inference_model']
            target_returns:
            - None
            - llm
        -   source: write_questions_file
            target: get_default_questions
            target_inputs: []
            target_returns:
            - questions
        -   source: write_questions_file
            target: Path(output_dir).is_dir
            target_inputs: []
        -   source: write_questions_file
            target: Path
            target_inputs:
            - output_dir
        -   source: write_questions_file
            target: os.getcwd
            target_inputs: []
        -   source: write_questions_file
            target: open
            target_inputs:
            - os.path.join(output_dir, QUESTIONS_FILE)
            - '''w'''
        -   source: write_questions_file
            target: os.path.join
            target_inputs:
            - output_dir
            - QUESTIONS_FILE
        -   source: write_questions_file
            target: json.dump
            target_inputs:
            - questions
            - file
        -   source: write_model_config_file
            target: get_default_model_config
            target_inputs: []
            target_returns:
            - model_config
        -   source: write_model_config_file
            target: Path(output_dir).is_dir
            target_inputs: []
        -   source: write_model_config_file
            target: Path
            target_inputs:
            - output_dir
        -   source: write_model_config_file
            target: os.getcwd
            target_inputs: []
        -   source: write_model_config_file
            target: open
            target_inputs:
            - os.path.join(output_dir, MODEL_CONFIG_FILE)
            - '''w'''
        -   source: write_model_config_file
            target: os.path.join
            target_inputs:
            - output_dir
            - MODEL_CONFIG_FILE
        -   source: write_model_config_file
            target: yaml.dump
            target_inputs:
            - model_config
            - file
    control_flow_structure:
    -   'def get_start_dir(start_dir: str)':
        -   if start_dir and (not Path(start_dir).is_dir()):
            - 'logging.info(f''Setting Start Dir : {start_dir}'')'
            - start_dir = os.getcwd()
            else:
            - start_dir = os.path.abspath(start_dir)
        -   return:
            - start_dir
    -   'def get_output_dir(output_dir: str)':
        - output_dir = os.path.abspath(output_dir or OUTPUT_DIR)
        - os.makedirs(output_dir, exist_ok=True)
        - 'logging.info(f''Using output directory: {output_dir}'')'
        -   return:
            - output_dir
    -   'def get_questions(questions_pathname: str)':
        -   try:
            -   if not questions_pathname:
                - questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)
            -   with open(questions_pathname, 'r') as f:
                - questions = json.load(f)
            - 'logging.info(f''Using questions from file: {questions_pathname}'')'
            except:
            -   'except (FileNotFoundError, json.decoder.JSONDecodeError) as :':
                - 'logging.info(f''Questions file not valid: {questions_pathname} Using default questions'')'
                - questions = get_default_questions()
        -   return:
            - questions
    -   'def get_model(model_config_pathname: str)':
        -   try:
            -   if not model_config_pathname:
                - model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)
            -   with open(model_config_pathname, 'r') as config_file:
                - model_config = yaml.safe_load(config_file)
            - 'logging.info(f''Using model config from file: {model_config_pathname}'')'
            except:
            -   'except (FileNotFoundError, yaml.YAMLError) as :':
                - 'logging.info(f''Model config file not valid: {model_config_pathname} Using default model config'')'
                - model_config = get_default_model_config()
        - model_config['model'] = instantiate_model(model_config['inference_model'])
        -   return:
            - model_config
    -   'def write_questions_file(output_dir: str)':
        - questions = get_default_questions()
        - output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()
        -   with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:
            - json.dump(questions, file, indent=4)
    -   'def write_model_config_file(output_dir: str)':
        - model_config = get_default_model_config()
        - output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()
        -   with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:
            - yaml.dump(model_config, file)
    - import os
    - import json
    - import logging
    - import importlib
    - from typing import Dict, List
    - from pathlib import Path
    - import yaml
    - logging.basicConfig(level=logging.INFO)
    - QUESTIONS_FILE = 'py2dataset_questions.json'
    - MODEL_CONFIG_FILE = 'py2dataset_model_config.yaml'
    - OUTPUT_DIR = 'datasets'
    -   def get_default_questions():
        - 'questions = [{''id'': ''file_dependencies'', ''text'': ''Dependencies in Python file: `{filename}`?'', ''type'': ''file''}, {''id'': ''entire_code_graph'', ''text'': ''Call code graph in Python file: `{filename}`?'', ''type'': ''file''}, {''id'': ''file_functions'', ''text'': ''Functions in Python file: `{filename}`?'', ''type'': ''file''}, {''id'': ''file_classes'', ''text'': ''Classes in Python file: `{filename}`?'', ''type'': ''file''}, {''id'': ''function_inputs'', ''text'': ''Inputs to `{function_name}` in Python file: `{filename}`?'', ''type'': ''function''}, {''id'': ''function_docstring'', ''text'': ''Docstring of `{function_name}` in Python file: `{filename}`?'', ''type'': ''function''}, {''id'': ''function_calls'', ''text'': ''Calls made in `{function_name}` in Python file: `{filename}`?'', ''type'': ''function''}, {''id'': ''function_variables'', ''text'': ''Variables in `{function_name}` in Python file: `{filename}`?'', ''type'': ''function''}, {''id'': ''function_returns'', ''text'': ''Returns from `{function_name}` in Python file: `{filename}`?'', ''type'': ''function''}, {''id'': ''class_methods'', ''text'': ''Methods in `{class_name}` in Python file: `{filename}`?'', ''type'': ''class''}, {''id'': ''class_docstring'', ''text'': ''Docstring of `{class_name}` in Python file: `{filename}`?'', ''type'': ''class''}, {''id'': ''class_attributes'', ''text'': ''Attributes of `{class_name}` in Python file: `{filename}`?'', ''type'': ''class''}, {''id'': ''class_inheritance'', ''text'': ''Inheritance of `{class_name}` in Python file: `{filename}`?'', ''type'': ''class''}, {''id'': ''method_inputs'', ''text'': ''Inputs to `{method_name}` in Python file: `{filename}`?'', ''type'': ''method''}, {''id'': ''method_docstring'', ''text'': ''Docstring of `{method_name}` in Python file: `{filename}`?'', ''type'': ''method''}, {''id'': ''method_calls'', ''text'': ''Calls made in `{method_name}` in Python file: `{filename}`?'', ''type'': ''method''}, {''id'': ''method_variables'', ''text'': ''Variables in `{method_name}` in Python file: `{filename}`?'', ''type'': ''method''}, {''id'': ''method_returns'', ''text'': ''Returns from `{method_name}` in Python file: `{filename}`?'', ''type'': ''method''}, {''id'': ''file_purpose'', ''text'': ''I) Describe the Purpose and Processing Approach for Python file: `{filename}`; II) Define detailed Requirements and API Signatures for all Functions and Class Methods and explain their logic and purpose of the inputs, outputs, variables, returns, and calls.'', ''type'': ''file''}]'
        -   return:
            - questions
    -   def get_default_model_config():
        - 'model_config = {''system_prompt'': "Lang: English. Output Format: unformatted, outline. Task: Create software documentation for an advanced computer science course using this code Context:\n''{context}''\n", ''instruction_prompt'': "Analyze Context to comprehensively describe the purpose and functions of these objects:\n''{code_objects}''\n to comply with this instruction:\n''{query}''\n", ''prompt_template'': ''system:\n{system_prompt}\n\ninstruction:n{instruction_prompt}\n\ndocumentation:\n'', ''inference_model'': {''model_import_path'': ''ctransformers.AutoModelForCausalLM'', ''model_inference_function'': ''from_pretrained'', ''model_params'': {''model_path'': ''jeffmeloy/WestLake-7B-v2.Q8_0.gguf'', ''model_type'': ''mistral'', ''local_files_only'': False, ''threads'': 16, ''batch_size'': 512, ''context_length'': 28000, ''max_new_tokens'': 16000, ''gpu_layers'': 100, ''reset'': True}}}'
        -   return:
            - model_config
    -   'def instantiate_model(model_config: Dict)':
        -   try:
            - module_name, class_name = model_config['model_import_path'].rsplit('.', 1)
            - ModelClass = getattr(importlib.import_module(module_name), class_name)
            - model_params = model_config['model_params']
            - inference_function_name = model_config['model_inference_function']
            -   if inference_function_name != '':
                - inference_function = getattr(ModelClass, inference_function_name)
                - llm = inference_function(model_params.pop('model_path'), **model_params)
                else:
                - llm = ModelClass(model_params.pop('model_path'), **model_params)
            -   return:
                - llm
            except:
            -   'except (ImportError, AttributeError, Exception) as :':
                - 'logging.info(f''Failed to instantiate the model. Error: {e}'')'
                -   return:
                    - None
    plant_uml: "@startuml\n  : def get_start_dir(start_dir: str);\n      if (start_dir and (not Path(start_dir).is_dir())) then (yes)\n          : logging.info(f'Setting Start Dir : {start_dir}');\n          : start_dir = os.getcwd();\n      endif\n      : return;\n  : def get_output_dir(output_dir: str);\n      : output_dir = os.path.abspath(output_dir or OUTPUT_DIR);\n      : os.makedirs(output_dir, exist_ok=True);\n      : logging.info(f'Using output directory: {output_dir}');\n      : return;\n  : def get_questions(questions_pathname: str);\n      partition \"try\" {\n          if (not questions_pathname) then (yes)\n              : questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE);\n          endif\n          : with open(questions_pathname, 'r') as f;\n          : logging.info(f'Using questions from file: {questions_pathname}');\n      }\n      : return;\n  : def get_model(model_config_pathname: str);\n      partition \"try\" {\n          if (not model_config_pathname) then (yes)\n              : model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE);\n          endif\n          : with open(model_config_pathname, 'r') as config_file;\n          : logging.info(f'Using model config from file: {model_config_pathname}');\n      }\n      : model_config['model'] = instantiate_model(model_config['inference_model']);\n      : return;\n  : def write_questions_file(output_dir: str);\n      : questions = get_default_questions();\n      : output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd();\n      : with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file;\n  : def write_model_config_file(output_dir: str);\n      : model_config = get_default_model_config();\n      : output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd();\n      : with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file;\n  : import os;\n  : import json;\n  : import logging;\n  : import importlib;\n  : from typing import Dict, List;\n  : from pathlib import Path;\n  : import yaml;\n  : logging.basicConfig(level=logging.INFO);\n  : QUESTIONS_FILE = 'py2dataset_questions.json';\n  : MODEL_CONFIG_FILE = 'py2dataset_model_config.yaml';\n  : OUTPUT_DIR = 'datasets';\n  : def get_default_questions();\n      : questions = [{'id': 'file_dependencies', 'text': 'Dependencies in Python file: `{filename}`?', 'type': 'file'}, {'id': 'entire_code_graph', 'text': 'Call code graph in Python file: `{filename}`?', 'type': 'file'}, {'id': 'file_functions', 'text': 'Functions in Python file: `{filename}`?', 'type': 'file'}, {'id': 'file_classes', 'text': 'Classes in Python file: `{filename}`?', 'type': 'file'}, {'id': 'function_inputs', 'text': 'Inputs to `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_docstring', 'text': 'Docstring of `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_calls', 'text': 'Calls made in `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_variables', 'text': 'Variables in `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_returns', 'text': 'Returns from `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'class_methods', 'text': 'Methods in `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id': 'class_docstring', 'text': 'Docstring of `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id': 'class_attributes', 'text': 'Attributes of `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id': 'class_inheritance', 'text': 'Inheritance of `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id': 'method_inputs', 'text': 'Inputs to `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_docstring', 'text': 'Docstring of `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_calls', 'text': 'Calls made in `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_variables', 'text': 'Variables in `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_returns', 'text': 'Returns from `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'file_purpose', 'text': 'I) Describe the Purpose and Processing Approach for Python file: `{filename}`; II) Define detailed Requirements and API Signatures for all Functions and Class Methods and explain their logic and purpose of the inputs, outputs, variables, returns, and calls.', 'type': 'file'}];\n      : return;\n  : def get_default_model_config();\n      : model_config = {'system_prompt': \"Lang: English. Output Format: unformatted, outline. Task: Create software documentation for an advanced computer science course using this code Context:\\n'{context}'\\n\", 'instruction_prompt': \"Analyze Context to comprehensively describe the purpose and functions of these objects:\\n'{code_objects}'\\n to comply with this instruction:\\n'{query}'\\n\", 'prompt_template': 'system:\\n{system_prompt}\\n\\ninstruction:n{instruction_prompt}\\n\\ndocumentation:\\n', 'inference_model': {'model_import_path': 'ctransformers.AutoModelForCausalLM', 'model_inference_function': 'from_pretrained', 'model_params': {'model_path': 'jeffmeloy/WestLake-7B-v2.Q8_0.gguf', 'model_type': 'mistral', 'local_files_only': False, 'threads': 16, 'batch_size': 512, 'context_length': 28000, 'max_new_tokens': 16000, 'gpu_layers': 100, 'reset': True}}};\n      : return;\n  : def instantiate_model(model_config: Dict);\n      partition \"try\" {\n          : module_name, class_name = model_config['model_import_path'].rsplit('.', 1);\n          : ModelClass = getattr(importlib.import_module(module_name), class_name);\n          : model_params = model_config['model_params'];\n          : inference_function_name = model_config['model_inference_function'];\n          if (inference_function_name != '') then (yes)\n              : inference_function = getattr(ModelClass, inference_function_name);\n              : llm = inference_function(model_params.pop('model_path'), **model_params);\n          endif\n          : return;\n      }\nend\n@enduml"
    code_qa_response: "py2dataset/get_params.py:\n  Code Documentation:\n  - 'In this provided Python code, there are multiple utilitarian functions dedicated to managing input data parameters related to a dataset processing system called \"py2dataset.\" The key functionality offered can be organized around several distinct modules: question handling, model setup configuration, output directory handling, and file I/O operations for configuration saving.\n    1. Question Handling Functions:\n    a. `get_default_questions()` returns a list of default questions used by the system in JSON format. These questions serve as prompts for analyzing Python files or code snippets during documentation generation. Each question dictionary has 'id', 'text', and 'type' keys defining its unique identifier, textual content, and category (file, function, method, class).\n    b. `get_questions(questions_pathname)` attempts to fetch questions from a given file path if valid or uses default questions otherwise. It throws exceptions on invalid files or missing JSON format.\n    2. Model Setup Configuration Functions:\n    a. `get_default_model_config()` returns a dictionary representing the default configuration for the language model used in the system. This includes system and instruction prompts, as well as parameters for initializing an inference model from Hugging Face's Transformers library (\"ctransformers\"). The dictionary holds settings related to the language generation process.\n    b. `get_model(model_config_pathname)` fetches either default or custom model configuration depending on the provided file path validity. It instantiates a language model object using imported classes and specified parameters. If no config file is given, it uses defaults.\n    3. Output Directory Handling Functions:\n    a. `get_start_dir(start_dir)` returns an absolute directory path either from the provided input or current working directory (cwd). It creates the directory if necessary but logs information about this operation for user notification.\n    b. `get_output_dir(output_dir)` follows the same process but generates output files specifications specifically while guaranteeing path creation upon usage when specified directories do not exist yet.\n    4. File Input/Output Functions:\n    a. `write_questions_file(output_dir)` saves default questions as JSON formatted text into the given directory or current working directory if no output directory is provided or invalid. It uses `json.dump()`.\n    b. `write_model_config_file(output_dir)` writes default model configuration as YAML formatted content in specified output location, which again falls back to cwd otherwise. `yaml.dump()` ensures formatting appropriately for easy comprehension during program use.\n    These components facilitate retrieval or customization of analysis parameters as well as enabling language modeling outcomes aligned with described software development needs like context examination across a Python script analyzing various programming aspects while incorporating details of object relations such as file structure, function call relationships, return statements and overall documentation generation for advanced computer science courses.\n    '\n  Dependencies:\n    Value: typing, pathlib, os, json, importlib, yaml, logging\n    Purpose: \"System: Lang: English. Output Format: unformatted, outline. Task: Create software documentation for an advanced computer science course using this context regarding given dependencies in Python code\\n\\nDependencies Analysis for [typing, pathlib, os, json, importlib, yaml, logging] in the provided Python script 'py2dataset':\\n\\n1. typing:\\n   Purpose: Typing is a built-in Python library introduced in Python 3.5, primarily focusing on static type hinting to provide improved readability and error detection during development phases without imposing runtime checks. This package aids developers in declaring function parameter and return value types. In our script, it's not explicitly imported but utilized implicitly as part of standard library features when defining arguments for functions like `get_output_dir()` and `instantiate_model()`.\\n\\n2. pathlib:\\n   Purpose: Pathlib is a module added in Python 3.4 which offers objects representing file system paths independently of operating systems. It abstracts common tasks related to manipulating pathnames by converting string representations into Path objects equipped with several helpful methods like existence checks and manipulations without hard-coding OS dependent commands or calls (such as os.sep for platform separator). This module powers the creation of absolute paths and verification steps throughout code e.g., `Path(start_dir)`, `os.path.join()`.\\n\\n3. os:\\n   Purpose: Os is a core Python library providing a way to interact with underlying operating systems by exposing various functionalities such as process and file management, environment variables access or path manipulation methods (e.g., `os.getcwd()`, `os.path.abspath()`, `os.makedirs()`). It assists in handling directories creation/validation for output paths and retrieving current working directory in the script.\\n\\n4. json:\\n   Purpose: JSON (JavaScript Object Notation) is a lightweight data interchange format designed to exchange structured data between languages like Python efficiently. Python has native JSON support with built-in modules including `json`, utilized for encoding and decoding objects as text streamlines storage/retrieval of configuration files or question lists in our script (`json.load()`, `json.dump()`).\\n\\n5. importlib:\\n   Purpose: Importlib is a Python standard library that manages object-based imports facilitating advanced customizations for handling Python modules. In our script, it supports dynamically importing desired models using given strings extracted from model_config dictionaries through `getattr()`, `importlib.import_module()` functions within `instantiate_model()`.\\n\\n6. yaml:\\n   Purpose: YAML (Yet Another Markup Language) is a human-readable data serialization language commonly used for configuration files due to its simplicity and extensibility. The script leverages PyYAML implementation of YAML parser `yaml` module to load model configurations from YAML formatted files into Python dictionaries (`yaml.safe_load()`) in `get_model()`.\\n\\n7. logging:\\n   Purpose: Logging is a Python standard library providing facilities for capturing event messages with configurable output streams while distinguishing various logging levels like debug, info, warning, error etcetera depending upon system settings. Our script initializes logger with INFO level `logging.basicConfig()` allowing informational notes during execution processes e.g., \\\"Setting Start Dir\\\", \\\"Using questions from file\\\" which enhance code debugging/troubleshooting.\\n\\nThe code employs these dependencies to manage input parameters effectively, handle directories and files operations while ensuring seamless communication between different modules involved in dataset processing tasks such as question retrieval or model instantiation for generating software documentation related to Python scripts analysis.\"\n  Functions:\n    Value: get_default_questions, get_default_model_config, get_start_dir, get_output_dir, get_questions, instantiate_model, get_model, write_questions_file, write_model_config_file\n    Purpose: 'In the given context relating to a Python codebase named \"py2dataset,\" several significant functions are employed to manage data parameters, model setup configuration, handle output directories, and facilitate file I/O operations for config saving. Let's examine their roles one by one:\n      1. get_default_questions(): This function provides default question prompts that aid in analyzing Python files or code snippets while creating software documentation. Each question returned as a dictionary comprises three essential keys - id, text (actual prompt content), and type signifying the nature of data item (file, function, method, class).\n      2. get_default_model_config(): It returns a dictionary representing default settings for the language model utilized within the system. This configuration includes system and instruction prompts along with parameters to initialize an inference model from Hugging Face's Transformers library (\"ctransformers\"). The dictionary holds details crucial for initiating language generation processes.\n      3. get_start_dir(start_dir=\"\"): This function determines the starting directory either from the provided input or current working directory (cwd). If a new directory is needed, it creates one while logging information about this operation for user awareness.\n      4. get_output_dir(output_dir=\"\"): It generates output files' specifications especially related to datasets, guaranteeing path creation if non-existent when specified directories do not exist yet. The process resembles 'get_start_dir', but the outcome pertains specifically to dataset generation purposes.\n      5. get_questions(questions_pathname=\"\"): This function tries to retrieve questions from a user-supplied file path maintaining validity or reverts to default ones otherwise. It throws exceptions on invalid files or missing JSON format in input data.\n      6. instantiate_model(model_config): A key operation involving importing and instantiating a model based on the provided configuration dictionary. It leverages Python's importlib module to dynamically load the specified class from an imported module and returns the initialized language model object.\n      7. get_model(model_config_pathname=\"\"): This function fetches either default or custom model configurations depending upon the validity of a given file path. It instantiates a language model object using imported classes and specified parameters according to its config; defaults ensue when no particular file path is passed in argumentation.\n      8. write_questions_file(output_dir=\"\"): Serves for saving default question data into a JSON formatted text file within the given directory or current working directory if no output directory is provided or invalid. json.dump() ensures proper storage format for easy accessibility during program execution.\n      9. write_model_config_file(output_dir=\"\"): Writes default model configuration as YAML formatted content into specified output location, reverting to cwd otherwise. yaml.dump() guarantees appropriate structuring of data for user convenience when using the software further on.\n      In summary, these functions collaborate to manage input parameters related to dataset processing tasks such as question retrieval or customization, model setup configuration handling, output directory management, and file I/O operations concerning config saving - all working together towards generating comprehensive software documentation from Python code analysis perspectives.'\n  get_start_dir:\n    Inputs:\n      Value: start_dir\n      Purpose: 'In the given context focusing on \"get_start_dir\" function analysis, we need to describe its purpose, significance along with explaining individual inputs it accepts. The primary objective of get_start_dir is to determine and return an appropriate directory path either provided or created when invoked in the \"py2dataset\" codebase. It serves as a crucial step in ensuring correct data management while accessing required files for question lists and model configurations during program execution.\n        The \"get_start_dir(start_dir: str = '')\" function takes one input parameter named 'start_dir', which represents the directory to begin the search process for obtaining an absolute path. It can have a default empty string ('') indicating cwd (current working directory), making this call optional with no negative effects on functioning but adding custom location detail intentionally speeds up tracking required resources such as configuration files explicitly when they don't lie in default storage paths.\n        The function ensures the provided start_dir exists or creates it if necessary by using os.makedirs() with 'exist_ok=True'. This behavior guarantees smooth execution even if the directory doesn't exist initially but needs to be created for further operations like file reading/writing. Logging information about the chosen output directory helps developers track their settings within the program flow.\n        In summary, input 'start_dir' in get_start_dir facilitates user-specified path selection for locating question lists or model configurations before running the software or allowing fallback to default current working directory when explicit locations aren't supplied or unreachable due to invalidity. This flexibility enhances program adaptability according to user requirements while maintaining core functionality regardless of input validity.'\n    Calls:\n      Value: Path(start_dir).is_dir, Path, logging.info, os.getcwd, os.path.abspath\n      Purpose: 'In the context given focusing on analyzing calls within `get_start_dir`, we have five distinct functions being utilized for specific purposes. These include: Path(start_dir).is_dir, Path, logging.info, os.getcwd, and os.path.abspath. Each of these serves a unique role in ensuring proper directory handling and providing essential information within the get_start_dir function from the provided Python codebase.\n        1. Path(start_dir).is_dir: This call checks whether the given start_dir argument represents an existing directory path or not. It returns a Boolean value indicating its existence status, helping validate user inputs related to directories throughout the program execution. If not available initially as an actual folder but acceptable syntax for future path generation processes such as absolute resolution and creating needed hierarchies upon requirements - logging is carried out about updating the Start Dir value using the default Current Working Directory. This validation ensures a smooth functioning of subsequent operations relying on the directory's presence or creation.\n        2. Path: Python's built-in Path class simplifies handling file system paths across different operating systems by normalizing them and providing useful methods for manipulating paths. In this context, it might be indirectly involved when combining with other functions but not explicitly called as an individual operation within `get_start_dir`. However, its presence in the list highlights its relevance to directory management throughout the codebase.\n        3. logging.info: This call is related to Python's logging module used for outputting informational messages during runtime. In `get_start_dir`, it appears twice - once while setting the Start Dir with user input (if valid) and another when falling back on the Current Working Directory due to invalid path validation failure in question one. Logging helps developers track program behavior, understand decision-making processes better, and debug issues more efficiently by providing contextual information about specific events or conditions encountered during execution.\n        4. os.getcwd(): This function returns the current working directory of the Python process executing the codebase - essentially representing the folder where the script is currently running from. In `get_start_dir`, it serves as a fallback option when no valid start_dir argument is provided or fails validation due to non-existence or inability to create necessary directories. It ensures operations continue without breaking even if users miss out on specifying an explicit directory path initially.\n        5. os.path.abspath: This function converts a given relative or absolute file system pathname into an absolute path by resolving all symbolic links and removing any redundant separators ('.' or '..'). In `get_start_dir`, it's employed to acquire the absolute path of either provided start_dir or fallback current working directory if deemed appropriate based on existence checks conducted earlier. This allows uniform use throughout various portions requiring certain path affirmations like making parent folders with accurate absolute path notation instead of a partial filename input without definitive placement inside hierarchical system tree structure (absolute reference always removes uncertainties regarding the context location).'\n    Variables:\n      Value: start_dir\n      Purpose: 'In the given context focusing on the \"get_start_dir\" function within the Python code for the \"py2dataset\" software documentation system, two primary variables play significant roles. These variables are named \"start_dir\" and serve distinct purposes contributing to the overall functionality of this function.\n        1. start_dir (str): This variable represents an input argument provided by users when calling the get_start_dir() function. It denotes a directory path that acts as a starting point for searching or accessing files within the program's operations. If given, it specifies where to look for questions or model configuration files related to dataset processing. When no start_dir is supplied during function invocation, the code defaults to using the current working directory (cwd).\n        2. The combination of os.getcwd() and Path().is_dir() checks ensures proper handling of user inputs. If start_dir is present but does not correspond to an existing directory path or cannot be created for some reason, then get_start_dir() reverts back to the current working directory as a safer alternative. This feature provides flexibility while maintaining program stability by preventing potential errors due to invalid paths.\n        In summary, start_dir acts as an optional user input directing file searches within the get_start_dir function, allowing users to specify a custom location for accessing configuration files related to dataset processing tasks in py2dataset software documentation generation.'\n    Returns:\n      Value: start_dir\n      Purpose: 'In the given context focusing on 'get_start_dir' functionality within the Python code, its purpose is to retrieve or determine an appropriate starting directory for various operations related to data handling and file management. This function plays a crucial role in setting up input paths while ensuring their validity and existence before use. It returns an absolute path of the provided start_dir if it exists or can be created during runtime.\n        The Returns from `get_start_dir` serve two main objectives:\n        1. Enabling developers to give an optional string parameter, 'start_dir', denoting their preferred initial location to commence the tasks (directory search origin). This path facilitates customizing operations in terms of specific project folders or user-defined paths. If no argument is supplied, `get_start_dir()` defaults to the current working directory retrieved through os.getcwd().\n        2. To ensure seamless execution regardless of provided start_dir validity, the function creates any missing directories en route while flagging notifications about such actions via logging statements for transparency and traceability. Thus, guaranteeing proper file management irrespective of input data consistency or path correctness at runtime.'\n  get_output_dir:\n    Inputs:\n      Value: output_dir\n      Purpose: 'In the given context focusing on analyzing \"get_output_dir\", its purpose is related to obtaining an appropriate directory path for saving output files generated by the \"py2dataset\" software. This function deals with managing where results will be stored during program execution.\n        Breaking down input aspects connected with get_output_dir(output_dir):\n        1. output_dir: This optional argument signifies the destination folder for generating reports or compiled datasets in terms of hierarchy structure within a file system. If provided, it ensures that files are written to this specific location. However, if not given or invalid (doesn't exist), get_output_dir creates the directory if possible and falls back to using the current working directory (cwd). This flexibility allows users to customize output locations while maintaining program functionality even without explicitly specifying an output path.\n        By combining these inputs, \"get_output_dir\" ensures proper handling of output files within a desired or default storage area during software operation. It plays a crucial role in organizing generated data and maintaining user preferences regarding file organization.'\n    Calls:\n      Value: os.path.abspath, os.makedirs, logging.info\n      Purpose: 'In analyzing the given context regarding the `get_output_dir` function usage within the described code base, we focus on understanding three distinct calls - `os.path.abspath`, `os.makedirs`, and `logging.info`. These calls serve specific purposes that contribute to defining output directory handling efficiency along with communication aspects during runtime operation.\n        1. `os.path.abspath`: This call retrieves an absolute pathname corresponding to the input directory or creates one if required. Within `get_output_dir`, it ensures a valid starting point for further operations by either accepting user-provided input or defaulting to the current working directory (cwd). It guarantees a stable reference regardless of relative paths used initially, which is crucial when dealing with file system interactions.\n        2. `os.makedirs`: This function creates one or more directories as necessary along the path specified by its argument. In `get_output_dir`, it ensures that the output directory exists prior to any write operations happening in the codebase. If the given output directory doesn't exist but should according to user input, `os.makedirs` creates it with 'exist_ok=True', preventing errors due to missing paths while maintaining compatibility with existing directories if present. This operation ensures proper file organization and avoids potential failures during data storage processes.\n        3. `logging.info`: It represents a logger function providing basic configuration set at INFO level within the codebase. Inside `get_output_dir`, logging messages are utilized to inform users about crucial operations such as selecting start directories or utilizing output directory paths for increased transparency in application behavior. The logged details provide context about active directories employed by the system aiding developers to debug or analyze issues when needed.\n        Thus, each call serves its purpose in enhancing functionality and usability within `get_output_dir`: `os.path.abspath` for ensuring accurate path resolution; `os.makedirs` to prepare output folder setup while safeguarding from error handling failures associated with nonexistent folders creation and maintenance concerns, finally logging insights rendered via `logging.info`, giving necessary application behavior cues assisting program developers effectively work with the system.'\n    Variables:\n      Value: output_dir\n      Purpose: \"In the given context focusing on understanding the \\\"get_output_dir\\\" function within the provided Python code related to \\\"py2dataset\\\", we need to analyze two primary variables associated with this operation - [output_dir]. These variables play crucial roles in determining where output files are stored or created during program execution.\\n\\n1. output_dir: This variable represents a directory path that serves as an optional argument for the get_output_dir function. It can accept either a string containing an existing directory path or be left empty (indicating no specific preference). If provided, it specifies where the generated outputs should be written. However, if the given path is invalid or does not exist, the code falls back to creating a new directory named \\\"datasets\\\" in the current working directory (denoted by os.getcwd()). Thus, output_dir allows users to customize the location of output files while ensuring their creation if necessary for seamless execution.\\n\\n2. Within the get_output_dir function itself, this variable is utilized as follows:\\n   - os.path.abspath(output_dir or OUTPUT_DIR) extracts either the input string converted into an absolute path or employs the default \\\"OUTPUT_DIR\\\" constant (denoted as \\\"datasets\\\") if output_dir is not supplied or invalid. This ensures consistent handling of directory paths regardless of user inputs.\\n   - os.makedirs(output_dir, exist_ok=True) creates the directory structure if it doesn't already exist while ignoring any existing files within it. This operation helps create organized storage for output files as required by the program.\\n\\nTherefore, both variables interact closely with get_output_dir functionality in maintaining flexible output storage and generating a structured approach for produced documents and associated datasets outputted from this system called \\\"py2dataset\\\". They support developers with setting explicit destination locations for convenience or allow default behaviors when specifications are absent or invalid.\"\n    Returns:\n      Value: output_dir\n      Purpose: 'In the given context focusing on \"get_output_dir\" functionality within the Python code for \"py2dataset\", its purpose lies in managing output directory-related operations. The primary task performed by this function is returning an appropriate output directory path. This directory will be utilized to store generated results or saved configurations during program execution.\n        There are two distinct actions involved when invoking \"get_output_dir\":\n        1. Accepting an optional argument called \"output_dir\": If provided, it validates the input path string for existence as a directory and ensures it can be created if missing (os.makedirs(output_dir, exist_ok=True)). In case of success, this absolute path is returned as the output directory location.\n        2. Returning the default OUTPUT_DIR value: If no \"output_dir\" argument is given or supplied input fails validation checks, the function uses a predefined constant named OUTPUT_DIR set to \"datasets\". This implies saving generated content within the specified project folder titled 'datasets' by default. It can be customized during code execution for output management preferences but carries no effect on core software behavior unless changed from its original value ('datasets').\n        In summary, \"get_output_dir\" ensures proper handling of output storage locations while maintaining flexibility through user-defined paths or relying on a default setting when necessary. This helps organize results generated by the program efficiently throughout execution without disrupting its primary tasks.'\n  get_questions:\n    Inputs:\n      Value: questions_pathname\n      Purpose: 'In the given context focusing on analyzing \"get_questions\" function involving 'questions_pathname', we need to break down its significance and explain individual inputs related to this particular Python method. The primary objective of the get_questions function is retrieving a list of questions used for processing data within the py2dataset system. It can source these questions either from an external file or use default ones if no specific file path is provided or invalid.\n        The 'questions_pathname' argument serves as an input parameter for specifying an optional file path where user-defined question lists may reside. This input enables customization by allowing users to create tailored sets of prompts relevant to their particular use case rather than solely relying on default ones. If this argument contains a valid path pointing to a JSON formatted file with well-structured questions, the function reads it and returns those contents as its output list. However, if 'questions_pathname' is missing or points to an invalid/incorrectly formatted file, get_questions will resort to default questions provided by the get_default_questions() function instead.\n        In summary, 'questions_pathname' acts as a flexible input option that empowers users to customize question prompts for data analysis within the py2dataset framework while maintaining fallback mechanisms with default options when necessary.'\n    Calls:\n      Value: os.path.join, os.getcwd, open, json.load, logging.info, get_default_questions\n      Purpose: 'In the context given focusing on analyzing calls made within the 'get_questions' function from the provided Python code related to py2dataset, five primary operations can be identified which serve distinct purposes: os.path.join, os.getcwd, open, json.load, logging.info, and get_default_questions(). Their role contributes toward reading, combining path elements effectively, fetching defaults, maintaining records on running state/error details and extractingJSON content respectively for understanding code objects at hand.\n        1. os.path.join(path1, path2): This Python OS library function concatenates two paths provided (path1 and path2) preserving their correct directory separators resulting in a unified full path string even if platforms vary (e.g., '\\' for Windows versus '/' on Linux/macOS). It is utilized to generate relative filepaths based on parts provided by user input or defaults, ensuring seamless navigation within the system while working with files.\n        2. os.getcwd(): This function returns the current working directory of the Python interpreter executing the script as a string. In 'get_questions', it serves as a fallback option when the specified questions_pathname argument is not valid or absent since it provides an accessible location for default question files (QUESTIONS_FILE).\n        3. open(filename, mode): A built-in Python function to create file objects for reading/writing purposes depending on 'mode' argument. Here in 'get_questions', it opens the specified questions_pathname or QUESTIONS_FILE (default) in read ('r') mode to extract question lists stored as JSON content.\n        4. json.load(file): The json module method loads JSON formatted data from an open file object into a Python dictionary structure for easy manipulation and further processing. In 'get_questions', it reads the JSON contents of the opened questions file (if valid) converting them into a list of dictionaries representing individual questions with their respective keys ('id', 'text', and 'type').\n        5. logging.info(message): This logging module function logs informational messages during runtime helping developers track execution progress or error scenarios within the codebase. In 'get_questions', it indicates valid operation instances related to files processing; specifically updating on the source of question retrieval i.e., file presence check followed by using defaults or supplied paths for question loading respectively.\n        6. get_default_questions(): A predefined function in our context that generates a default list of questions following certain requirements (i.e., each dictionary must contain 'id', 'text', and 'type' keys representing specific data prompts relevant for code analysis purposes. Its invocation guarantees populating a JSON like list containing those generic prompts ready to serve regardless of supplied paths' validity.\n        Collectively these six aspects in the get_questions function manage interaction with potential files carrying questions alongside fetching defaults, thus allowing dynamic adjustment as per given parameters or failing safely when appropriate question lists aren't present at specified locations.'\n    Variables:\n      Value: questions_pathname, questions\n      Purpose: 'In the context given relating to the Python code analysis regarding the 'get_questions' function within the 'py2dataset' module, we need to understand the roles of two variables: 'questions_pathname' and 'questions'. These variables are significant in handling input parameters associated with retrieving a list of questions for dataset processing.\n        1. questions_pathname: This parameter represents the pathname of an external JSON file containing user-defined questions. Its purpose is to enable users to customize or override default questioning patterns specified in the code with their specific ones during software execution. It could come into play when someone wishes to adapt prompts to particular datasets, focusing on certain aspects more than others. If left empty or if the provided path leads to an invalid file, a default set of questions is used instead.\n        2. questions: This variable holds either custom questions read from the 'questions_pathname' file or default ones when no valid input file exists or fails JSON format validation. It stores the list of dictionaries representing individual question entries retrieved from either user-provided data or internal defaults. Each dictionary contains keys such as 'id', 'text', and 'type', which define unique identifiers, textual content, and categorization (file, function, method, class) for each prompt in the list.\n        In summary, 'questions_pathname' allows external configuration of prompts while 'questions' stores the resulting list of questions used by the system during analysis processes after handling user inputs or resorting to default settings if necessary. Both variables contribute significantly to personalizing query patterns within the 'get_questions' function according to users' requirements.'\n    Returns:\n      Value: questions\n      Purpose: 'In the given context focusing on analyzing \"questions\" functionality within the Python codebase, we are asked to explain the purpose and significance of returns from `get_questions`. This function is primarily responsible for obtaining questions relevant to processing a Python dataset as prompts for understanding program elements. The significant points related to its outputs include:\n        1. Function Behavior: `get_questions(questions_pathname)` fetches questions either from the specified file path (if valid JSON format) or defaults to the built-in list of prompts when no path is provided or given file contains errors. It ensures proper handling of user inputs while maintaining consistency in data retrieval.\n        2. Return Value: This function returns a List[Dict] containing question details, each represented as dictionaries with keys 'id', 'text', and 'type' specified in accordance to its intended query application range: files (\"file\"), methods/functions ('function'), class declarations ('class') or standalone instances without restriction (the type=\"general\" for instance). These questions serve as prompts during dataset analysis, helping extract necessary information about Python code structure and functionality.\n        By understanding these aspects of `get_questions`, we can comprehend its role in facilitating comprehensive software documentation generation through prompting relevant queries about Python files or code snippets within the \"py2dataset\" system.'\n  instantiate_model:\n    Inputs:\n      Value: model_config\n      Purpose: \"In the given context focusing on understanding \\\"model_config\\\" within instructions related to the \\\"instantiate_model\\\" function, we need to describe its purpose and significance along with explaining individual inputs used during instantiation.\\n\\nThe 'model_config' refers to a dictionary holding essential configurations required for setting up a language model utilized in the codebase. It acts as an input parameter passed into the instantiate_model function to create an instance of the desired model class based on specified settings. Breaking down each significant component within this configuration dictionary will help grasp their individual roles:\\n\\n1. 'system_prompt': This key contains a string containing detailed instructions for the language model about its role as a system assistant generating software documentation using the provided context and query. It sets up initial prompts for comprehensive analysis during the generation process.\\n\\n2. 'instruction_prompt': Another string value defining how instruction will be conveyed to the language model while generating software documentation. This part guides the model on analyzing code objects based on given context and query inputs.\\n\\n3. 'prompt_template': A template string used for structuring output documentation in a specific format combining system prompt, instruction prompt followed by actual documentation results ('documentation:' section).\\n\\n4. 'inference_model': This sub-dictionary defines attributes concerning the core language model instantiated inside the instantiate_model function call. It contains three critical aspects:\\n    a. 'model_import_path': The import path leading to the desired language model class within the codebase (e.g., \\\"ctransformers.AutoModelForCausalLM\\\"). This information helps Python locate and load the appropriate module during instantiation.\\n    b. 'model_inference_function': Specifies how exactly the model instance should be initialized from its pretrained weights file. It may either use \\\"from_pretrained\\\" or other potential functions provided by the language model library depending on its implementation requirements.\\n    c. 'model_params': A dictionary containing crucial parameters necessary for initializing and running the language model efficiently such as path to a pretrained checkpoint (\\\"model_path\\\"), model architecture details like \\\"model_type\\\", GPU layer allocation ('gpu_layers'), thread usage ('threads'), batch size, context length limitations ('context_length'), maximum token generation limit ('max_new_tokens'), reset flag status ('reset') etc.\\n\\nBy combining these inputs collectively within 'model_config', the instantiate_model function imports, creates an instance of required classes using importlib library features, invokes suitable constructor methods considering parameters provided through various keys and ultimately returns the ready-to-use model object suited for software documentation tasks specified in the codebase.\"\n    Calls:\n      Value: model_config['model_import_path'].rsplit, getattr, importlib.import_module, inference_function, model_params.pop, ModelClass, logging.info\n      Purpose: 'In the context given related to the 'instantiate_model' function within the Python code for py2dataset, several notable functions are employed with distinct purposes towards building and returning a Language Model object using the configuration details provided. To explain each operation clearly:\n        1. [`model_config['model_import_path'].rsplit`]: This line splits the string value stored in 'model_import_path' from the model configuration dictionary at the last occurrence of a period ('.'). It separates the package path (e.g., 'ctransformers') from the actual model class name (e.g., 'AutoModelForCausalLM'). The purpose is to split into different segments suitable for `getattr` function usage in the next step.\n        2. [`getattr`]: This built-in Python function retrieves an attribute or property value from an object using its string name. Here, it fetches the specified class from the imported module based on the package path obtained earlier. For instance, if 'model_import_path' is 'ctransformers.AutoModelForCausalLM', `getattr` will return 'AutoModelForCausalLM'.\n        3. [`importlib.import_module`]: This function imports a module dynamically by its name extracted from the model configuration dictionary. It allows importing the specified package identified earlier by `model_config['model_import_path'].rsplit without hardcoding the module name within the codebase, providing flexibility in using different libraries or models.\n        4. [`inference_function`]: This variable holds the string value of 'from_pretrained' if mentioned in the model configuration dictionary under 'model_inference_function'. It indicates which initialization method should be used for creating the Language Model instance from the imported module. If not empty, this function call will invoke the specified initialization method on the model class object later.\n        5. [`model_params.pop`]: This line removes and returns a key-value pair from the dictionary 'model_params' according to its given argument ('\"model_path\"'). It extracts the path of the pretrained language model used in initialization. This technique allows passing other parameters while maintaining simplicity in referencing individual keys during instantiation processes without complicating syntax.\n        6. [`ModelClass`]: Variable holding the actual class object extracted by `getattr`, this helps preserve modularity while waiting to perform any desired tasks within further context boundaries of defining new model instance using parameters specified up to this stage - except those defined differently for separate calls related exclusively with instantiated instances creation such as inference method and initialization functions selection from previous steps.\n        7. [`logging.info`]: A debugging/reporting mechanism built into the Python codebase utilized to keep track of ongoing events happening throughout its execution process - including progress about unsuccessful model instantiation attempts mentioned later after 'instantiate_model' exceptions catching part in case errors arise while performing operations outlined before it (function invocations).\n        In summary, these calls within `instantiate_model` work together to import a desired language model class dynamically from an external library using configuration details provided by the user or default settings. They also prepare necessary parameters and remove redundant keys before instantiating the Language Model object ready for use in subsequent steps of py2dataset functionality.'\n    Variables:\n      Value: ModelClass, inference_function, model_params, inference_function_name, model_config, llm\n      Purpose: 'In the context given focusing on understanding 'instantiate_model' function within the Python code provided, we need to elaborate on the purpose and significance of mentioned variables: ModelClass, inference_function, model_params, inference_function_name, model_config, and llm. These variables play crucial roles during the instantiation process of a language model object.\n        1. ModelClass: This variable represents the class imported from an external module specified by 'model_import_path' within the provided model configuration dictionary (model_config). Instantiate_model relies on this imported class to create an instance of the targeted model.\n        2. inference_function: It holds the name of a function within ModelClass that is responsible for initializing or setting up the language model according to given parameters. This function gets called after importing and instantiating ModelClass. If its value is not empty, it indicates there's a custom initialization method other than default constructor usage.\n        3. model_params: A dictionary containing parameters required by either inference_function or ModelClass constructor for initializing the language model object. These parameters may include paths to pre-trained models, context length limits, batch sizes, GPU layer numbers, etc., depending on the specific model architecture and library requirements.\n        4. inference_function_name: This variable stores the name of a function within ModelClass used for model initialization when instantiate_model calls ModelClass (as opposed to directly invoking its constructor). It serves as an optional alternative way to set up the language model with specific methods other than default constructors provided by the class.\n        5. model_config: This variable contains comprehensive configuration details about the language model used in the system, including system and instruction prompts along with parameters for initializing an inference model from Transformers library (\"ctransformers\"). It is utilized to gather necessary information before calling instantiate_model to create a functional language model object.\n        6. llm: The lowercase 'llm' denotes the initialized language model object after successfully importing ModelClass, retrieving appropriate function calls/constructors (inference_function or default constructor), and passing required parameters (model_params). This instantiated model is returned by the instantiate_model function for further usage within the program flow.\n        In summary, these variables facilitate efficient handling of importing relevant modules/classes from external libraries while configuring initialization processes necessary to create a usable language model instance suitable for analyzing code contexts and generating desired documentation in 'instantiate_model'.'\n    Returns:\n      Value: llm, None\n      Purpose: 'In the given context focusing on understanding \"instantiate_model\" function behavior within the provided Python code related to the dataset processing system 'py2dataset', we are asked to elaborate on the purpose and significance of its returns - [llm, None]. These two outputs represent distinct outcomes when executing this function.\n        1. llm: This return value denotes an instantiated language model object obtained after successfully importing a specified module and class from the given configuration in the 'model_config' dictionary within 'get_model'. The imported model is initialized using provided parameters, primarily serving as the core component for generating software documentation based on input prompts. Its exact functionality depends on the selected model architecture configured through 'inference_model', which may involve natural language processing tasks like text generation or summarization.\n        2. None: This alternative return value indicates an error occurred during the instantiation process. It might happen due to issues such as incorrect import paths, missing classes, or invalid parameters within the 'model_config'. In such cases where creating a valid model instance fails, 'None' is returned signaling unsuccessful execution of the 'instantiate_model' function. Users need to analyze logged error messages to address any mistakes before retrying with revised configuration settings for model initialization success.'\n  get_model:\n    Inputs:\n      Value: model_config_pathname\n      Purpose: \"In the given context focusing on understanding \\\"get_model\\\" function inputs related to describing their purpose and significance within the Python code, we have two primary parameters involved: [model_config_pathname]. Here's a breakdown of each input's role in the `get_model` operation:\\n\\n1. model_config_pathname (str): This argument represents the pathname to a file containing customized configuration settings for the language model utilized by the py2dataset system. By providing this file path, developers can adjust various parameters associated with model instantiation and behavior according to their specific requirements. If left empty or invalid, the function falls back on default model configurations provided within get_default_model_config().\\n\\nThe primary responsibilities of model_config_pathname in the `get_model` function are as follows:\\n   a. It allows users to override default settings with customized ones stored externally in a file for more tailored language modeling outcomes.\\n   b. Enables flexible integration of multiple configurations by letting developers store diverse settings and quickly switch between them depending on project demands. This adaptability boosts versatility across various scenarios and ensures a wide range of usage cases can be handled effectively by py2dataset.\"\n    Calls:\n      Value: os.path.join, os.getcwd, open, yaml.safe_load, logging.info, get_default_model_config, instantiate_model\n      Purpose: 'In the context given focusing on analyzing calls within the 'get_model' function, we have several key operations that contribute to retrieving a configured language model for software documentation purposes. Here are detailed explanations of each mentioned call:\n        1. os.path.join: This Python library function joins two or more pathname components into a single path with proper separators based on the current operating system. In 'get_model', it combines parts to form file paths for reading model configuration files either from user input or default locations. For instance, if a custom path is provided but invalid or absent, it falls back to using os.getcwd() combined with MODEL_CONFIG_FILE constant as the default location.\n        2. os.getcwd(): This function returns the current working directory of the application at runtime, indicating the default path if none is given when retrieving questions file ('get_questions') or model config file ('get_model'). By understanding its significance in directory navigation and determination, it ensures program operability regardless of the execution environment.\n        3. open(): This built-in Python function manages reading and writing files. It's used twice in 'get_model'; once for validating the provided model configuration file (if any) by opening it in read mode ('r'), allowing YAML data extraction using yaml.safe_load(). The second instance occurs when saving default questions as JSON format through write_questions_file() or writing default model configurations as YAML in write_model_config_file(), depending on their respective paths determined by the code flow.\n        4. yaml.safe_load(): This function from PyYAML library parses a YAML formatted file into a Python object (dict in this case). In 'get_model', it loads user-specified model configuration data if present, enabling further processing like instantiating the language model with given parameters.\n        5. logging.info(): This function from Python's logging module prints informational messages to standard output or log files during runtime. It helps developers track program behavior and identify potential issues by logging relevant information about directory settings (e.g., using output directories). For example, it notifies users when switching to default questions file paths due to invalid inputs in 'get_questions' or model config file unavailability in 'get_model'.\n        6. get_default_model_config(): As explained earlier in the overall code summary, this function returns a dictionary representing default settings for the language model used within py2dataset. It forms an essential part of 'get_model', where it contributes initial configuration before instantiating the actual model object via instantiate_model().\n        7. instantiate_model(): This custom function imports and creates an instance of a specified model class based on provided configuration details from 'get_default_model_config()'. It handles importing modules and classes related to Transformers library, extracts required parameters (model path and other model-specific settings), initializes the language model according to the user or default config set beforehand, ultimately returning it for further use in documentation generation.\n        Each of these calls within 'get_model' serves a distinct purpose advancing towards building a functional language model ready to analyze code contexts based on user-provided or default configurations while maintaining traceability through logging mechanisms and flexible directory handling options.'\n    Variables:\n      Value: model_config_pathname, model_config\n      Purpose: 'In the context given focusing on understanding \"model_config_pathname\" and \"model_config\" within the scope of the function 'get_model', we need to describe their purpose and significance. These two variables are instrumental in configuring language model setup during the process of software documentation generation using the py2dataset codebase.\n        1. model_config_pathname: This parameter represents an optional input argument passed into the 'get_model' function. It refers to the pathname pointing towards a YAML file containing user-defined configurations for initializing the language model employed by the system. If supplied, this file acts as an alternative to default settings mentioned in get_default_model_config(). If invalid or missing, the function defaults to using predetermined configuration details stored within get_default_model_config().\n        2. model_config: This variable holds the actual retrieved configurations once read from either a customized user file ('model_config_pathname') or default settings depending on pathname validation. The obtained model config is utilized for creating an instantiated language model instance in collaboration with instantiate_model(). It serves as a central object carrying all necessary details about the language model's behavior and functioning during the software documentation process.\n        Within 'get_model', model_config_pathname helps users customize their model configurations while model_config stores these settings to initialize an appropriate language model instance for generating desired outputs based on user requirements. Both variables play a crucial role in providing versatility for diverse needs regarding specific task handling with advanced AI integration throughout documentation creation workflows related to programming and analysis within python code snippets.'\n    Returns:\n      Value: model_config\n      Purpose: 'In the given context focusing on understanding \"model_config\" within the scope of the Python code and relating it to the instructions provided, we need to break down the crucial aspects returned by the `get_model` function when dealing with this configuration object. The `get_model` function primarily aims to instantiate a language model based on the provided or default model configuration settings. Two significant returns from this function are as follows:\n        1. Instantiated Model Object: This is the primary outcome after importing a specified module and class using the supplied model configuration details through `importlib` and setting up model parameters using imported functionality with required path, model type, or inference options defined earlier within 'inference_model' of the model_config dictionary. Instantiating it means creating an instance or preparing it to use later in data analysis processes within this system related to documentation generation for code examination tasks as instructed.\n        2. Prompt Template: This return contains a string containing both system and instruction prompts concatenated together with specific variables inserted into them. The system prompt starts with \"Lang: English. Output Format: unformatted, outline.\" followed by an instruction section tailored to the given context. This template is used for generating human-readable documentation based on analyzed Python code or files through language modeling techniques employed by the instantiated model object mentioned above.\n        To summarize, `get_model` returns a functionalized language model ready to process input data according to configured settings and a prompt template that combines system and instruction prompts to facilitate comprehensive software documentation generation as per requirements described in context snippets related to code analysis tasks.'\n  write_questions_file:\n    Inputs:\n      Value: output_dir\n      Purpose: 'In the given context focusing on understanding \"write_questions_file\" function involvement with input parameter \"[output_dir]\", we need to describe its purpose and significance along with breaking down their individual roles. The main objective of `write_questions_file` lies in persisting the default questions (provided by get_default_questions()) as JSON format within a user-defined directory path or default location (current working directory when \"[output_dir]\" lacks validity). It's vital for data retention between execution cycles for subsequent software processing if desired.\n        The primary inputs to `write_questions_file` are:\n        1. \"[output_dir]\": This parameter accepts a string representing the target directory path where the JSON file containing questions will be written. If valid and existing, it ensures data storage in that specific location. However, if non-existent or incorrectly specified, it falls back to saving within the current working directory (cwd). The function creates this directory structure when needed while logging a relevant message for traceability purposes. This input serves as an additional layer of customization by enabling users to define file locations that fit their specific organizational preferences and storage schemes outside the program's default behavior.\n        2. In absence or incorrectness of \"[output_dir]\", the code implicitly utilizes the current working directory (\"os.getcwd()\"). It serves as a default path if explicit output direction isn't provided by users or fails validation checks during runtime. This ensures essential functionality even when no external storage specifications are given but doesn't override user-defined paths when validated correctly.\n        Both inputs contribute to data management and accessibility after script execution for potential further usage, improving system adaptability while emphasizing modularity within code design. They let users handle data persistence flexibly based on their storage needs without significantly impacting underlying algorithms operating 'write_questions_file' core responsibility i.e., persisting JSON file holding the default set of questions specified via `get_default_questions()`.'\n    Calls:\n      Value: get_default_questions, Path(output_dir).is_dir, Path, os.getcwd, open, os.path.join, json.dump\n      Purpose: 'In the context given focusing on understanding 'write_questions_file' functionality within the Python codebase, several key function calls contribute to its operation. These functions serve specific purposes as explained below:\n        1. get_default_questions(): This function returns a predefined list of default questions that aid in analyzing Python files or code snippets for software documentation generation. The returned questions are structured as dictionaries with keys 'id', 'text', and 'type'. These questions act as prompts to understand various aspects like file dependencies, class attributes, method calls, etc., during the documentation process.\n        2. Path(output_dir).is_dir: This operation checks whether the provided output directory exists or not. The Path function converts the given string into a pathlib.Path object, and then it utilizes the '.is_dir()' method to verify if that path refers to an existing directory. If true, it ensures proper handling of output files in the specified location; otherwise, alternative directories are considered.\n        3. Path: Although mentioned alongside 'Path(output_dir).is_dir', Path is a built-in Python module from the pathlib library used for manipulating file paths independently or as part of other functions like above. It provides object-oriented access to filesystem paths and simplifies working with them in Python code.\n        4. os.getcwd(): This function returns the current working directory of the program execution. If no valid output directory is supplied to 'write_questions_file', this call helps determine where to save the questions file by default.\n        5. open(): A built-in Python function used for opening files in various modes such as reading or writing. In 'write_questions_file', it opens a new file with the given path (combined using os.path.join) for saving JSON data containing questions retrieved from get_default_questions().\n        6. os.path.join(): A helper function taking two or more directory paths concatenates them, accounting for appropriate system dependent separators (i.e., forward slashes ('/') on UNIX platforms or backslashes ('\\') in Windows environments. It ensures correct file path formation when combining different parts of the filename and directory structure within write_questions_file().\n        7. json.dump(): This method from Python's json module serializes a Python object into a JSON formatted string, which is then written to the opened file by 'open()'. In this case, it converts the list of default questions returned by get_default_questions() into JSON text format and stores it within write_questions_file().\n        Each of these calls combined facilitates saving default question data in a file with JSON formatting either at a user-specified output directory or falling back to the current working directory if no valid path is provided. This process ensures easy accessibility for further software documentation tasks involving Python code analysis as per the given instruction.'\n    Variables:\n      Value: output_dir, questions\n      Purpose: 'In the given context asking for analysis focusing on `output_dir` and `questions` within `write_functions_file`, we need to break down their roles in this specific function. The `write_questions_file()` serves to save default questions as a JSON file format either in a designated directory or current working directory if no output path is provided or invalid. These variables play crucial parts in accomplishing that task.\n        1. `output_dir`: It represents the destination directory where we want to store the questions file created from the `write_questions_file()` function call results. When calling this function, you can either supply a string with a path representing an existing or creatable output folder (as confirmed by its existence check using os.path.is_dir()) or simply let it default to the current working directory by not providing any argument. If an invalid directory is passed, it defaults back to cwd too. In summary, `output_dir` decides where our questions file will be written.\n        2. `questions`: This variable contains the list of questions obtained either from a given configuration file or default ones if that file path fails validation checks or isn't provided at all. These questions are crucial inputs for generating documentation in Python files analysis processes by prompting specific queries related to code structure, functions, classes, methods, etc., as defined earlier in `get_default_questions()`. In `write_questions_file()`, this variable passes the questions list that gets dumped into JSON format within the specified output directory or current working directory (if `output_dir` isn't valid). Thus, `questions` holds essential content to be saved as a file.'\n  write_model_config_file:\n    Inputs:\n      Value: output_dir\n      Purpose: \"In the given context focusing on \\\"write_model_config_file\\\" function analysis, we aim to describe its purpose and significance along with explaining individual inputs associated with it within the Python code provided.\\n\\n1. Function Purpose: The 'write_model_config_file' is part of the \\\"py2dataset\\\" module, contributing towards facilitating configuration file handling operations. Specifically, it saves default model configuration settings as a YAML formatted text into a designated directory. This process ensures easy accessibility and customization for users while working with the dataset processing system.\\n\\n2. Inputs Description:\\n   a. output_dir: This parameter serves as an optional argument passed to 'write_model_config_file'. Its role is to define the directory where the user desires to store the model configuration file containing default settings in YAML format. If no explicit directory path is given or fails validation checks (doesn't exist or isn't writeable), the current working directory will be utilized as a fallback option for saving purposes. In both scenarios, the function guarantees creating the required output folder if necessary during runtime.\"\n    Calls:\n      Value: get_default_model_config, Path(output_dir).is_dir, Path, os.getcwd, open, os.path.join, yaml.dump\n      Purpose: \"In the context given focusing on analyzing calls within the 'write_model_config_file' function using particular objects, we can understand their individual purposes as follows:\\n\\n1. get_default_model_config(): This call retrieves a predefined dictionary containing the default configuration for setting up a language model used in the py2dataset system. It holds details about prompts and parameters related to initializing an inference model from Hugging Face's Transformers library (\\\"ctransformers\\\").\\n\\n2. Path(output_dir).is_dir: This expression checks if the provided output directory exists as a valid folder path. If True, it ensures smooth file writing operations; otherwise, it prepares for creating the directory when needed in other scenarios.\\n\\n3. Path: Though not explicitly called as a function here but used as a built-in module in Python's 'pathlib', it offers path manipulation functionalities making working with file paths easier and more robust by considering platform dependencies.\\n\\n4. os.getcwd(): This built-in Python function returns the current working directory path where the script is running. It acts as a default output location if no valid user input directory or custom config file paths are supplied during execution of the write_model_config_file function call chain.\\n\\n5. open(): This is a built-in Python library for opening textual data streams ('r' flag given denotes read access), helping writing data onto specified files (models_config). In write_model_config_file(), it serves for configuring interactions with filesystem operations to store configuration settings persistently on disk.\\n\\n6. os.path.join(): Another Python library function, joining two or more path components preserving system-dependent separators ensuring consistent directory referencing between various platforms like Unix (\\\"/\\\") or Windows ('\\\\\\\\'). Here, it constructs file paths with respective segments seamlessly by connecting base paths to subfolders for better maintainability in managing code hierarchy within larger projects.\\n\\n7. yaml.dump(): Part of PyYAML package enabling Python objects' conversion into YAML strings efficiently and vice versa, facilitating easy data storage across languages having varied data structuring demands such as keys separated with colon and values wrapped on distinct lines\\u2014this converts py2dataset\\u2019s model_config dictionary content to properly formatted yaml format which further saves in disk after preparing file paths using os.path.join().\\n\\nIn summary, these calls collaborate within write_model_config_file() to save default model configuration details into a YAML file at specified or default locations (based on directory validity), enabling users to customize their py2dataset setup as per requirements while maintaining flexibility in handling diverse file structures across platforms.\"\n    Variables:\n      Value: output_dir, model_config\n      Purpose: 'In the given context focusing on understanding the roles of output_dir and model_config within the function write_model_config_file, we can break down their individual purposes as follows:\n        1. output_dir: This variable represents a directory path where files are to be written or created during program execution. It primarily concerns saving configuration files related to py2dataset processes. In write_model_config_file, it determines the location for storing the default model configuration file in YAML format (MODEL_CONFIG_FILE). If no specific output directory is provided or turns out invalid, the current working directory is employed as an alternative choice by get_output_dir(). The output_dir facilitates managing the organizational structure of saved configurations related to this software system.\n        2. model_config: This parameter encompasses a dictionary holding information about how the language modeling process operates within py2dataset, including details on system prompts, instruction prompts, and parameters required for initializing an inference model from Transformers library (ctransformers). In write_model_config_file, it passes this configuration to get_model() before saving its default or customized version as a YAML file. Model configuration ensures the system runs according to desired settings while interacting with language models during software documentation generation tasks.\n        In summary, output_dir governs storage locations for configuration files while model_config defines how py2dataset functions in terms of language modeling aspects within write_model_config_file and overall program operation.'\n  get_default_questions:\n    Variables:\n      Value: questions\n      Purpose: \"In the given Context focused on analyzing within the context of variables associated with 'questions' from the `get_default_questions` function, we need to delve into its significance and highlight their respective roles within that code snippet. Here are detailed descriptions of crucial elements found therein:\\n\\n1. `questions` (List[Dict] - Global in `get_default_questions()` function scope:\\n   This variable represents a primary output of the `get_default_questions()` function, which returns a list containing dictionaries as its elements. Each dictionary encapsulates question-related metadata required for Python file analysis during documentation generation. These questions are stored in this variable after processing by the function and serve as prompts to extract relevant information about code objects like files, functions, methods, classes, etc., ensuring comprehensive software documentation.\\n\\n2. 'id' (Key within each dictionary):\\n   This key holds a unique identifier for every question inside the returned list of dictionaries from `get_default_questions()`. It helps maintain orderliness and ease in referencing specific questions during processing or manipulation.\\n\\n3. 'text' (Key within each dictionary):\\n   The 'text' key stores the actual textual content of each question in the returned list of dictionaries from `get_default_questions()`. It represents the query that will be asked to understand various aspects of Python code objects such as file dependencies, function inputs/outputs/returns, class attributes, etc., during documentation generation.\\n\\n4. 'type' (Key within each dictionary):\\n   Another vital attribute found in question dictionaries outputted by `get_default_questions()`, the 'type' key defines a category or type for every question related to the analyzed code object. It could be \\\"file\\\", \\\"function\\\", \\\"method\\\", or \\\"class\\\" depending upon which programming entity the query is addressing, thereby assisting in targeted analysis of Python scripts during documentation generation.\\n\\nBy understanding these variables' roles within `get_default_questions()`, we can comprehend how they contribute to generating essential prompts for analyzing Python code objects comprehensively while creating software documentation.\"\n    Returns:\n      Value: questions\n      Purpose: 'In given Context focusing on analyzing the 'questions' related concepts after running instructions via \"py2dataset\" software documentation code, we need to explain the Purpose and Importance of return values obtained from function `get_default_questions`. This specific Python module sets default parameters needed for retrieving questions intended as prompts used to elicit elaborate documentations concerning analyzed code structures like Python files or functions.\n        The primary goal of `get_default_questions()` is providing a predefined list of dictionary entries representing potential inquiries relevant to Python code analysis tasks. Each question itemized here has three significant attributes - 'id', 'text', and 'type'. These details play essential roles as follows:\n        1. 'id': A unique identifier for each query facilitating later processing referencing and differentiation. Developers might require a quick index for various kinds of analysis needs associated with file components, function parameters or return statements separately while navigating complex programming artifacts.\n        2. 'text': This attribute contains the actual textual content of each question posed to the language model during documentation generation. These questions are crafted to elicit comprehensive descriptions about Python code elements such as dependencies, call graphs, variable usage patterns within functions or classes, method calls, class attributes, inheritance relationships, etc., ensuring thorough analysis across diverse aspects of a given script.\n        3. 'type': It categorizes each question into one of four types - file, function, method, and class. This classification helps the system understand which programming element the query pertains to while generating software documentation tailored accordingly. By knowing the context (i.e., type), it can appropriately apply its intelligence in analyzing code objects accordingly during the generation process.\n        Hence, these Returns from `get_default_questions` enable prompt creation for generating precise documentation on diverse aspects of Python code using language models efficiently while keeping a systematic organization structure that allows further categorization based on code components' types. It sets the foundation stone upon which actual context evaluation operates.'\n  get_default_model_config:\n    Variables:\n      Value: model_config\n      Purpose: \"In analyzing the given context focusing on variables within `get_default_model_config`, we need to understand their purpose and significance in the overall functionality of this specific function. The `get_default_model_config()` returns a dictionary containing default settings for the language model used by the py2dataset system during documentation generation. Here are explanations for each variable mentioned:\\n\\n1. **system_prompt**: This variable holds a predefined string that serves as the initial system prompt for generating software documentation using the given context and instructions. It sets up an overall framework for the language model to comprehend its role in creating software documentation while providing essential information about the task at hand.\\n\\n2. **instruction_prompt**: It contains another templated string serving as the instructional portion which merges with the system prompt when generating outputs from context analysis. This segment ensures clarity about the exact problem statement or question asked of the model so it can generate relevant responses addressing specific requirements within the given task context.\\n\\n3. **prompt_template**: This variable forms a composite template combining both system and instruction prompts into one coherent string format before passing them to the language model for processing. It ensures proper structuring of input data for generating desired output documentation.\\n\\n4. **inference_model**: It represents a nested dictionary inside `get_default_model_config()`, specifying crucial parameters related to the language modeling component (Transformer-based large language model). The key components within this nested dict are as follows:\\n    - **model_import_path**: Imports specific module containing a suitable Transformer-based LLM class (mistral) for this case, employed for analyzing and synthesizing code documentation. This enables efficient instantiation through Python import mechanism.\\n    - **model_inference_function**: Describes how exactly to instantiate the imported language model with a reference function from said class (\\\"from_pretrained\\\" in this instance). This step helps initialize the model object using pre-trained weights optimized for the task at hand.\\n    - **model_params**: Contains arguments like `model_path`, `model_type` and additional configurations compatible with specified hardware setups to establish correct environment settings required for the Transformer-based large language model performance enhancement while analyzing software details provided during program execution.\\n\\nBy understanding these variables' roles within `get_default_model_config()`, we can appreciate their significance in configuring a robust setup for generating comprehensive software documentation using advanced natural language processing techniques employed by the py2dataset system.\"\n    Returns:\n      Value: model_config\n      Purpose: 'In analyzing the context regarding the object \"model_config\" in compliance with the given instruction about understanding returns from `get_default_model_config`, we need to focus on deciphering its significance within the overall codebase and breaking down each key component it encompasses. The `get_default_model_config()` function primarily generates a dictionary representing default configurations for the language model utilized in the \"py2dataset\" system. This configuration serves as crucial input data for various operations related to generating documentation or analyzing Python files/code snippets.\n        Within the returned 'model_config' dictionary, we can identify several key elements that play distinct roles:\n        1. **System Prompt:** It holds a multi-line string starting with \"Lang: English. Output Format: unformatted, outline...\" which sets the language to English and outlines desired output format as plain text without formatting details like HTML tags or other embellishments. This prompt ensures the model understands expectations related to the target documentation structure and writing style.\n        2. **Instruction Prompt:** A dynamic multi-line string combining static elements (\"Analyze Context...\") with variables ({context}, {code_objects}, {query}) that will be replaced during actual execution. It instructs the language model on how to process input data by analyzing context, comprehending code objects (such as files, functions, methods, classes), and addressing a specific query.\n        3. **Prompt Template:** A fixed string (\"system:\\n{system_prompt}\\n\\ndocumentation:\\n\") concatenated with instruction prompt text after variable replacement during execution. This structure guides the language model on organizing output as first displaying system instructions, followed by generated documentation in a readable format.\n        4. **Inference Model:** Contains specifications for instantiating a transformer-based language model from Hugging Face's library (ctransformers). It includes details about the AutoModelForCausalLM class import path (\"AutoModelForCausalLM\"), function used to initialize the model instance (\"from_pretrained\") as well as essential parameters. Model settings inside \"model_params\" contain valuable insights for model configurations suitable with an optimized GPU and robust CPU for its tasks: thread management (threads = 16), batch size adjustments (batch_size = 512), context length control (context_length = 28000), maximum new tokens count limitation (max_new_tokens = 16000), GPU layer optimization (gpu_layers = 100), and resetting model state before each query execution (reset = True).\n        To summarize, 'model_config' serves as a comprehensive blueprint for language modeling operations within the \"py2dataset\" system. It encompasses prompts guiding the AI on how to generate software documentation while also defining essential parameters to initialize an advanced Transformer model equipped for these tasks. The function primarily creates this setup during startup stages ensuring accurate program operation with defined parameters reflecting resource compatibility concerns such as CPU or GPU configuration considerations.'"
    purpose: 'In this provided Python code, there are multiple utilitarian functions dedicated to managing input data parameters related to a dataset processing system called "py2dataset." The key functionality offered can be organized around several distinct modules: question handling, model setup configuration, output directory handling, and file I/O operations for configuration saving.


        1. Question Handling Functions:

        a. `get_default_questions()` returns a list of default questions used by the system in JSON format. These questions serve as prompts for analyzing Python files or code snippets during documentation generation. Each question dictionary has ''id'', ''text'', and ''type'' keys defining its unique identifier, textual content, and category (file, function, method, class).

        b. `get_questions(questions_pathname)` attempts to fetch questions from a given file path if valid or uses default questions otherwise. It throws exceptions on invalid files or missing JSON format.


        2. Model Setup Configuration Functions:

        a. `get_default_model_config()` returns a dictionary representing the default configuration for the language model used in the system. This includes system and instruction prompts, as well as parameters for initializing an inference model from Hugging Face''s Transformers library ("ctransformers"). The dictionary holds settings related to the language generation process.

        b. `get_model(model_config_pathname)` fetches either default or custom model configuration depending on the provided file path validity. It instantiates a language model object using imported classes and specified parameters. If no config file is given, it uses defaults.


        3. Output Directory Handling Functions:

        a. `get_start_dir(start_dir)` returns an absolute directory path either from the provided input or current working directory (cwd). It creates the directory if necessary but logs information about this operation for user notification.

        b. `get_output_dir(output_dir)` follows the same process but generates output files specifications specifically while guaranteeing path creation upon usage when specified directories do not exist yet.


        4. File Input/Output Functions:

        a. `write_questions_file(output_dir)` saves default questions as JSON formatted text into the given directory or current working directory if no output directory is provided or invalid. It uses `json.dump()`.

        b. `write_model_config_file(output_dir)` writes default model configuration as YAML formatted content in specified output location, which again falls back to cwd otherwise. `yaml.dump()` ensures formatting appropriately for easy comprehension during program use.


        These components facilitate retrieval or customization of analysis parameters as well as enabling language modeling outcomes aligned with described software development needs like context examination across a Python script analyzing various programming aspects while incorporating details of object relations such as file structure, function call relationships, return statements and overall documentation generation for advanced computer science courses.

        '
functions:
    get_default_questions:
        function_name: get_default_questions
        function_code: "def get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [{'id': 'file_dependencies', 'text': 'Dependencies in Python file: `{filename}`?', 'type': 'file'}, {'id': 'entire_code_graph', 'text': 'Call code graph in Python file: `{filename}`?', 'type': 'file'}, {'id': 'file_functions', 'text': 'Functions in Python file: `{filename}`?', 'type': 'file'}, {'id': 'file_classes', 'text': 'Classes in Python file: `{filename}`?', 'type': 'file'}, {'id': 'function_inputs', 'text': 'Inputs to `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_docstring', 'text': 'Docstring of `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_calls', 'text': 'Calls made in `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_variables', 'text': 'Variables in `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'function_returns', 'text': 'Returns from `{function_name}` in Python file: `{filename}`?', 'type': 'function'}, {'id': 'class_methods', 'text': 'Methods in `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id': 'class_docstring', 'text': 'Docstring of `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id': 'class_attributes', 'text': 'Attributes of `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id': 'class_inheritance', 'text': 'Inheritance of `{class_name}` in Python file: `{filename}`?', 'type': 'class'}, {'id': 'method_inputs', 'text': 'Inputs to `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_docstring', 'text': 'Docstring of `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_calls', 'text': 'Calls made in `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_variables', 'text': 'Variables in `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'method_returns', 'text': 'Returns from `{method_name}` in Python file: `{filename}`?', 'type': 'method'}, {'id': 'file_purpose', 'text': 'I) Describe the Purpose and Processing Approach for Python file: `{filename}`; II) Define detailed Requirements and API Signatures for all Functions and Class Methods and explain their logic and purpose of the inputs, outputs, variables, returns, and calls.', 'type': 'file'}]\n    return questions"
        function_docstring: "Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    "
        function_inputs: []
        function_defaults: []
        function_returns:
        - questions
        function_calls: []
        function_call_inputs: {}
        function_variables:
        - questions
        function_decorators: []
        function_annotations: []
        function_properties: []
    get_default_model_config:
        function_name: get_default_model_config
        function_code: "def get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {'system_prompt': \"Lang: English. Output Format: unformatted, outline. Task: Create software documentation for an advanced computer science course using this code Context:\\n'{context}'\\n\", 'instruction_prompt': \"Analyze Context to comprehensively describe the purpose and functions of these objects:\\n'{code_objects}'\\n to comply with this instruction:\\n'{query}'\\n\", 'prompt_template': 'system:\\n{system_prompt}\\n\\ninstruction:n{instruction_prompt}\\n\\ndocumentation:\\n', 'inference_model': {'model_import_path': 'ctransformers.AutoModelForCausalLM', 'model_inference_function': 'from_pretrained', 'model_params': {'model_path': 'jeffmeloy/WestLake-7B-v2.Q8_0.gguf', 'model_type': 'mistral', 'local_files_only': False, 'threads': 16, 'batch_size': 512, 'context_length': 28000, 'max_new_tokens': 16000, 'gpu_layers': 100, 'reset': True}}}\n    return model_config"
        function_docstring: "Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    "
        function_inputs: []
        function_defaults: []
        function_returns:
        - model_config
        function_calls: []
        function_call_inputs: {}
        function_variables:
        - model_config
        function_decorators: []
        function_annotations: []
        function_properties: []
    get_start_dir:
        function_name: get_start_dir
        function_code: "def get_start_dir(start_dir: str='') -> str:\n    \"\"\"\n    Returns the appropriate start directory.\n    Args:\n        start_dir (str): The directory to start the search from.\n    Returns:\n        str: The absolute path of the provided start_dir if it exists or can be created.\n    \"\"\"\n    if start_dir and (not Path(start_dir).is_dir()):\n        logging.info(f'Setting Start Dir : {start_dir}')\n        start_dir = os.getcwd()\n    else:\n        start_dir = os.path.abspath(start_dir)\n    return start_dir"
        function_docstring: "\n    Returns the appropriate start directory.\n    Args:\n        start_dir (str): The directory to start the search from.\n    Returns:\n        str: The absolute path of the provided start_dir if it exists or can be created.\n    "
        function_inputs:
        - start_dir
        function_defaults:
        - ''''''
        function_returns:
        - start_dir
        function_calls:
        - Path(start_dir).is_dir
        - Path
        - logging.info
        - os.getcwd
        - os.path.abspath
        function_call_inputs:
            Path(start_dir).is_dir: []
            Path:
            - start_dir
            logging.info:
            - 'f''Setting Start Dir : {start_dir}'''
            os.getcwd: []
            os.path.abspath:
            - start_dir
        function_variables:
        - start_dir
        function_decorators: []
        function_annotations: []
        function_properties: []
    get_output_dir:
        function_name: get_output_dir
        function_code: "def get_output_dir(output_dir: str='') -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f'Using output directory: {output_dir}')\n    return output_dir"
        function_docstring: "Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    "
        function_inputs:
        - output_dir
        function_defaults:
        - ''''''
        function_returns:
        - output_dir
        function_calls:
        - os.path.abspath
        - os.makedirs
        - logging.info
        function_call_inputs:
            os.path.abspath:
            - output_dir or OUTPUT_DIR
            os.makedirs:
            - output_dir
            logging.info:
            - 'f''Using output directory: {output_dir}'''
        function_variables:
        - output_dir
        function_decorators: []
        function_annotations: []
        function_properties: []
    get_questions:
        function_name: get_questions
        function_code: "def get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try:\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, 'r') as f:\n            questions = json.load(f)\n        logging.info(f'Using questions from file: {questions_pathname}')\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(f'Questions file not valid: {questions_pathname} Using default questions')\n        questions = get_default_questions()\n    return questions"
        function_docstring: "\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    "
        function_inputs:
        - questions_pathname
        function_defaults: []
        function_returns:
        - questions
        function_calls:
        - os.path.join
        - os.getcwd
        - open
        - json.load
        - logging.info
        - get_default_questions
        function_call_inputs:
            os.path.join:
            - os.getcwd()
            - QUESTIONS_FILE
            os.getcwd: []
            open:
            - questions_pathname
            - '''r'''
            json.load:
            - f
            logging.info:
            - 'f''Using questions from file: {questions_pathname}'''
            - 'f''Questions file not valid: {questions_pathname} Using default questions'''
            get_default_questions: []
        function_variables:
        - questions_pathname
        - questions
        function_decorators: []
        function_annotations: []
        function_properties: []
    instantiate_model:
        function_name: instantiate_model
        function_code: "def instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config['model_import_path'].rsplit('.', 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config['model_params']\n        inference_function_name = model_config['model_inference_function']\n        if inference_function_name != '':\n            inference_function = getattr(ModelClass, inference_function_name)\n            llm = inference_function(model_params.pop('model_path'), **model_params)\n        else:\n            llm = ModelClass(model_params.pop('model_path'), **model_params)\n        return llm\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f'Failed to instantiate the model. Error: {e}')\n        return None"
        function_docstring: "\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    "
        function_inputs:
        - model_config
        function_defaults: []
        function_returns:
        - llm
        - None
        function_calls:
        - model_config['model_import_path'].rsplit
        - getattr
        - importlib.import_module
        - inference_function
        - model_params.pop
        - ModelClass
        - logging.info
        function_call_inputs:
            model_config['model_import_path'].rsplit:
            - '''.'''
            - '1'
            getattr:
            - importlib.import_module(module_name)
            - class_name
            - ModelClass
            - inference_function_name
            importlib.import_module:
            - module_name
            inference_function:
            - model_params.pop('model_path')
            model_params.pop:
            - '''model_path'''
            - '''model_path'''
            ModelClass:
            - model_params.pop('model_path')
            logging.info:
            - 'f''Failed to instantiate the model. Error: {e}'''
        function_variables:
        - ModelClass
        - inference_function
        - model_params
        - inference_function_name
        - model_config
        - llm
        function_decorators: []
        function_annotations: []
        function_properties: []
    get_model:
        function_name: get_model
        function_code: "def get_model(model_config_pathname: str) -> object:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model\n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, 'r') as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f'Using model config from file: {model_config_pathname}')\n    except (FileNotFoundError, yaml.YAMLError):\n        logging.info(f'Model config file not valid: {model_config_pathname} Using default model config')\n        model_config = get_default_model_config()\n    model_config['model'] = instantiate_model(model_config['inference_model'])\n    return model_config"
        function_docstring: "\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model\n    "
        function_inputs:
        - model_config_pathname
        function_defaults: []
        function_returns:
        - model_config
        function_calls:
        - os.path.join
        - os.getcwd
        - open
        - yaml.safe_load
        - logging.info
        - get_default_model_config
        - instantiate_model
        function_call_inputs:
            os.path.join:
            - os.getcwd()
            - MODEL_CONFIG_FILE
            os.getcwd: []
            open:
            - model_config_pathname
            - '''r'''
            yaml.safe_load:
            - config_file
            logging.info:
            - 'f''Using model config from file: {model_config_pathname}'''
            - 'f''Model config file not valid: {model_config_pathname} Using default model config'''
            get_default_model_config: []
            instantiate_model:
            - model_config['inference_model']
        function_variables:
        - model_config_pathname
        - model_config
        function_decorators: []
        function_annotations: []
        function_properties: []
    write_questions_file:
        function_name: write_questions_file
        function_code: "def write_questions_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), 'w') as file:\n        json.dump(questions, file, indent=4)"
        function_docstring: "\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    "
        function_inputs:
        - output_dir
        function_defaults:
        - ''''''
        function_returns: []
        function_calls:
        - get_default_questions
        - Path(output_dir).is_dir
        - Path
        - os.getcwd
        - open
        - os.path.join
        - json.dump
        function_call_inputs:
            get_default_questions: []
            Path(output_dir).is_dir: []
            Path:
            - output_dir
            os.getcwd: []
            open:
            - os.path.join(output_dir, QUESTIONS_FILE)
            - '''w'''
            os.path.join:
            - output_dir
            - QUESTIONS_FILE
            json.dump:
            - questions
            - file
        function_variables:
        - output_dir
        - questions
        function_decorators: []
        function_annotations: []
        function_properties: []
    write_model_config_file:
        function_name: write_model_config_file
        function_code: "def write_model_config_file(output_dir: str='') -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), 'w') as file:\n        yaml.dump(model_config, file)"
        function_docstring: "\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    "
        function_inputs:
        - output_dir
        function_defaults:
        - ''''''
        function_returns: []
        function_calls:
        - get_default_model_config
        - Path(output_dir).is_dir
        - Path
        - os.getcwd
        - open
        - os.path.join
        - yaml.dump
        function_call_inputs:
            get_default_model_config: []
            Path(output_dir).is_dir: []
            Path:
            - output_dir
            os.getcwd: []
            open:
            - os.path.join(output_dir, MODEL_CONFIG_FILE)
            - '''w'''
            os.path.join:
            - output_dir
            - MODEL_CONFIG_FILE
            yaml.dump:
            - model_config
            - file
        function_variables:
        - output_dir
        - model_config
        function_decorators: []
        function_annotations: []
        function_properties: []
classes: {}
