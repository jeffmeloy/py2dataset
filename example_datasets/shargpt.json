[
    {
        "conversation": [
            {
                "from": "system",
                "value": "code documentation: I) The purpose of 'py2dataset\\get_code_graph.py' is to analyze Python source code files and generate detailed documentation related to its structure, control flow, and visual representation using PlantUML activity diagrams. It primarily employs parsing through various elements from abstract syntax tree (AST) produced by python-mode analyzing token sequences obtained as output. Several distinct yet complementary functionalities serve separate yet intricate processes which interact for fulfilling overall task. Below given breakup sheds light on every component in this module:\n\n1. 'code_graph': It builds a dictionary representing nodes and edges for relationships found in Python file summaries with the aid of networkx package's DiGraph(). Nodes stand for function names, class method details, and classes themselves. Edges are formed based on calls between functions or methods within the codebase. Edge data holds input/output information for better understanding of flow control.\n\n2. 'get_edge_data_from_details': This helper function extracts edge data from target details (function return values) and source details (function call inputs). It returns a dictionary with 'target_inputs' and 'target_returns'.\n\n3. 'add_edge_with_data': Adding edges to the code graph along with associated data based on node type classification, utilizing 'get_edge_data_from_details'. It considers functions, class methods, and special control structures like try/except blocks for detailed representation.\n\n4. 'add_edges_for_calls': Determining the connections in source functions to targeted call functions from class/instance details while respecting proper fully-qualified method names during execution of program operations like file iterations & handling exceptional conditions if applicable.\n\n5. 'extract_control_flow_tree': Creates control flow trees (Python abstracted statements and conditional logic), segregated for try blocks including its sub-clauses along with handling classes/definitions in Python source code as nodes or leaf strings representing distinct activities. This traverses the AST node-by-node for proper parsing & mapping purposes.\n\n6. 'reorganize_control_flow': Modifies extracted control flow structures according to the graph obtained from 'code_graph' function, ensuring starting points match the code graph's nodes. It recursively processes elements until all control flow parts are accounted for in an organized manner.\n\n7. 'get_plantUML_element': Generates PlantUML code snippets for each element within the control flow structure with clear hints for try/except blocks, providing visual representation of Python program's logic flow.\n\n8. 'get_plantUML': Gathers all generated PlantUML elements from previous steps into a single string representing entire file activity diagram using '@startuml' and '@enduml' markers as standard PlantUML syntax requirements.\n\n9. 'get_code_graph': Combines code graph generation, control flow extraction, and PlantUML creation into one cohesive process by calling all previously mentioned functions. It handles exceptions during execution and returns the entire code graph, reorganized control flow structure, and final PlantUML diagram code.\n\nII) Requirements Summary:\n[req01] 'code_graph': Constructs file details dictionary with nodes (functions/classes) & edges (function calls).\n[req02] 'extract_control_flow_tree': Parses AST to create control flow tree representation.\n[req03] 'reorganize_control_flow': Adjusts control flow structure as per code graph's starting points for organized understanding.\n[req04] 'get_plantUML_element': Prepares plantUML representation elements individually (elements include method def, control logic and blocks).\n[req05] 'get_plantUML': Constructs comprehensive plantUML diagram code from extracted elements.\n[req06] 'get_code_graph': Integrates code graph, control flow structure & PlantUML generation for entire file analysis.\n\nAPI Signatures:\ncode_graph(file_summary): Returns a dictionary with nodes and edges representing relationships in the code.\nget_edge_data_from_details(target_details, source_details, target): Returns edge data from details of target and source elements.\nadd_edge_with_data(source, target[, init_method]): Adds an edge with data to the graph.\nadd_edges_for_calls(source_name, calls): Handles edges for function/class method calls.\nextract_control_flow_tree(nodes): Extracts control flow tree from input list of nodes extracted using AST parsing.\nreorganize_structure(structure, start_points): Organizes structured data as per given start points (mostly recursive).\nget_plantUML_element(element, indentation): Creates plantUML code for each element with clear hints for try/except blocks.\nget_plantUML(control_flow_structure): Compiles whole file activity diagram's plantUML code string using collected elements from all methods calls before.\nget_code_graph(file_summary, file_ast): Combines code graph creation, control flow extraction & PlantUML generation for entire Python file analysis while handling exceptions.\n\nIII) Inputs and Variables Description:\nDepending on context:\ncode_graph -> 'file_summary' consists of details from analyzed tokens with node separation like function definitions/calls & class structures (dictionaries), AST tree is absent here but utilized by 'extract_control_flow_tree'. It uses 'nx.DiGraph()', 'function_details_lookup', 'class_method_details_lookup', 'edges', 'nodes', 'G' as graph object, etc.\nget_edge_data_from_details -> 'target_details', 'source_details', 'target' are parsed data from function/class method details lookup dictionaries; 'edge_data' holds extracted information for edge properties.\nadd_edge_with_data -> 'source', 'target', 'init_method' represents node identities; classifications aid in connecting related functions or methods ('class_names', 'method_name', etc.).\nadd_edges_for_calls -> 'source_name', 'calls' contain function/class method names and their respective calls.\nextract_control_flow_tree -> 'nodes' are AST nodes for parsing control flow tree generation.\nreorganize_control_flow -> 'code_graph', 'control_flow_structure' is organized output after graph & flow processing, 'starting_points', 'seen', 'element_id' help in recursive structuring.\nreorganize_structure -> 'structure', 'start_points' are control flow elements to be rearranged as per starting points.\nget_plantUML_element -> 'element', 'indentation' denotes current level of indentation for plantUML code generation; 'key', 'value', 'condition', 'exception_condition', etc., are used during processing.\nget_plantUML -> 'control_flow_structure' is parsed control flow tree data, 'plantuml_str' accumulates final PlantUML diagram code string.\nget_code_graph -> 'file_summary', 'file_ast' represents Python file details & AST respectively; 'entire_code_graph', 'control_flow_structure', 'plantUML' are results of combined processing steps while handling exceptions ('Exception as e')."
            },
            {
                "from": "human",
                "value": "Output the Python code described by the code documentation."
            },
            {
                "from": "gpt",
                "value": "```python\n\"\"\"\nRequirements\n[req01] The code_graph function performs the following:\n        a. Extracts the function and class method details from the file summary.\n        b. Creates a lookup dictionary for function and class method details.\n        c. Creates a directed graph with nodes and edges representing the relationships in the code.\n        d. Adds edges for function and class method calls.\n        e. Adds edge data to edges.\n        f. Returns a dictionary with nodes and edges representing the relationships in the code.\n[req02] The extract_control_flow_tree function performs the following:\n        a. Extracts control flow tree from AST.\n        b. Returns control flow tree.\n[req03] The reorganize_control_flow function performs the following:\n        a. Gets starting points from the code graph.\n        b. Reorganizes the control flow structure recursively.\n        c. Returns reorganized control flow structure.\n[req04] The get_plantUML_element function performs the following:\n        a. Gets plantUML code for each element.\n        b. Returns plantUML code for each element.\n[req05] The get_plantUML function performs the following: \n        a. Gets plantUML code for entire file.\n        b. Returns plantUML code for entire file.\n[req06] The get_code_graph function performs the following:\n        a. Gets the entire code graph\n        b. Gets the control flow structure\n        c. Gets the plantUML code\n        d. Returns entire code graph, control flow structure and plantUML code\n\"\"\"\nimport ast\nimport json\nfrom typing import Dict, List, Optional, Union\nimport networkx as nx\n\n\ndef code_graph(\n    file_summary: Dict[str, Union[Dict, str]],\n) -> Dict[str, Union[List[str], Dict[str, List[str]]]]:\n    \"\"\"\n    Create a dictionary representation of file details.\n    Args:\n        file_summary: Dict[str, Union[Dict, str]]: The details extracted from the file.\n    Returns:\n        dict: A dictionary with nodes and edges representing the relationships in the code.\n    \"\"\"\n    G = nx.DiGraph()\n\n    # Create lookup dictionaries for function and class method details\n    function_details_lookup = {}\n    for function_def in file_summary[\"function_defs\"]:\n        function_details_lookup.update(function_def)\n    class_method_details_lookup = {}\n    for class_def in file_summary[\"class_defs\"]:\n        for (\n            class_name,\n            class_details,\n        ) in class_def.items():  # Extract class name and details\n            G.add_node(class_name)  # Add class as a graph node\n            for method_name, method_details in class_details[\"method_defs\"].items():\n                qualified_method_name = (\n                    f\"{class_name}.{method_name}\"  # Create method fully qualified name\n                )\n                G.add_node(qualified_method_name)  # Add method as a graph node\n                class_method_details_lookup[\n                    qualified_method_name\n                ] = method_details  # Store method details\n                G.add_edge(\n                    class_name, qualified_method_name\n                )  # Add edge from class to method\n\n    # Helper function to extract edge data from target details\n    def get_edge_data_from_details(\n        target_details: dict, source_details: dict, target: str\n    ) -> dict:\n        edge_data = {}\n        if target_details:\n            edge_data[\"target_inputs\"] = target_details.get(\"inputs\")\n            edge_data[\"target_returns\"] = list(set(target_details.get(\"returns\", [])))\n        if (\n            source_details\n            and \"call_inputs\" in source_details\n            and target in source_details[\"call_inputs\"]\n        ):\n            edge_data[\"target_inputs\"] = source_details[\"call_inputs\"][target]\n        return edge_data\n\n    # Helper function to add edge with data\n    def add_edge_with_data(\n        source: str, target: str, init_method: Optional[str] = None\n    ) -> None:\n        target_details = class_method_details_lookup.get(\n            init_method or target\n        ) or function_details_lookup.get(target)\n        source_details = function_details_lookup.get(\n            source\n        ) or class_method_details_lookup.get(source)\n        G.add_edge(\n            source,\n            target,\n            **get_edge_data_from_details(target_details, source_details, target),\n        )\n\n    # Helper function to add edges for function or class method calls\n    def add_edges_for_calls(source_name, calls):\n        class_names = [\n            list(class_def.keys())[0] for class_def in file_summary[\"class_defs\"]\n        ]\n        for called in calls:\n            called_class_name = called.split(\".\")[0]\n            if called.startswith(\"self.\"):\n                method_name = called.replace(\"self.\", \"\")\n                fully_qualified_name = f\"{source_name.split('.')[0]}.{method_name}\"\n                if fully_qualified_name in class_method_details_lookup:\n                    add_edge_with_data(source_name, fully_qualified_name)\n                    continue\n            if (\n                called in function_details_lookup\n                or called in class_method_details_lookup\n                or f\"{source_name.split('.')[0]}.{called}\"\n                in class_method_details_lookup\n            ):\n                add_edge_with_data(source_name, called)\n            elif called_class_name in class_names:\n                init_method = None\n                init_method_name = f\"{called}.__init__\"\n                if init_method_name in class_method_details_lookup:\n                    init_method = init_method_name\n                add_edge_with_data(source_name, called, init_method)\n            else:\n                G.add_node(called)\n                add_edge_with_data(source_name, called)\n\n    # Add function nodes to graph and edges for function calls\n    for function_name in function_details_lookup:\n        G.add_node(function_name)\n    for func_name, details in function_details_lookup.items():\n        add_edges_for_calls(func_name, details[\"calls\"])\n\n    # Add edges for method calls\n    for qualified_method_name, details in class_method_details_lookup.items():\n        add_edges_for_calls(qualified_method_name, details[\"calls\"])\n\n    # Add edge data to edges and create node and edges to return\n    for edge in G.edges:\n        source, target = edge\n        target_details = function_details_lookup.get(\n            target\n        ) or class_method_details_lookup.get(target)\n        source_details = function_details_lookup.get(\n            source\n        ) or class_method_details_lookup.get(source)\n        edge_data = get_edge_data_from_details(target_details, source_details, target)\n        G[source][target].update(edge_data)\n    nodes = list(G.nodes)\n    edges = [\n        {\"source\": edge[0], \"target\": edge[1], **edge[2]} for edge in G.edges.data()\n    ]\n\n    return {\"nodes\": nodes, \"edges\": edges}\n\n\ndef extract_control_flow_tree(nodes: List[ast.AST]) -> List[Union[str, dict]]:\n    \"\"\"\n    Extract control flow tree from AST.\n    Args:\n        nodes: AST nodes\n    Returns:\n        control_flow_tree: control flow tree\n    \"\"\"\n    control_flow_tree = []\n    node_keywords_map = {\n        ast.FunctionDef: \"def\",\n        ast.AsyncFunctionDef: \"def\",\n        ast.ClassDef: \"class\",\n        ast.While: \"while\",\n        ast.For: \"for\",\n        ast.AsyncFor: \"for\",\n        ast.With: \"with\",\n        ast.AsyncWith: \"with\",\n        ast.Return: \"return\",\n        ast.If: \"if\",\n        ast.Try: \"try\",\n    }\n\n    for node in nodes:\n        node_type = type(node)\n        if node_type not in node_keywords_map:\n            control_flow_tree.append(ast.unparse(node))\n            continue\n        keyword = node_keywords_map[node_type]\n\n        if keyword == \"def\":\n            args_str = \", \".join([ast.unparse(arg) for arg in node.args.args])\n            key = f\"def {node.name}({args_str})\"\n            value = extract_control_flow_tree(node.body)\n            control_flow_tree.append({key: value})\n        elif keyword == \"class\":\n            key = f\"class {node.name}\"\n            value = extract_control_flow_tree(node.body)\n            control_flow_tree.append({key: value})\n        elif keyword == \"while\":\n            key = f\"while {ast.unparse(node.test)}\"\n            value = extract_control_flow_tree(node.body)\n            control_flow_tree.append({key: value})\n        elif keyword == \"for\":\n            key = f\"for {ast.unparse(node.target)} in {ast.unparse(node.iter)}\"\n            value = extract_control_flow_tree(node.body)\n            control_flow_tree.append({key: value})\n        elif keyword == \"with\":\n            key = f\"with {', '.join([ast.unparse(item) for item in node.items])}\"\n            value = extract_control_flow_tree(node.body)\n            control_flow_tree.append({key: value})\n        elif keyword == \"return\":\n            key = \"return\"\n            value = [ast.unparse(node.value)] if node.value is not None else []\n            control_flow_tree.append({key: value})\n        elif keyword == \"if\":\n            key = f\"if {ast.unparse(node.test)}\"\n            value = extract_control_flow_tree(node.body)\n            if_block = {key: value}\n            orelse = node.orelse\n            while orelse and isinstance(orelse[0], ast.If):\n                key = f\"elif {ast.unparse(orelse[0].test)}\"\n                value = extract_control_flow_tree(orelse[0].body)\n                if_block[key] = value\n                orelse = orelse[0].orelse\n            if orelse:\n                key = \"else\"\n                value = extract_control_flow_tree(orelse)\n                if_block[key] = value\n            control_flow_tree.append(if_block)\n        elif keyword == \"try\":\n            try_block = extract_control_flow_tree(node.body)\n            except_block = []\n            for handler in node.handlers:\n                h_type = ast.unparse(handler.type) if handler.type is not None else \"\"\n                h_name = (\n                    ast.unparse(handler.name)\n                    if isinstance(handler.name, ast.Name)\n                    else \"\"\n                )\n                key = f\"except {h_type} as {h_name}:\"\n                value = extract_control_flow_tree(handler.body)\n                except_block.append({key: value})\n            control_flow_dict = {\"try\": try_block, \"except\": except_block}\n            if node.orelse:\n                else_block = extract_control_flow_tree(node.orelse)\n                control_flow_dict[\"else\"] = else_block\n            if node.finalbody:\n                finally_block = extract_control_flow_tree(node.finalbody)\n                control_flow_dict[\"finally\"] = finally_block\n            control_flow_tree.append(control_flow_dict)\n        else:\n            control_flow_tree.append(ast.unparse(node))\n\n    return control_flow_tree\n\n\ndef reorganize_control_flow(code_graph, control_flow_structure):\n    \"\"\"\n    Reorganize control flow structure to match the code graph.\n    Args:\n        file_details: file details\n        control_flow_structure: control flow structure\n    Returns:\n        reorganized_control_flow_structure: reorganized control flow structure\n    \"\"\"\n    # Get starting points from the code graph as those\n    targets = [edge[\"target\"] for edge in code_graph[\"edges\"]]\n    starting_points = [node for node in code_graph[\"nodes\"] if node not in targets]\n\n    # Define a function to reorganize the structure recursively\n    def reorganize_structure(structure, start_points):\n        organized, seen = [], set()\n\n        # Iterate through each start point and find matching elements in structure\n        for start in start_points:\n            for element in structure:\n                if isinstance(element, dict):\n                    key = next(iter(element))  # Get the first key of the dictionary\n                    if (\n                        start in key\n                    ):  # Add element if it matches the start point and hasn't been seen\n                        element_id = json.dumps(element)\n                        if element_id not in seen:\n                            organized.append(element)\n                            seen.add(element_id)\n                elif (\n                    isinstance(element, str) and start in element\n                ):  # Handle string elements\n                    organized.append(element)\n\n        # Append elements not included in the organized list\n        remaining = [elem for elem in structure if json.dumps(elem) not in seen]\n        organized.extend(remaining)\n        return organized\n\n    # Reorganize the control flow structure recursively\n    return reorganize_structure(control_flow_structure, starting_points)\n\n\ndef get_plantUML_element(element: dict, indentation=\"\") -> str:\n    \"\"\"\n    Get plantUML code for each element, including clear hints for try/except blocks.\n    Args: \n        element: control flow element\n        indentation: current indentation\n    Returns:\n        plantuml_str: plantUML code for each element\n    \n    \"\"\"\n    plantuml_str = \"\"\n\n    if isinstance(element, dict):\n        key = next(iter(element))\n        value = element[key]\n        if \"def\" in key or \"class\" in key:\n            plantuml_str += f'{indentation}: {key};\\n'\n            inner_indentation = indentation + \"    \"\n            for item in value:\n                plantuml_str += get_plantUML_element(item, inner_indentation)\n        elif \"if\" in key or \"while\" in key or \"for\" in key:\n            condition = key.replace(\"if \", \"\").replace(\"while \", \"\").replace(\"for \", \"\")\n            plantuml_str += f'{indentation}if ({condition}) then (yes)\\n'\n            inner_indentation = indentation + \"    \"\n            for item in value:\n                plantuml_str += get_plantUML_element(item, inner_indentation)\n            plantuml_str += f'{indentation}endif\\n'\n        elif \"try\" in key: # Mark the start of a try block\n            plantuml_str += f'{indentation}partition \"try\" {{\\n'\n            inner_indentation = indentation + \"    \"\n            for item in value:\n                plantuml_str += get_plantUML_element(item, inner_indentation)\n            plantuml_str += f'{indentation}}}\\n'\n        elif \"except\" in key: # Mark the start of an except block\n            exception_condition = key.replace(\"except \", \"\")\n            plantuml_str += f'{indentation}partition \"except {exception_condition}\" {{\\n'\n            inner_indentation = indentation + \"    \"\n            for item in value:\n                plantuml_str += get_plantUML_element(item, inner_indentation)\n            plantuml_str += f'{indentation}}}\\n'\n        else:\n            plantuml_str += f\"{indentation}: {key};\\n\"\n    elif isinstance(element, str):\n        plantuml_str += f\"{indentation}: {element};\\n\"\n\n    return plantuml_str\n\n\ndef get_plantUML(control_flow_structure: List[Union[str, dict]]) -> str:\n    \"\"\"\n    Get plantUML activity diagram code for entire file.\n    Args:\n        file_details: file details\n    Returns:\n        plantuml_str: plantUML code for entire file\n    \"\"\"\n    plantuml_str = \"@startuml\\n\"\n    for element in control_flow_structure:\n        plantuml_str += get_plantUML_element(element, \"  \")\n    plantuml_str += \"end\\n@enduml\"\n    return plantuml_str\n\n\ndef get_code_graph(file_summary: dict, file_ast: ast.AST) -> (dict, list, str):\n    \"\"\"\n    Add code graph and control flow to file details.\n    Args:\n        file_details: file details\n    Returns:\n        file_details: file details\n    \"\"\"\n    try:\n        entire_code_graph = code_graph(file_summary)\n        control_flow_tree = extract_control_flow_tree(file_ast.body)\n        control_flow_structure = reorganize_control_flow(\n            entire_code_graph, control_flow_tree\n        )\n        plantUML = get_plantUML(control_flow_structure)\n    except Exception as e:\n        control_flow_structure = [str(e)]\n        plantUML = str(e)\n\n    return entire_code_graph, control_flow_structure, plantUML\n\n```"
            }
        ],
        "nbytes": 22923,
        "source": "py2dataset/get_code_graph.py"
    },
    {
        "conversation": [
            {
                "from": "system",
                "value": "code documentation: In this provided Python code, there are multiple utilitarian functions dedicated to managing input data parameters related to a dataset processing system called \"py2dataset.\" The key functionality offered can be organized around several distinct modules: question handling, model setup configuration, output directory handling, and file I/O operations for configuration saving.\n\n1. Question Handling Functions:\na. `get_default_questions()` returns a list of default questions used by the system in JSON format. These questions serve as prompts for analyzing Python files or code snippets during documentation generation. Each question dictionary has 'id', 'text', and 'type' keys defining its unique identifier, textual content, and category (file, function, method, class).\nb. `get_questions(questions_pathname)` attempts to fetch questions from a given file path if valid or uses default questions otherwise. It throws exceptions on invalid files or missing JSON format.\n\n2. Model Setup Configuration Functions:\na. `get_default_model_config()` returns a dictionary representing the default configuration for the language model used in the system. This includes system and instruction prompts, as well as parameters for initializing an inference model from Hugging Face's Transformers library (\"ctransformers\"). The dictionary holds settings related to the language generation process.\nb. `get_model(model_config_pathname)` fetches either default or custom model configuration depending on the provided file path validity. It instantiates a language model object using imported classes and specified parameters. If no config file is given, it uses defaults.\n\n3. Output Directory Handling Functions:\na. `get_start_dir(start_dir)` returns an absolute directory path either from the provided input or current working directory (cwd). It creates the directory if necessary but logs information about this operation for user notification.\nb. `get_output_dir(output_dir)` follows the same process but generates output files specifications specifically while guaranteeing path creation upon usage when specified directories do not exist yet.\n\n4. File Input/Output Functions:\na. `write_questions_file(output_dir)` saves default questions as JSON formatted text into the given directory or current working directory if no output directory is provided or invalid. It uses `json.dump()`.\nb. `write_model_config_file(output_dir)` writes default model configuration as YAML formatted content in specified output location, which again falls back to cwd otherwise. `yaml.dump()` ensures formatting appropriately for easy comprehension during program use.\n\nThese components facilitate retrieval or customization of analysis parameters as well as enabling language modeling outcomes aligned with described software development needs like context examination across a Python script analyzing various programming aspects while incorporating details of object relations such as file structure, function call relationships, return statements and overall documentation generation for advanced computer science courses."
            },
            {
                "from": "human",
                "value": "Output the Python code described by the code documentation."
            },
            {
                "from": "gpt",
                "value": "```python\n\"\"\"\nObtain data parameter and model from the py2dataset functions.\nRequirements:\n[req01] The `get_default_questions` function shall:\n        a. Return a list of default questions.\n        b. Ensure each question in the list is a dictionary.\n        c. Ensure each dictionary has the keys: id, text, and type.\n[req02] The `get_default_model_config` function shall:\n        a. Return a dictionary representing the default model configuration.\n[req03] The `get_output_dir` function shall:\n        a. Accept an optional output_dir argument.\n        b. Return the absolute path of the provided output_dir if it exists or can be created.\n        c. Return the default OUTPUT_DIR if the provided output_dir argument is not provided or invalid.\n[req04] The `get_questions` function shall:\n        a. Accept an optional questions_pathname argument.\n        b. Validate the question file provided by the questions_pathname.\n        c. Return the questions from the provided questions_pathname if valid.\n        d. Return default questions if the questions_pathname is not provided or invalid.\n[req05] The `instantiate_model` function shall:\n        a. Accept a model_config dictionary as an argument.\n        b. Import the specified module and class from the model_config.\n        c. Instantiate and return the model using the provided configuration.\n[req06] The `get_model` function shall:\n        a. Accept an optional model_config_pathname argument.\n        b. Validate the model config file provided by the model_config_pathname.\n        c. Return an instantiated model and a prompt template based on the provided configuration.\n        d. Return an instantiated model and a prompt template based on the default model configuration if the model_config_pathname is not provided or invalid.\n[req07] The `write_questions_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default questions to the QUESTIONS_FILE in the specified directory.\n        c. Write the default questions to the QUESTIONS_FILE in the current working directory if the output_dir argument is not provided or invalid.\n[req08] The `write_model_config_file` function shall:\n        a. Accept an optional output_dir argument.\n        b. Write the default model configuration to the MODEL_CONFIG_FILE in the specified directory.\n        c. Write the default model configuration to the MODEL_CONFIG_FILE in the current working directory if the output_dir argument is not provided or invalid.\n\"\"\"\nimport os\nimport json\nimport logging\nimport importlib\nfrom typing import Dict, List\nfrom pathlib import Path\nimport yaml\n\n# Setting up a basic logger\nlogging.basicConfig(level=logging.INFO)\n\n# defaults if provided inputs fail\nQUESTIONS_FILE = \"py2dataset_questions.json\"\nMODEL_CONFIG_FILE = \"py2dataset_model_config.yaml\"\nOUTPUT_DIR = \"datasets\"\n\n\ndef get_default_questions() -> List[Dict]:\n    \"\"\"Return default question list\n    Args:\n        None\n    Returns:\n        List[Dict]: The default question list\n    \"\"\"\n    questions = [\n        {\n            \"id\": \"file_dependencies\",\n            \"text\": \"Dependencies in Python file: `{filename}`?\",\n            \"type\": \"file\",\n        },\n        {\n            \"id\": \"entire_code_graph\",\n            \"text\": \"Call code graph in Python file: `{filename}`?\",\n            \"type\": \"file\",\n        },\n        {\n            \"id\": \"file_functions\",\n            \"text\": \"Functions in Python file: `{filename}`?\",\n            \"type\": \"file\",\n        },\n        {\n            \"id\": \"file_classes\",\n            \"text\": \"Classes in Python file: `{filename}`?\",\n            \"type\": \"file\",\n        },\n        {\n            \"id\": \"function_inputs\",\n            \"text\": \"Inputs to `{function_name}` in Python file: `{filename}`?\",\n            \"type\": \"function\",\n        },\n        {\n            \"id\": \"function_docstring\",\n            \"text\": \"Docstring of `{function_name}` in Python file: `{filename}`?\",\n            \"type\": \"function\",\n        },\n        {\n            \"id\": \"function_calls\",\n            \"text\": \"Calls made in `{function_name}` in Python file: `{filename}`?\",\n            \"type\": \"function\",\n        },\n        {\n            \"id\": \"function_variables\",\n            \"text\": \"Variables in `{function_name}` in Python file: `{filename}`?\",\n            \"type\": \"function\",\n        },\n        {\n            \"id\": \"function_returns\",\n            \"text\": \"Returns from `{function_name}` in Python file: `{filename}`?\",\n            \"type\": \"function\",\n        },\n        {\n            \"id\": \"class_methods\",\n            \"text\": \"Methods in `{class_name}` in Python file: `{filename}`?\",\n            \"type\": \"class\",\n        },\n        {\n            \"id\": \"class_docstring\",\n            \"text\": \"Docstring of `{class_name}` in Python file: `{filename}`?\",\n            \"type\": \"class\",\n        },\n        {\n            \"id\": \"class_attributes\",\n            \"text\": \"Attributes of `{class_name}` in Python file: `{filename}`?\",\n            \"type\": \"class\",\n        },\n        {\n            \"id\": \"class_inheritance\",\n            \"text\": \"Inheritance of `{class_name}` in Python file: `{filename}`?\",\n            \"type\": \"class\",\n        },\n        {\n            \"id\": \"method_inputs\",\n            \"text\": \"Inputs to `{method_name}` in Python file: `{filename}`?\",\n            \"type\": \"method\",\n        },\n        {\n            \"id\": \"method_docstring\",\n            \"text\": \"Docstring of `{method_name}` in Python file: `{filename}`?\",\n            \"type\": \"method\",\n        },\n        {\n            \"id\": \"method_calls\",\n            \"text\": \"Calls made in `{method_name}` in Python file: `{filename}`?\",\n            \"type\": \"method\",\n        },\n        {\n            \"id\": \"method_variables\",\n            \"text\": \"Variables in `{method_name}` in Python file: `{filename}`?\",\n            \"type\": \"method\",\n        },\n        {\n            \"id\": \"method_returns\",\n            \"text\": \"Returns from `{method_name}` in Python file: `{filename}`?\",\n            \"type\": \"method\",\n        },\n        {\n            \"id\": \"file_purpose\",\n            \"text\": \"I) Describe the Purpose and Processing Approach for Python file: `{filename}`; II) Define detailed Requirements and API Signatures for all Functions and Class Methods and explain their logic and purpose of the inputs, outputs, variables, returns, and calls.\",\n            \"type\": \"file\",\n        },\n    ]\n    return questions\n\n\ndef get_default_model_config() -> Dict:\n    \"\"\"Return default model config dict\n    Args:\n        None\n    Returns:\n        Dict: The default model config dictionary\n    \"\"\"\n    model_config = {\n        \"system_prompt\": \"Lang: English. Output Format: unformatted, outline. Task: Create software documentation for an advanced computer science course using this code Context:\\n'{context}'\\n\",\n        \"instruction_prompt\": \"Analyze Context to comprehensively describe the purpose and functions of these objects:\\n'{code_objects}'\\n to comply with this instruction:\\n'{query}'\\n\", \n        \"prompt_template\": \"system:\\n{system_prompt}\\n\\ninstruction:n{instruction_prompt}\\n\\ndocumentation:\\n\", \n        \"inference_model\": {\n            \"model_import_path\": \"ctransformers.AutoModelForCausalLM\",\n            \"model_inference_function\": \"from_pretrained\",\n            \"model_params\": {\n                \"model_path\": \"jeffmeloy/WestLake-7B-v2.Q8_0.gguf\",\n                \"model_type\": \"mistral\",\n                \"local_files_only\": False,\n                ## MODEL CONFIGURATION PARAMETERS (params set for model with this HW: GPU: 4090-24GB VRAM, CPU: 5950x-64GB RAM)\n                # avx2 and gpu_layers are not compatible\n                # \"lib\": \"avx2\",\n                \"threads\": 16,\n                \"batch_size\": 512,\n                \"context_length\": 28000,\n                \"max_new_tokens\": 16000,\n                \"gpu_layers\": 100,\n                \"reset\": True,\n            },\n        },\n    }\n    return model_config\n\n\ndef get_start_dir(start_dir: str = \"\") -> str:\n    \"\"\"\n    Returns the appropriate start directory.\n    Args:\n        start_dir (str): The directory to start the search from.\n    Returns:\n        str: The absolute path of the provided start_dir if it exists or can be created.\n    \"\"\"\n    if start_dir and not Path(start_dir).is_dir():\n        logging.info(f\"Setting Start Dir : {start_dir}\")\n        start_dir = os.getcwd()\n    else:\n        start_dir = os.path.abspath(start_dir)\n    return start_dir\n\n\ndef get_output_dir(output_dir: str = \"\") -> str:\n    \"\"\"Returns the appropriate output directory.\n    Args:\n        output_dir (str): The directory to write the output to.\n    Returns:\n        str: The absolute path of the provided output_dir if it exists or can be created.\n    \"\"\"\n    output_dir = os.path.abspath(output_dir or OUTPUT_DIR)\n    os.makedirs(output_dir, exist_ok=True)\n    logging.info(f\"Using output directory: {output_dir}\")\n    return output_dir\n\n\ndef get_questions(questions_pathname: str) -> List[Dict]:\n    \"\"\"\n    Get questions from file or default\n    Args:\n        questions_pathname (str): The pathname of the questions file\n    Returns:\n        List[Dict]: The list of questions\n    \"\"\"\n    try:  # get questions from provided or default configuration file\n        if not questions_pathname:\n            questions_pathname = os.path.join(os.getcwd(), QUESTIONS_FILE)\n        with open(questions_pathname, \"r\") as f:\n            questions = json.load(f)\n        logging.info(f\"Using questions from file: {questions_pathname}\")\n    except (FileNotFoundError, json.decoder.JSONDecodeError):\n        logging.info(\n            f\"Questions file not valid: {questions_pathname} Using default questions\"\n        )\n        questions = get_default_questions()\n    return questions\n\n\ndef instantiate_model(model_config: Dict) -> object:\n    \"\"\"\n    Imports and instantiates a model based on the provided configuration.\n    Args:\n        model_config (dict): model configuration dictionary.\n    Returns:\n        object: An instance of the specified model class, or None if error.\n    \"\"\"\n    try:\n        module_name, class_name = model_config[\"model_import_path\"].rsplit(\".\", 1)\n        ModelClass = getattr(importlib.import_module(module_name), class_name)\n        model_params = model_config[\"model_params\"]\n        inference_function_name = model_config[\"model_inference_function\"]\n        if inference_function_name != \"\":\n            inference_function = getattr(ModelClass, inference_function_name)\n            llm = inference_function(model_params.pop(\"model_path\"), **model_params)\n        else:\n            llm = ModelClass(model_params.pop(\"model_path\"), **model_params)\n        return llm\n    except (ImportError, AttributeError, Exception) as e:\n        logging.info(f\"Failed to instantiate the model. Error: {e}\")\n        return None\n\n\ndef get_model(model_config_pathname: str) -> object:\n    \"\"\"\n    Returns an instantiated model and prompt template based on the model configuration.\n    Agrs:\n        model_config_pathname (str): The pathname of the model config file\n    Returns:\n        Tuple[object, str]: The instantiated model\n    \"\"\"\n    try:\n        if not model_config_pathname:\n            model_config_pathname = os.path.join(os.getcwd(), MODEL_CONFIG_FILE)\n        with open(model_config_pathname, \"r\") as config_file:\n            model_config = yaml.safe_load(config_file)\n        logging.info(f\"Using model config from file: {model_config_pathname}\")\n    except (FileNotFoundError, yaml.YAMLError):\n        logging.info(\n            f\"Model config file not valid: {model_config_pathname} Using default model config\"\n        )\n        model_config = get_default_model_config()\n    model_config[\"model\"] = instantiate_model(model_config[\"inference_model\"])\n\n    return model_config\n\n\ndef write_questions_file(output_dir: str = \"\") -> None:\n    \"\"\"\n    Writes the default questions to a file in JSON format.\n    Args:\n        output_dir (str): The directory to write the questions file to.\n    Returns:\n        None\n    \"\"\"\n    questions = get_default_questions()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, QUESTIONS_FILE), \"w\") as file:\n        json.dump(questions, file, indent=4)\n\n\ndef write_model_config_file(output_dir: str = \"\") -> None:\n    \"\"\"\n    Writes the default model config to a file in YAML format.\n    Args:\n        output_dir (str): The directory to write the model config file to.\n    Returns:\n        None\n    \"\"\"\n    model_config = get_default_model_config()\n    output_dir = output_dir if output_dir and Path(output_dir).is_dir() else os.getcwd()\n    with open(os.path.join(output_dir, MODEL_CONFIG_FILE), \"w\") as file:\n        yaml.dump(model_config, file)\n\n```"
            }
        ],
        "nbytes": 15942,
        "source": "py2dataset/get_params.py"
    },
    {
        "conversation": [
            {
                "from": "system",
                "value": "code documentation: For given Python file 'py2dataset\\get_python_datasets copy 2.py', the core task involves generating datasets from Python code using a dataset generator named DatasetGenerator. It takes various inputs like file path, file details dictionary, base name representing the Python file without extension, question list containing multiple inquiries about different aspects of the code, model configuration (if provided), and a flag indicating detailed explanation requirement.\n\nThe main functionality lies within the DatasetGenerator class with several methods:\n\n1. __init__(): Initializes an instance of DatasetGenerator by assigning input parameters to corresponding attributes like file_path, file_details, base_name, questions, model_config (if provided), detailed flag, and creating attributes related to code response generation such as instruct_list for queries along with code-specific response organization using dicts (code_qa_dict & code_qa_response). Some special mentions here include establishing relations like connecting methods (e.g., function -> functions) through question_mapping attribute.\n\n2. get_response_from_llm(): This method leverages a language model (LLM) to generate responses for complex queries related to Python code understanding. It involves context management, tokenization checks, prompt generation using model configuration templates, LLM call with provided query and context, response extraction & processing from the generated text, updating code_qa_dict based on LLM output, and updating file details accordingly.\n\n3. get_code_qa(): Extracts relevant code objects' responses excluding specific instructions ('Call code graph', 'Docstring') from instruct_list to store them in code_objects_responses dictionary using given base name as key. If LLM is enabled (use_llm flag), it also generates detailed responses for these code objects.\n\n4. get_info_string(): Retrieves comma-separated strings from a given dictionary based on specified item type ('file_variables', 'file_inputs', etc.). It returns unique elements after removing empty strings.\n\n5. process_question(): Handles individual question types like 'file', 'method', or custom ones defined in question_mapping attribute. Depending upon the question type and id, it invokes appropriate processing methods with relevant inputs (filename, class name, method name), code segments from file details dictionary, context generation using Python code snippets, and calls clean_and_get_unique_elements() or get_response_from_llm().\n\n6. process_question_type(): Iterates through questions list and invokes process_question() for each question type ('file', 'method', etc.). It formats query strings with relevant placeholders based on input parameters.\n\n7. generate(): Finally, sorts instruct_list by input length (query size) in reverse order before returning it along with updated DatasetGenerator object attributes like instruct_list containing generated responses to different queries.\n\nComing to the provided instruction set:\n\nI) To describe the purpose and processing approach of 'py2dataset\\get_python_datasets copy 2.py', we can use get_response_from_llm() with an appropriate query as input along with file context. However, this file doesn't contain Python code but rather defines its functionality through DatasetGenerator class methods.\n\nII) Functions in scope are 'clean_and_get_unique_elements', which takes a string input and returns unique elements after cleaning and sorting them alphabetically (case insensitive). It uses regex, list manipulation, set operations, string stripping techniques to achieve this task. As for DatasetGenerator class methods: __init__, get_response_from_llm(), get_code_qa(), get_info_string(), process_question(), process_question_type(), generate(). These functions perform initialization tasks, handle LLM calls with context management, organize code object responses from user queries, retrieve strings related to file requirements, variables, inputs & returns explanation respectively, and generate final dataset outputs.\n\nIII) For explaining purpose of inputs, variables, call, and returns in the code snippets within Python files or classes/methods, we need to invoke process_question() with relevant question types ('file', 'method') and ids corresponding to these aspects. The get_info_string() method can be used to extract unique elements from file details dictionary related to variables and inputs of functions/classes."
            },
            {
                "from": "human",
                "value": "Output the Python code described by the code documentation."
            },
            {
                "from": "gpt",
                "value": "```python\nimport logging\nimport re\nimport math\nfrom typing import Tuple\nimport yaml\n\n\ndef clean_and_get_unique_elements(input_str: str) -> str:\n    elements = re.split(r\",(?=(?:[^{}]|{[^{}]*})*$)\", input_str.strip(\"[]'\\\"\"))\n    return \", \".join(\n        sorted(\n            set(element.strip(\"'\\\" \") for element in elements if element), key=str.lower\n        )\n    )\n\n\nclass DatasetGenerator:\n    def __init__(\n        self,\n        file_path: str,\n        file_details: dict,\n        base_name: str,\n        questions: list[dict],\n        model_config: dict,\n        detailed: bool,\n    ):\n        self.file_path = file_path\n        self.file_details = file_details\n        self.base_name = base_name\n        self.questions = questions\n        if model_config:  # If model_config is not None\n            self.model_config = model_config\n            self.llm = model_config.get(\"model\")\n            self.use_llm = bool(self.llm)\n        else:\n            self.model_config = None\n            self.llm = None\n            self.use_llm = False\n        self.detailed = detailed\n        self.instruct_list = []\n        self.question_mapping = {\n            \"function\": \"functions\",\n            \"class\": \"classes\",\n            \"method\": \"classes\",\n        }\n        self.code_qa_response = \"\"\n        self.code_qa_dict = {}\n\n    def get_response_from_llm(self, query: str, context: str) -> str:\n        context_strategies = [\n            lambda: f\"{context}\",\n            lambda: f\"```python\\n{self.file_details['file_info']['file_code_simplified']}\\n```\",\n            lambda: f\"```python\\n{self.get_info_string(self.file_details['file_info'], 'file_summary')}\\n```\",\n            lambda: \"\",\n        ]\n        max_context_length = self.model_config[\"inference_model\"][\"model_params\"][\n            \"context_length\"\n        ]\n        prompt_template = self.model_config[\"prompt_template\"].format(\n            system_prompt=self.model_config[\"system_prompt\"],\n            instruction_prompt=self.model_config[\"instruction_prompt\"],\n        )\n\n        for strategy in context_strategies:\n            prompt = prompt_template.format(\n                context=strategy(), query=query, code_objects=self.code_qa_response\n            )\n            context_length = len(self.llm.tokenize(prompt))\n            logging.info(f\"***Context: {context_length}\")\n            if context_length <= 0.70 * max_context_length:\n                break\n        else:\n            logging.error(\n                f\"Model response failed, increase py2dataset_model_config.yaml context_length > {math.ceil(len(self.llm.tokenize(prompt))/0.70)}\"\n            )\n            return \"\"\n\n        try:\n            response = (\n                re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", self.llm(prompt))\n                .replace(\"<|im_end|>\", \"\")\n                .replace(\"</|im_end|>\", \"\")\n            )\n            response = \"\\n\".join(line.lstrip() for line in response.split(\"\\n\"))\n            logging.info(f\"***Overall Response: {response}\")\n        except Exception as error:\n            logging.error(f\"Failed to generate model response: {error}\")\n            response = \"\"\n\n        # code_qa_dict is structured like { 'key1': {'key2': 'response2', 'key3': 'response3', 'key4': {'key5': 'response5'}, 'key6': {'key7': 'response7'}...}}\n        # step 1 - loop through the code_qa_dict to obtain the key and value pairs within the code_qa_dict and all nested dictionaries\n        # step 2 - if the value value is a string, then obtain the code type as the f'{higher level key} {lower level key}' as the code_type and the string value the code_object\n        # step 3 - if the value is a dictionary, then skip to the next nested level and repeat step 2\n        # step 4 - construct the prompt and item_response for the current code_type and code_object\n        # step 5 - append the item_response to the corresponding self.instruct_list\n        # step 6 - append the item_response to the corresponding string of the code_qa_dict\n        for code_object, type_responses in self.code_qa_dict.items():\n            for code_type, _ in type_responses.items():\n                item_response = \"\"  # Initialize item_response with an empty string\n                if self.detailed:\n                    try:\n                        query = f\"Describe the Purpose and Significance of {code_type} `{code_object}` and Explain what {code_type} `{code_object}` does in the code.\"\n                        prompt = (\n                            self.model_config[\"prompt_template\"]\n                            .format(\n                                system_prompt=self.model_config[\"system_prompt\"],\n                                instruction_prompt=self.model_config[\n                                    \"instruction_prompt\"\n                                ],\n                            )\n                            .format(\n                                context=f\"{context}\\nCode Summary:\\n{response}\",\n                                query=query,\n                                code_objects=code_object,\n                            )\n                        )\n                        item_response = (\n                            re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", self.llm(prompt))\n                            .replace(\"<|im_end|>\", \"\")\n                            .replace(\"</|im_end|>\", \"\")\n                        )\n                        logging.info(\n                            f\"\\n***Itemized Response: {query}\\n{item_response}\"\n                        )\n                        # remove this line when code below changed.\n                        item_response = f\"\\n- Purpose: {item_response}\"\n                    except Exception as error:\n                        logging.error(f\"Failed to generate model response: {error}\")\n                        item_response = \"\"\n\n                if isinstance(self.code_qa_dict[code_object][code_type], str):\n                    self.code_qa_dict[code_object][code_type] = (\n                        f\"{self.code_qa_dict[code_object][code_type]} {item_response}\".strip()\n                    )\n\n        basename = list(self.code_qa_dict.keys())[0]\n        self.code_qa_dict[basename] = {\n            \"Code Documentation\": [response],\n            **self.code_qa_dict[basename],\n        }\n        self.code_qa_response = (\n            re.sub(\n                r\"\\n\\s*\\n\",\n                \"\\n\",\n                yaml.dump(\n                    self.code_qa_dict,\n                    Dumper=yaml.SafeDumper,\n                    width=float(\"inf\"),\n                    sort_keys=False,\n                    default_flow_style=False,\n                    indent=2,\n                ),\n            )\n            .replace(\"''\", \"'\")\n            .replace(\"\\n    ? '\\n    :\", \"\")\n            .strip('\"')\n            .strip(\"'\")\n            .strip()\n        )\n\n        self.file_details[\"file_info\"][\"code_qa_response\"] = self.code_qa_response\n        self.file_details[\"file_info\"][\"purpose\"] = response\n        return response\n\n    def get_code_qa(self):\n        excluded_instructions = {\"Call code graph\", \"Docstring\"}\n        self.code_qa_dict = {\n            item[\"instruction\"].split(\" in Python file:\")[0]: item[\"output\"]\n            for item in self.instruct_list\n            if not any(\n                item[\"instruction\"].startswith(prefix)\n                for prefix in excluded_instructions\n            )\n        }\n\n        code_objects_responses = {}\n        for instruction, output in self.code_qa_dict.items():\n            code_object = (\n                instruction.split(\"`\")[1] if \"`\" in instruction else instruction\n            )\n            code_type = instruction.split()[0] if \"`\" in instruction else instruction\n            if \"`\" in instruction:\n                code_objects_responses.setdefault(code_object, {})[code_type] = output\n            else:\n                code_objects_responses[code_type] = output\n\n        self.code_qa_dict = {\n            str(self.base_name).replace(\"\\\\\", \"/\"): code_objects_responses\n        }\n\n        print(self.code_qa_dict)\n\n        self.code_qa_response = (\n            re.sub(\n                r\"\\n\\s*\\n\",\n                \"\\n\",\n                yaml.dump(\n                    self.code_qa_dict,\n                    Dumper=yaml.SafeDumper,\n                    width=float(\"inf\"),\n                    sort_keys=False,\n                    default_flow_style=False,\n                    indent=2,\n                ),\n            )\n            .replace(\"''\", \"'\")\n            .strip('\"')\n            .strip(\"'\")\n            .strip()\n        )\n\n        self.file_details[\"file_info\"][\"code_qa_response\"] = self.code_qa_response\n\n    @staticmethod\n    def get_info_string(info: dict, item_type: str) -> str:\n        return \", \".join(\n            item.strip() for item in str(info.get(item_type, \"\")).split(\",\") if item\n        )\n\n    def process_question(\n        self, question_type: str, question_id: str, query: str, context: str, info: dict\n    ) -> None:\n        response = (\n            info.get(question_id, {})\n            if question_id.endswith((\"code_graph\", \"docstring\"))\n            else clean_and_get_unique_elements(str(info.get(question_id, \"\")))\n        )\n\n        if question_id.endswith(\"file_purpose\"):\n            self.get_code_qa()\n            if self.use_llm:\n                response = str(self.get_response_from_llm(query, context).strip())\n\n        if response and response != \"None\":\n            self.instruct_list.append(\n                {\"instruction\": query, \"input\": context, \"output\": response}\n            )\n\n    def process_question_type(\n        self, question_type: str, question_id: str, question_text: str\n    ) -> None:\n        if question_type == \"file\":\n            self.process_question(\n                question_type,\n                question_id,\n                question_text.format(filename=self.base_name),\n                f\"```python\\n{self.file_details['file_info']['file_code']}\\n```\",\n                self.file_details[\"file_info\"],\n            )\n        elif question_type == \"method\":\n            for class_name, class_info in self.file_details[\"classes\"].items():\n                for key, method_info in class_info.items():\n                    if key.startswith(\"class_method_\"):\n                        method_name = f\"{class_name}.{key[len('class_method_'):]}\"\n                        self.process_question(\n                            question_type,\n                            question_id,\n                            question_text.format(\n                                filename=self.base_name,\n                                class_name=class_name,\n                                method_name=method_name,\n                            ),\n                            f\"```python\\n{method_info['method_code']}\\n```\",\n                            method_info,\n                        )\n        else:\n            for name, info in self.file_details[\n                self.question_mapping[question_type]\n            ].items():\n                mapping = {f\"{question_type}_name\": name}\n                if question_id == f\"{question_type}_purpose\" and self.use_llm:\n                    variables = self.get_info_string(info, f\"{question_type}_variables\")\n                    inputs = self.get_info_string(info, f\"{question_type}_inputs\")\n                    mapping[f\"{question_type}_variables\"] = (\n                        clean_and_get_unique_elements(\n                            \", \".join(s for s in [variables, inputs] if s)\n                        )\n                    )\n                    if question_type == \"class\":\n                        mapping[f\"{question_type}_methods\"] = self.get_info_string(\n                            info, f\"{question_type}_methods\"\n                        )\n                self.process_question(\n                    question_type,\n                    question_id,\n                    question_text.format(filename=self.base_name, **mapping),\n                    f\"```python\\n{info[f'{question_type}_code']}\\n```\",\n                    info,\n                )\n\n    def generate(self) -> Tuple[list[dict], list[dict]]:\n        for question in self.questions:\n            self.process_question_type(\n                question[\"type\"], question[\"id\"], question[\"text\"]\n            )\n        self.instruct_list.sort(key=lambda x: len(x[\"input\"]), reverse=True)\n        return self.instruct_list\n\n\ndef get_python_datasets(\n    file_path: str,\n    file_details: dict,\n    base_name: str,\n    questions: list[dict],\n    model_config: dict,\n    detailed: bool,\n) -> Tuple[list[dict], list[dict]]:\n    return DatasetGenerator(\n        file_path, file_details, base_name, questions, model_config, detailed\n    ).generate()\n\n```"
            }
        ],
        "nbytes": 17256,
        "source": "py2dataset/get_python_datasets copy 2.py"
    },
    {
        "conversation": [
            {
                "from": "system",
                "value": "code documentation: I) Python file `py2dataset\\get_python_datasets.py` serves as a central component to extract information from a given Python file along with associated questions pertaining to it and generate structured outputs in JSON format containing question-answer pairs. This dataset generation involves multiple processes, namely file processing through Language Models for generating detailed explanations and an extensive series of methods for question classification, data organization, response generation, etc. Let's delve deeper into each aspect:\n\n1. Dependencies: The script relies on four external libraries - `re`, `yaml`, `logging`, and `math`. These libraries enable regular expression handling (`re`), managing complex data structures like dictionaries (`yaml`), logging errors or debugging information (`logging`), and mathematical operations (`math`) respectively.\n\n2. Functions: There are three user-defined functions in the script - `get_unique_elements`, `element_generator`, and `get_python_datasets`.\na. `get_unique_elements(input_str)` cleans an input string by removing duplicates and returns a string containing unique elements separated by commas. It uses `enumerate`, `input_str[start:i].strip()`, `input_str[start:].strip()`, `input_str.strip(\"[]'\\\"\")`, and `getelement generator`. Its application streamlines readability of complex data structures.\nb. `element_generator(input_str)` generates elements from an input string while maintaining contextual integrity by tracking braces ('{', '}'). It uses `enumerate`, `input_str[start:i].strip()`, `input_str[start:].strip()`, `yield`, and `lambda`.\nc. `get_python_datasets(file_path, file_details, base_name, questions, model_config, detailed)` instantiates a `DatasetGenerator` class using given inputs and invokes its `generate()` method to retrieve instruct_list and code_qa_dict as outputs - crucial data structures for JSON formatted question-answer pairs. It uses the `DatasetGenerator` class for extensive functionality described below.\n\n3. Classes: There is one major user-defined class named `DatasetGenerator`. It encapsulates multiple methods and attributes to achieve its purpose.\na. `__init__(self, file_path, file_details, base_name, questions, model_config, detailed)` initializes the DatasetGenerator object by setting input arguments as respective instance variables while creating internal attributes for code_qa_response storage (to hold generated responses for code questions), detailed response flag based on LLM usage, and instruct_list to store question-answer pairs. It also defines question mapping between file details and question types ('file', 'function', 'class', 'method').\nb. `format_response()` formats the code_qa_dict output by applying YAML formatting techniques for readability. This ensures that generated JSON data remains organized.\nc. `get_response_from_llm(self, query, context)` queries language models using specified prompt template (derived from configuration). It attempts different context strategies and manages LLM response processing while handling errors and detailed response generation if necessary. This method relies heavily on external LLM services through the `llm` attribute.\nd. `get_detailed_response(context, response)` generates detailed responses for code objects by querying LLM again with additional context and question-specific information. It updates relevant data structures accordingly.\ne. `get_code_qa()` identifies code responses from instruct_list and updates internal attributes like code_qa_dict to store these responses in a structured manner.\nf. `process_question(self, question_id, query, context, info)` processes questions related to different file entities ('file', 'function', 'class', or 'method') by invoking other methods and appending relevant outputs to instruct_list based on the given question IDs.\ng. `get_info_string(info, item_type)` returns a string of comma-separated distinct values from given dictionary 'info' associated with the provided key (item_type).\nh. `process_question_type(self, question_type, question_id, question_text)` dispatches further question processing as per query types such as handling function-related or class-related questions by invoking `process_question()`. It also collects additional information like variables and methods for 'class' type questions.\ni. `generate(self)` processes all given questions and generates instruct_list with answers for JSON output. It calls multiple internal methods to accomplish this task.\n\nIII. Key Inputs include Python file path, file details (dictionary), base name of the Python file, list of questions, model configuration (dict), and detailed flag indicating LLM usage. Outputs are instruct_list containing question-answer pairs and code_qa_dict with code responses from instruct_list. Variables like llm, use_llm, detailed, instruct_list, question_mapping, code_qa_list, etc., assist internal data manipulation for better readability. Functions/methods invoke each other forming a complex but coordinated system for comprehensive dataset generation according to specified requirements in the codebase."
            },
            {
                "from": "human",
                "value": "Output the Python code described by the code documentation."
            },
            {
                "from": "gpt",
                "value": "```python\n\"\"\"\nGenerates JSON format question-answer pairs and instructions for a Python file\nRequirements:\n[req01] The `DatasetGenerator` class shall:\n        a. Accept Python file path, file details, base name, list of questions,\n        and model configuration as input during instantiation.\n        b. Initialize and store Python file path, file details, base name,\n        question list, llm, and use_llm flag as class attributes.\n        d. Provide `get_response_from_llm` method to retrieve llm response.\n        e. Provide `get_detailed_response` method to generate detailed responses.\n        f. Provide `get_code_qa` method to get code responses from instruct_list.\n        g. Provide `process_question` method to process each question, generate\n        corresponding responses, and add to the instruct_list.\n        h. Provide `process_question_type` method to process questions\n        related to the file, functions, classes, and methods.\n        i. Provide `generate` method to generate responses for all questions\n        and return the instruct_list.\n        j. Internally manage question mapping to file details.\n[req02] The `get_python_datasets` function shall:\n        a. Accept a Python file path, file details, base name, questions list,\n        and model config as input.\n        b. Instantiate `DatasetGenerator` class using the provided input.\n        c. Generate instruct_list using `DatasetGenerator` `generate` method.\n        d. Return the generated `instruct_list`.\n[req03] The `get_unique_elements` function shall:\n        a. Clean an input string (str) and return a string of unique elements.\n\"\"\"\n\nimport logging\nimport re\nimport math\nimport yaml\n\n\ndef get_unique_elements(input_str: str) -> str:\n    \"\"\"\n    Clean an input string (str) and return a string of unique elements.\n    Args:\n        input_str (str): Input string.\n    Returns:\n        str: String of unique elements.\n    \"\"\"\n    def element_generator(input_str):\n        start, brace_level = 0, 0\n        for i, char in enumerate(input_str):\n            if char in \"{}\":\n                brace_level += 1 if char == \"{\" else -1\n            elif char == \",\" and brace_level == 0:\n                yield input_str[start:i].strip(\"'\\\" \")\n                start = i + 1\n        yield input_str[start:].strip(\"'\\\" \")\n    input_str = input_str.strip(\"[]'\\\"\")\n    cleaned_elements = [element for element in element_generator(input_str) if element]\n    return \", \".join(cleaned_elements)\n\n\nclass DatasetGenerator:\n    \"\"\"\n    Generate JSON formatted dictionary outputs for a Python file.\n    Args:\n        file_path (str): Path to the Python file.\n        file_details (dict): Dictionary containing details of the Python file.\n        base_name (str): Base name of the Python file.\n        questions (list): List of questions to be answered for the Python file.\n        model_config (dict): Dictionary containing the model configuration.\n        detailed (bool): Flag to generate detailed responses.\n    Attributes:\n        file_path (str): Path to the Python file.\n        file_details (dict): Dictionary containing details of the Python file.\n        base_name (str): Base name of the Python file.\n        questions (list): List of questions to be answered for the Python file.\n        model_config (dict): Dictionary containing the model configuration.\n        llm (obj): Language model object.\n        use_llm (bool): Flag to use language model.\n        detailed (bool): Flag to generate detailed responses.\n        instruct_list (list): List of instructions and responses.\n        question_mapping (dict): Mapping of question types to file details.\n        code_qa_list (list): List of code questions and responses.\n        code_qa_response (str): Response for the code_qa_dict.\n        code_qa_dict (dict): Dictionary containing code questions and responses.\n    \"\"\"\n\n    def __init__(\n        self,\n        file_path: str,\n        file_details: dict,\n        base_name: str,\n        questions: list[dict],\n        model_config: dict,\n        detailed: bool,\n    ) -> None:\n        \"\"\"Initialize the DatasetGenerator class.\"\"\"\n        self.file_path = file_path\n        self.file_details = file_details\n        self.base_name = base_name\n        self.questions = questions\n        self.model_config = model_config\n        self.llm = model_config[\"model\"] if model_config else None\n        self.use_llm = bool(model_config)\n        self.detailed = detailed if self.use_llm else False\n        self.instruct_list = []\n        self.question_mapping = {\n            \"file\": \"file\",\n            \"function\": \"functions\",\n            \"class\": \"classes\",\n            \"method\": \"classes\",\n        }\n        self.code_qa_list = []\n        self.code_qa_response = \"\"\n\n    def format_response(self):\n        \"\"\"Format the response for the code_qa_dict.\"\"\"\n        self.code_qa_response = (\n            re.sub(\n                r\"\\n\\s*\\n\",\n                \"\\n\",\n                yaml.dump(\n                    self.code_qa_dict,\n                    Dumper=yaml.SafeDumper,\n                    width=float(\"inf\"),\n                    sort_keys=False,\n                    default_flow_style=False,\n                    indent=2,\n                ),\n            )\n            .replace(\"''\", \"'\")\n            .strip('\"')\n            .strip(\"'\")\n            .strip()\n        )\n        self.file_details[\"file_info\"][\"code_qa_response\"] = self.code_qa_response\n\n    def get_response_from_llm(self, query: str, context: str) -> str:\n        \"\"\"\n        Get language model response to query for given context.\n        Args:\n            query (str): Query to be answered.\n            context (str): Context for the query.\n        Returns:\n            str: Language model response.\n        \"\"\"\n        context_strategies = [\n            lambda: str(context),\n            lambda: f\"```python\\n{self.file_details['file_info']['file_code_simplified']}\\n```\",\n            lambda: f\"```python\\n{self.get_info_string(self.file_details['file_info'], 'file_summary')}\\n```\",\n            lambda: \"\",\n        ]\n\n        max_context_length = self.model_config[\"inference_model\"][\"model_params\"][\n            \"context_length\"\n        ]\n        prompt_template = self.model_config[\"prompt_template\"].format(\n            system_prompt=self.model_config[\"system_prompt\"],\n            instruction_prompt=self.model_config[\"instruction_prompt\"],\n        )\n\n        for strategy in context_strategies:\n            context = strategy()\n            prompt = prompt_template.format(\n                context=context, query=query, code_objects=self.code_qa_response\n            )\n            context_size = len(self.llm.tokenize(prompt))\n            logging.info(f\"***Context Size: {context_size}\")\n            if context_size <= 0.70 * max_context_length:\n                break\n        else:\n            err_msg = \"Model response failed, increase py2dataset_model_config.yaml context_length\"\n            logging.error(f\"{err_msg} > {math.ceil(context_size/0.70)}\")\n            return \"\"\n\n        context = self.code_qa_list if context == \"\" else context\n        response = \"\"\n\n        try:\n            response = (\n                re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", self.llm(prompt))\n                .replace(\"<|im_end|>\", \"\")\n                .replace(\"</|im_end|>\", \"\")\n            )\n            response = \"\\n\".join(line.lstrip() for line in response.split(\"\\n\"))\n            logging.info(f\"***Overall Response: {response}\")\n        except Exception as error:\n            logging.error(f\"Failed to generate model response: {error}\")\n\n        if self.detailed:\n            self.get_detailed_response(context, response)\n\n        basename = str(self.base_name).replace(\"\\\\\", \"/\")\n        self.code_qa_dict = {basename: self.code_qa_dict}\n        self.code_qa_dict[basename] = {\n            \"Code Documentation\": [response],\n            **self.code_qa_dict[basename],\n        }\n        self.format_response()\n        self.file_details[\"file_info\"][\"purpose\"] = response\n        return response\n\n    def get_detailed_response(self, context: str, response: str) -> None:\n        \"\"\"\n        Generate detailed responses for code objects.\n        Args:\n            context (str): Context for the response.\n            response (str): Response from the model.\n        \"\"\"\n        for item in self.code_qa_list:\n            try:\n                instruct_key = list(item.keys())[0]\n                instruct_value = list(item.values())[0]\n                query = f\"Describe the Purpose and Significance of these {instruct_key}: [{instruct_value}] and Explain what each of these {instruct_key} does in the code.\"\n                prompt = (\n                    self.model_config[\"prompt_template\"]\n                    .format(\n                        system_prompt=self.model_config[\"system_prompt\"],\n                        instruction_prompt=self.model_config[\"instruction_prompt\"],\n                    )\n                    .format(\n                        context=f\"{context}/nCode Summary:/n{response}\",\n                        query=f\"{query}\",\n                        code_objects=f\"{instruct_value}\",\n                    )\n                )\n                item_response = (\n                    re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", self.llm(prompt))\n                    .replace(\"<|im_end|>\", \"\")\n                    .replace(\"</|im_end|>\", \"\")\n                )\n                logging.info(f\"\\n***Itemized Response: {query}\\n{item_response}\")\n                for item in self.instruct_list:\n                    if item[\"instruction\"].startswith(instruct_key):\n                        output = f\"\\n\\nPurpose and Significance:\\n{item_response}\"\n                        item[\"output\"] += output\n\n                if \"`\" in instruct_key:\n                    dict_key1 = instruct_key.split(\"`\")[1]\n                    dict_key2 = instruct_key.split()[0]\n                else:\n                    dict_key1 = instruct_key\n                    dict_key2 = \"\"\n\n                purpose_dict = {\"Purpose\": item_response.strip()}\n                if dict_key1 not in self.code_qa_dict:\n                    self.code_qa_dict[dict_key1] = {}\n                elif not isinstance(self.code_qa_dict[dict_key1], dict):\n                    value = self.code_qa_dict[dict_key1]\n                    self.code_qa_dict[dict_key1] = {\"Value\": value}\n                if dict_key2:\n                    if not isinstance(self.code_qa_dict[dict_key1], dict):\n                        self.code_qa_dict[dict_key1] = {}\n                    if dict_key2 not in self.code_qa_dict[dict_key1] or not isinstance(\n                        self.code_qa_dict[dict_key1][dict_key2], dict\n                    ):\n                        value = self.code_qa_dict[dict_key1].get(dict_key2, \"\")\n                        self.code_qa_dict[dict_key1][dict_key2] = {\"Value\": value}\n                    self.code_qa_dict[dict_key1][dict_key2].update(purpose_dict)\n                else:\n                    self.code_qa_dict[dict_key1].update(purpose_dict)\n            except Exception as error:\n                logging.error(f\"Failed to generate detailed response: {error}\")\n\n    def get_code_qa(self):\n        \"\"\"Get code responses from the instruct_list and update.\"\"\"\n        excluded = {\"Call code graph\", \"Docstring\"}\n        self.code_qa_list = []\n        responses = {}\n        for item in self.instruct_list:\n            instruction, output = (\n                item[\"instruction\"].split(\" in Python file:\")[0],\n                item[\"output\"],\n            )\n            if not any(instruction.startswith(prefix) for prefix in excluded):\n                self.code_qa_list.append({instruction: output})\n                if \"`\" in instruction:\n                    code_object, code_type = (\n                        instruction.split(\"`\")[1],\n                        instruction.split()[0],\n                    )\n                    responses.setdefault(code_object, []).append((code_type, output))\n                else:\n                    responses.setdefault(instruction, []).append((instruction, output))\n\n        self.code_qa_dict = {}\n        for code_object, type_responses in responses.items():\n            self.code_qa_dict[code_object] = {}\n            for code_type, response in type_responses:\n                if code_object == code_type:\n                    self.code_qa_dict[code_object] = response\n                else:\n                    self.code_qa_dict.setdefault(code_object, {})[code_type] = response\n\n        if not self.use_llm:\n            basename = str(self.base_name).replace(\"\\\\\", \"/\")\n            self.code_qa_dict = {basename: self.code_qa_dict}\n\n        self.format_response()\n\n    def process_question(\n        self, question_id: str, query: str, context: str, info: dict\n    ) -> None:\n        \"\"\"Process question and add the generated response to the instruct_list.\"\"\"\n        if question_id.endswith((\"code_graph\", \"docstring\")):\n            response = info.get(question_id, {})\n        elif question_id.endswith(\"file_purpose\"):  # file_purpose is last question\n            self.get_code_qa()\n            response = (\n                self.get_response_from_llm(query, context) if self.use_llm else \"\"\n            )\n        else:\n            response = get_unique_elements(str(info.get(question_id, \"\")))\n\n        if response and response != \"None\":\n            response = str(response).strip()\n            self.instruct_list.append(\n                {\"instruction\": query, \"input\": context, \"output\": response}\n            )\n\n    @staticmethod\n    def get_info_string(info: dict, item_type: str) -> str:\n        \"\"\"Get string from info dictionary.\"\"\"\n        return \", \".join(\n            [item.strip() for item in str(info.get(item_type, \"\")).split(\",\") if item]\n        )\n\n    def process_question_type(\n        self, question_type: str, question_id: str, question_text: str\n    ) -> None:\n        \"\"\"\n        Process questions related to a file, function, class, or method.\n        Args:\n            question_type (str): Type of question.\n            question_id (str): Question ID.\n            question_text (str): Question text.\n        \"\"\"\n        if question_type == \"file\":\n            query = question_text.format(filename=self.base_name)\n            info = self.file_details[\"file_info\"]\n            context = f\"```python\\n{self.file_details['file_info']['file_code']}\\n```\"\n            self.process_question(question_id, query, context, info)\n        elif question_type == \"method\":\n            for class_name, class_info in self.file_details[\"classes\"].items():\n                for key, method_info in class_info.items():\n                    if key.startswith(\"class_method_\"):\n                        method_name = f\"{class_name}.{key[len('class_method_'):]}\"\n                        context = f\"```python\\n{method_info['method_code']}\\n```\"\n                        mapping = {\"class_name\": class_name, \"method_name\": method_name}\n                        query = question_text.format(filename=self.base_name, **mapping)\n                        self.process_question(question_id, query, context, method_info)\n        else:  # question_type is 'function' or 'class'\n            for name, info in self.file_details[\n                self.question_mapping[question_type]\n            ].items():\n                context = f\"```python\\n{info[f'{question_type}_code']}\\n```\"\n                mapping = {f\"{question_type}_name\": name}\n                if question_id == f\"{question_type}_purpose\" and self.use_llm:\n                    variables = self.get_info_string(info, f\"{question_type}_variables\")\n                    inputs = self.get_info_string(info, f\"{question_type}_inputs\")\n                    combined = \", \".join(filter(None, [variables, inputs]))\n                    mapping[f\"{question_type}_variables\"] = get_unique_elements(\n                        combined\n                    )\n                    if question_type == \"class\":\n                        mapping[f\"{question_type}_methods\"] = self.get_info_string(\n                            info, f\"{question_type}_methods\"\n                        )\n                query = question_text.format(filename=self.base_name, **mapping)\n                self.process_question(question_id, query, context, info)\n\n    def generate(self) -> tuple[list[dict], list[dict]]:\n        \"\"\"Generate responses for all the questions and returns the instruct_list.\"\"\"\n        for question in self.questions:\n            self.process_question_type(\n                question[\"type\"], question[\"id\"], question[\"text\"]\n            )\n        self.instruct_list.sort(key=lambda x: len(x[\"input\"]), reverse=True)\n        return self.instruct_list\n\n\ndef get_python_datasets(\n    file_path: str,\n    file_details: dict,\n    base_name: str,\n    questions: list[dict],\n    model_config: dict,\n    detailed: bool,\n) -> tuple[list[dict], list[dict]]:\n    \"\"\"\n    Extract information from a Python file and return it in JSON format.\n    Args:\n        file_path (str): Path to the Python file.\n        file_details (dict): Dictionary containing details of the Python file.\n        base_name (str): Base name of the Python file.\n        questions (list): List of questions to be answered for the Python file.\n        model_config (dict): Dictionary containing the model configuration.\n        detailed (bool): Flag to generate detailed responses.\n    Returns:\n        tuple: Tuple containing the instruct_list and code_qa_dict.\n    \"\"\"\n    return DatasetGenerator(\n        file_path, file_details, base_name, questions, model_config, detailed\n    ).generate()\n\n```"
            }
        ],
        "nbytes": 22806,
        "source": "py2dataset/get_python_datasets copy.py"
    },
    {
        "conversation": [
            {
                "from": "system",
                "value": "code documentation: I) The purpose of 'py2dataset/get_python_file_details.py' script is to extract detailed information from Python source code files. It performs analysis using Abstract Syntax Tree (AST), parses docstrings, function calls, dependencies, constants, and generates a code graph representation for better understanding of the file structure. This extracted data helps developers gain insights into the functionality of the given Python file.\n\nII) Requirements & API Signatures:\n1. `remove_docstring` - Removes docstrings from provided Python code string while preserving its syntax.\nInputs: Python code string, parsed Abstract Syntax Tree representing this code snippet as argument `tree`.\nReturn value: sanitized source code after stripping the comments and top-level docstrings within functions and classes but retaining the structure intact using ast.unparse().\n2. `get_all_calls` - Traverses the given AST node's subtree to identify all function calls, including nested occurrences in class attributes, list comprehensions, and lambda functions.\nInputs: Node of type ast.AST as argument `node`, an optional dictionary `calls` to accumulate function call lists when no existing instances provided initially (Default = []).\nOutputs: A Dictionary of strings keyed with the calling functions listing arguments respectively [Function_Calls => [args...]] formed using recursion within the subtree.\n3. `CodeVisitor` - A class that traverses an Abstract Syntax Tree and extracts details about Python code, inheriting from ast.NodeVisitor for easy traversal management. It collects function definitions, class definitions, file dependencies, constants, etc., storing them in relevant attributes such as 'functions', 'classes', 'file_info'.\nConstructor Arguments: Source code `code` and parsed Abstract Syntax Tree `tree`.\n4. `get_python_file_details` - Extracts comprehensive details from a given Python file path using CodeVisitor class methods and generates a control flow structure, entire code graph representation, and PlantUML notation for visualization purposes through get_code_graph function integration.\nInputs: File path as string `file_path`.\nOutputs: A dictionary containing extracted file details or None if an error occurs during processing.\n\nIII) Inputs, Variables, Calls & Returns explanation in the code context:\n1. remove_docstring():\n- Inputs 'code' represents Python source code string while 'tree' is its Abstract Syntax Tree representation generated using ast.parse(). Functions remove top-level docstrings from code strings while recursively deleting nested docstrings inside function bodies or class definitions keeping AST intact by invoking `ast.unparse(tree)`.\n2. get_all_calls():\n- 'node' represents an AST node, used to find all occurrences of ast.Call instances along with their arguments within the subtree rooted at this node. It returns a dictionary mapping function calls as keys to lists of their respective arguments. If no initial call list provided ('calls'), it creates an empty list by default ['Dict[str, List[str]]].\n3. get_python_file_details():\n- Receives Python file path string 'file_path' and performs the following steps:\na) Opens the file using 'open()', reads its content into variable 'code'.\nb) Parses code into Abstract Syntax Tree using ast.parse().\nc) Instantiates CodeVisitor object with provided source code 'code' and parsed tree as arguments ('visitor').\nd) Invokes visitor.analyze() to populate details related to the file in instance attributes.\ne) Gets a detailed graphical representation of function call relations, control flow structure & PlantUML notation from get_code_graph().\nf) Replaces quotations from json.dumps() output using replace().\ng) Returns file_details dictionary with extracted data or None in case of an error.\n4. CodeVisitor class:\n- Its methods operate on AST nodes and extract relevant information for various aspects of Python code like functions, classes, dependencies, constants, etc., storing them into attributes such as 'functions', 'classes', 'file_info'. It also maintains a current class context ('current_class') to track nested class definitions.\n- visit_FunctionDef() and visit_ClassDef(): Calls self.extract_details() method passing relevant node types as parameters ('function' or 'class'), populates 'functions'/'classes' dictionaries accordingly.\n- extract_details(): Iterates through AST walk of given node, collects function/class details into a dictionary using various calls like ast.walk(), get_all_calls(), ast.unparse(). Returns this collected data as detailed output dictionary depending on node type ('function', 'method', 'class', or 'self').\n- analyze(): Traverses AST node ('node') for dependencies capturing details related to file_summary (used JSON format) while setting up variables such as file_dependencies, function_defs, class_defs. Invokes get_code_graph() to generate entire code graph representation and PlantUML notation.\n- Other methods like visit_FunctionDef(), visit_ClassDef(), generic_visit(), visit_Assign(): Assist in traversing AST nodes efficiently by invoking appropriate extract_details() method or calling other relevant ast functions."
            },
            {
                "from": "human",
                "value": "Output the Python code described by the code documentation."
            },
            {
                "from": "gpt",
                "value": "```python\n\"\"\"\nReturn file_details dictionary for python source code.\nRequirements:\n[req00] The `remove_docstring` function shall:\n        a. Accept a Python code string as an argument.\n        b. Remove docstrings and comments from the provided code.\n        c. Return the sanitized code string.\n[req01] The get_all_calls function shall:\n        a. Accept a node of type ast.AST as an argument.\n        b. Recursively find all function calls in the subtree rooted at the node.\n        c. Return a dictionary of all function calls in the subtree rooted at the node.\n[req02] The `CodeVisitor` class shall:\n        a. Accept the source code as input when instantiated.\n        b. Use the AST to extract details about the code.\n        c. Inherit from `ast.NodeVisitor`.\n        d. Implement `visit_FunctionDef` method to gather details about functions.\n        e. Implement `visit_ClassDef` method to gather details about classes.\n        f. Implement `extract_details` method to parse information about a given node.\n        g. Implement `analyze` method to traverse the AST and 'file_info'. \n        h. Maintain a current class context using the attribute 'current_class'.\n[req03] The `code_graph` function shall:\n        a. Accept the file summary as input.\n        b. Construct a directed graph with nodes and edges using networkx library.\n        c. Define elements such as function nodes, class nodes, and method nodes.\n        d. Specify edges to represent relationships. \n        e. Return a dictionary representation of the code call graph. \n[req04] The `get_python_file_details` function shall:\n        a. Accept a file path as an argument.\n        b. Extract info from Python file using the AST and the `CodeVisitor` class.\n        c. Include the entire code graph in the returned details.\n        d. Return a dictionary encompassing the extracted file details. \n\"\"\"\nimport ast\nimport logging\nimport json\nfrom typing import Dict, List, Union\nfrom get_code_graph import get_code_graph\n\n\ndef remove_docstring(code: str, tree: ast.AST) -> str:\n    \"\"\"\n    Remove docstrings from the provided Python code.\n    This includes top-level module docstrings and docstrings in\n    functions, classes, and async functions.\n    Args:\n        code (str): The source code from which to remove docstrings.\n    Returns:\n        str: The source code with docstrings removed.\n    \"\"\"\n    if (\n        tree.body\n        and isinstance(tree.body[0], ast.Expr)\n        and isinstance(tree.body[0].value, ast.Str)\n    ):\n        tree.body.pop(0)\n\n    for node in ast.walk(tree):\n        if (\n            isinstance(node, (ast.FunctionDef, ast.ClassDef, ast.AsyncFunctionDef))\n            and node.body\n        ):\n            first_body_node = node.body[0]\n            if isinstance(first_body_node, ast.Expr) and isinstance(\n                first_body_node.value, ast.Str\n            ):\n                node.body.pop(0)\n\n    return ast.unparse(tree)\n\n\ndef get_all_calls(node: ast.AST, calls=None) -> Dict[str, List[str]]:\n    \"\"\"\n    Recursively find all function calls in the subtree rooted at `node`,\n    including those in class attributes, list comprehensions, and lambda functions.\n    Args:\n        node (ast.AST): The root node to start the search from.\n        calls (List[Tuple[str, List[str]]], optional): Accumulator for function calls found.\n    Returns:\n        Dict[str, List[str]]: dictionary mapping function calls (as strings) to lists of their arguments.\n    \"\"\"\n    if calls is None:\n        calls = []\n    if isinstance(node, ast.Call):\n        calls.append((ast.unparse(node.func), [ast.unparse(arg) for arg in node.args]))\n    elif isinstance(node, ast.ClassDef):\n        for body_item in node.body:\n            if isinstance(body_item, ast.Assign) and isinstance(\n                body_item.targets[0], ast.Name\n            ):\n                get_all_calls(body_item.value, calls)\n\n    for child in ast.iter_child_nodes(node):\n        get_all_calls(child, calls)\n\n    # Build the dictionary after traversal\n    calls_dict = {}\n    for func, args in calls:\n        if func not in calls_dict:\n            calls_dict[func] = []\n        calls_dict[func].extend(args)\n\n    return calls_dict\n\n\nclass CodeVisitor(ast.NodeVisitor):\n    \"\"\"\n    Visitor class for traversing an AST (Abstract Syntax Tree) and extracting details about the code.\n    Attributes:\n        code (str): The source code.\n        functions(Dict): details about functions in the code.\n        classes (Dict): details about classes in the code.\n        file_info (Dict): details about the file.\n    Methods:\n        visit_FunctionDef(node: ast.FunctionDef) -> None:\n            Extract details about a function.\n        visit_ClassDef(node: ast.ClassDef) -> None:\n            Extract details about a class.\n        extract_details(node: ast.AST, node_type: str) -> Dict[str, Union[str, List[str]]]:\n            Extract details about a node.\n        analyze(node: ast.AST) -> None:\n            Populate file_info with details about the file.\n    \"\"\"\n\n    def __init__(self, code: str, tree: ast.AST) -> None:\n        \"\"\"\n        Initialize a new instance of the class.\n        Args:\n            code: str: The source code.\n        \"\"\"\n        self.code: str = code\n        self.functions: Dict[str, Dict[str, Union[str, List[str]]]] = {}\n        self.classes: Dict[str, Dict[str, Union[str, List[str]]]] = {}\n        self.file_info: Dict[str, Union[str, List[str]]] = {}\n        self.current_class: str = None\n        self.constants: List[str] = []\n        self.tree = tree\n\n    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:\n        \"\"\"\n        Extract details about a function.\n        Args:\n            node: ast.FunctionDef: The node to visit.\n        \"\"\"\n        details = self.extract_details(\n            node, \"method\" if self.current_class else \"function\"\n        )\n        if self.current_class:\n            self.classes[self.current_class][f\"class_method_{node.name}\"] = details\n        else:\n            self.functions[node.name] = details\n        self.generic_visit(node)\n\n    def visit_ClassDef(self, node: ast.ClassDef) -> None:\n        \"\"\"\n        Extract details about a class.\n        Args:\n            node: ast.ClassDef: The node to visit.\n        \"\"\"\n        self.classes[node.name] = self.extract_details(\n            node, \"class\"\n        )  # populate class dictionary when class definition found in AST\n        self.current_class = node.name  # set current_class to indicate inside a class\n        self.generic_visit(node)  # continue AST traversal to the next node\n        self.current_class = None  # reset current_class when finished with this class\n\n    def generic_visit(self, node):\n        \"\"\"\n        Called if no explicit visitor function exists for a node.\n        Args:\n            node: ast.AST: The node to visit.\n        \"\"\"\n        for child in ast.iter_child_nodes(node):\n            child.parent = node\n            self.visit(child)\n\n    def visit_Assign(self, node: ast.Assign):\n        \"\"\"\n        Get self.constants\n        Args:\n            node: ast.Assign: The node to visit.\n        \"\"\"\n        if isinstance(node.parent, ast.Module):\n            for target in node.targets:\n                if isinstance(target, ast.Name):\n                    value = node.value\n                    if isinstance(value, ast.Constant) and isinstance(value.value, str):\n                        value_repr = f\"'{value.value}'\"\n                    else:\n                        value_repr = ast.unparse(value)\n                    constant_assignment = f\"{target.id}={value_repr}\"\n                    self.constants.append(constant_assignment)\n        self.generic_visit(node)\n\n    def extract_details(\n        self, node: ast.AST, node_type: str\n    ) -> Dict[str, Union[str, List[str]]]:\n        \"\"\"\n        Extract details about a node.\n        Args:\n            node: ast.AST: The node to extract details from.\n            node_type: str: The type of node.\n        Returns:\n            Dict[str, Union[str, List[str]]]: The details extracted from the node.\n        \"\"\"\n        node_walk = list(ast.walk(node))\n        call_data = get_all_calls(node)\n        node_inputs = (\n            [arg.arg for arg in node.args.args]\n            if node_type in [\"function\", \"method\"]\n            else None\n        )\n        node_variables = list(\n            {\n                ast.unparse(target)\n                for subnode in node_walk\n                if isinstance(subnode, ast.Assign)\n                for target in subnode.targets\n                if isinstance(target, ast.Name)\n            }\n        )\n        if node_inputs:\n            node_variables = list(set(node_inputs + node_variables))\n\n        details = {\n            f\"{node_type}_name\": node.name,\n            f\"{node_type}_code\": ast.unparse(node),\n            f\"{node_type}_docstring\": next(\n                (\n                    n.value.s\n                    for n in node_walk\n                    if isinstance(n, ast.Expr) and isinstance(n.value, ast.Str)\n                ),\n                None,\n            ),\n            f\"{node_type}_inputs\": node_inputs,\n            f\"{node_type}_defaults\": [ast.unparse(d) for d in node.args.defaults]\n            if node_type in [\"function\", \"method\"]\n            else None,\n            f\"{node_type}_returns\": [\n                ast.unparse(subnode.value) if subnode.value is not None else \"None\"\n                for subnode in node_walk\n                if isinstance(subnode, ast.Return)\n            ],\n            f\"{node_type}_calls\": list(call_data.keys()),\n            f\"{node_type}_call_inputs\": call_data,\n            f\"{node_type}_variables\": node_variables,\n            f\"{node_type}_decorators\": list(\n                {ast.unparse(decorator) for decorator in node.decorator_list}\n                if node.decorator_list\n                else set()\n            ),\n            f\"{node_type}_annotations\": list(\n                {\n                    ast.unparse(subnode.annotation)\n                    for subnode in node_walk\n                    if isinstance(subnode, ast.AnnAssign)\n                    and subnode.annotation is not None\n                }\n            ),\n            f\"{node_type}_properties\": list(\n                {\n                    ast.unparse(subnode)\n                    for subnode in node_walk\n                    if isinstance(subnode, ast.Attribute)\n                    and isinstance(subnode.ctx, ast.Store)\n                }\n            ),\n        }\n        if node_type in [\"class\", \"method\"]:\n            if (\n                node_type == \"method\" and self.current_class\n            ):  # find attributes defined as self.attribute\n                attributes = [\n                    target.attr\n                    for subnode in node_walk\n                    if isinstance(subnode, ast.Assign)\n                    for target in subnode.targets\n                    if isinstance(target, ast.Attribute)\n                    and isinstance(target.value, ast.Name)\n                    and target.value.id == \"self\"\n                ]\n                class_attributes = self.classes[self.current_class].setdefault(\n                    \"class_attributes\", []\n                )\n                class_attributes += attributes\n            if node_type == \"class\":\n                details.update(\n                    {\n                        \"class_attributes\": [\n                            target.attr\n                            for subnode in node.body\n                            if isinstance(subnode, ast.Assign)\n                            for target in subnode.targets\n                            if isinstance(target, ast.Attribute)\n                        ],\n                        \"class_methods\": [\n                            subnode.name\n                            for subnode in node.body\n                            if isinstance(subnode, ast.FunctionDef)\n                        ],\n                        \"class_inheritance\": [ast.unparse(base) for base in node.bases]\n                        if node.bases\n                        else [],\n                        \"class_static_methods\": [\n                            subnode.name\n                            for subnode in node.body\n                            if isinstance(subnode, ast.FunctionDef)\n                            and any(\n                                isinstance(decorator, ast.Name)\n                                and decorator.id == \"staticmethod\"\n                                for decorator in subnode.decorator_list\n                            )\n                        ],\n                    }\n                )\n        return details\n\n    def analyze(self, node: ast.AST) -> None:\n        \"\"\"\n        Traverse the AST, list all nodes, and populate 'file_info'\n        Args:\n            node: ast.AST: The node to analyze.\n        \"\"\"\n        # Traverse the AST to capture various code details\n        self.visit(node)\n        node_walk = list(ast.walk(node))\n\n        file_dependencies = {\n            alias.name\n            for subnode in node_walk\n            if isinstance(subnode, ast.Import)\n            for alias in subnode.names\n        } | {\n            subnode.module\n            for subnode in node_walk\n            if isinstance(subnode, ast.ImportFrom)\n        }\n\n        function_defs = [\n            {\n                func_name: {\n                    \"inputs\": details[\"function_inputs\"],\n                    \"calls\": details[\"function_calls\"],\n                    \"call_inputs\": details[\"function_call_inputs\"],\n                    \"returns\": details[\"function_returns\"],\n                }\n            }\n            for func_name, details in self.functions.items()\n        ]\n\n        class_defs = [\n            {\n                class_name: {\n                    \"method_defs\": {\n                        method_name[len(\"class_method_\") :]: {\n                            \"inputs\": details[\"method_inputs\"],\n                            \"calls\": details[\"method_calls\"],\n                            \"call_inputs\": details[\"method_call_inputs\"],\n                            \"returns\": details[\"method_returns\"],\n                        }\n                        for method_name, details in class_details.items()\n                        if method_name.startswith(\"class_method_\")\n                    }\n                }\n            }\n            for class_name, class_details in self.classes.items()\n        ]\n\n        self.file_info = {\n            \"file_code\": self.code,\n            \"file_ast\": node,\n            \"file_dependencies\": list(file_dependencies),\n            \"file_functions\": list(self.functions.keys()),\n            \"file_classes\": list(self.classes.keys()),\n            \"file_constants\": self.constants,\n            \"file_summary\": {\n                \"dependencies\": list(file_dependencies),\n                \"function_defs\": function_defs,\n                \"class_defs\": class_defs,\n            },\n            \"file_code_simplified\": remove_docstring(ast.unparse(node), self.tree),\n        }\n\n\ndef get_python_file_details(file_path: str) -> Dict[str, Union[Dict, str]]:\n    \"\"\"\n    Extract details from a Python file.\n    Args:\n        file_path: str: The path to the Python file.\n    Returns:\n        Dict[str, Union[Dict, str]]: The details extracted from the file.\n    \"\"\"\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            code = f.read()\n            tree = ast.parse(code)\n    except (PermissionError, SyntaxError, IOError) as e:\n        logging.warning(f\"{e} error in file: {file_path}\")\n        return None\n\n    visitor = CodeVisitor(code, tree)\n    visitor.analyze(tree)\n    file_details = {\n        \"file_info\": visitor.file_info,\n        \"functions\": visitor.functions,\n        \"classes\": visitor.classes,\n    }\n\n    # get code graph items and add to file_details\n    file_summary = file_details[\"file_info\"][\"file_summary\"]\n    file_ast = file_details[\"file_info\"][\"file_ast\"]\n    entire_code_graph, control_flow_structure, plant_uml = get_code_graph(\n        file_summary, file_ast\n    )\n    file_details[\"file_info\"][\"entire_code_graph\"] = entire_code_graph\n    file_details[\"file_info\"][\"control_flow_structure\"] = control_flow_structure\n    file_details[\"file_info\"][\"plant_uml\"] = plant_uml\n    file_details[\"file_info\"][\"file_summary\"] = json.dumps(file_summary).replace(\n        '\"', \"\"\n    )\n    del file_details[\"file_info\"][\"file_ast\"]\n\n    return file_details\n\n```"
            }
        ],
        "nbytes": 21743,
        "source": "py2dataset/get_python_datasets.py"
    },
    {
        "conversation": [
            {
                "from": "system",
                "value": "code documentation: I) The purpose of 'py2dataset/py2dataset.py' is creating a Python software aimed at generating and storing question-answer pair datasets by inspecting and processing various aspects of one or multiple given Python files from specific directories (with additional flexibility for interactivity during runtime). This information can later be employed to understand the code better through machine learning models or other analysis tools. It consists of several functions working together to achieve this goal: process_single_python_file, py2dataset, clone_github_repo, get_bool_from_input (used only for interactive mode), and main - the entry point when executing the script.\n\nII) Detailed Requirements & API Signatures for all Functions & Class Methods:\n1. process_single_python_file(python_pathname, relative_path, output_dir, model_config_pathname, questions, use_llm, model_config, detailed): This function processes a single Python file to generate question-answer pairs and instructions related to the code within it. It logs relevant information about the progress of processing each file, fetches details about the file using get_python_file_details, acquires instruct.json datasets via get_python_datasets if required configurations are present, and finally stores file details and datasets utilizing save_python_data after handling exceptions where applicable.\n- python_pathname (str): Path to the Python file\n- relative_path (Path): Represents file location in the hierarchy related to start directory\n- output_dir (str): Directory to store output files\n- model_config_pathname (str): Path and filename of the model configuration file\n- questions (Dict): Dictionary containing questions about Python files\n- use_llm (bool): Use LLM for answering code purpose question if True\n- model_config (Dict): Configuration dictionary for the LLM (populated when needed)\n- detailed (bool): Perform detailed analysis if True\n2. py2dataset(start='', output_dir='', questions_pathname='', model_config_pathname='', use_llm=False, quiet=False, single_process=False, detailed=False, html=False, skip_regen=False): The primary function for generating datasets from Python files within a directory. It handles logging configuration based on quiet mode argument, adjusts output and start directories accordingly (defaulting if empty), reads questions file details (defaults provided), retrieves GitHub repository paths using clone_github_repo if required URL is given, spawns child processes or uses single process to execute process_single_python_file depending on LLM usage, combines instruct.json files using combine_json_files, and returns the generated datasets.\n- start (str): Starting directory for Python files or GitHub repository Python files (default: current working directory)\n- output_dir (str): Directory to write output files (default: ./dataset/)\n- questions_pathname (str): Path and filename of the questions file (default: ./py2dataset_questions.json)\n- model_config_pathname (str): Path and filename of the model configuration file (default: ./py2dataset_model_config.yaml)\n- use_llm (bool): Use LLM to answer code purpose question if True (default: False)\n- quiet (bool): Limit logging output if True (default: False)\n- single_process (bool): Use a single process for Python file processing when LLM is used (default: False)\n- detailed (bool): Include detailed analysis (default: False)\n- html (bool): Generate HTML output (default: False)\n- skip_regen (bool): Skip regeneration of existing instruct.json files if True (default: False)\n3. clone_github_repo(url: str): Clones a repository from GitHub or fetches the latest changes if available locally, then returns its local path. It creates an exception handler to manage errors encountered during this process.\n- url (str): URL of the GitHub repository\n- Returns (str): Local path of the cloned repository\n4. main(): Command-line entry point for processing Python files and generating datasets. It parses command-line arguments, handles interactive mode if enabled, adjusts parameters accordingly, checks validity of start directory, calls py2dataset with derived parameters, and executes clone_github_repo if necessary.\n- No explicit inputs or returns but interacts with various global variables defined in the script\n5. get_bool_from_input(input_str: str, current_value: bool): An auxiliary function used only during interactive mode to obtain user input for changing parameters and converts it into boolean values. It checks if input matches true/false keywords or keeps the existing value if none provided.\n- input_str (str): User input string from prompt\n- current_value (bool): Default boolean value of the parameter being updated\n- Returns: current_value, True, False depending on user input matching true/false keywords\n\nIII) Explanation of Inputs, Variables, Calls & Returns in the code:\n1. In process_single_python_file():\n- Input parameters represent necessary data for processing a Python file's details and instruct.json dataset generation while handling LLM integration when needed. Logging is utilized to keep track of progress; get_model instantiates an LLM model config if use_llm = True with no given config but model_config still takes configured parameters through the calling py2dataset function later\n- process spawns child threads to execute py2dataset when use_llm & single_process are False or runs all files sequentially otherwise. It saves file details and instruct.json data using save_python_data after fetching Python file information with get_python_file_details, acquiring datasets via get_python_datasets, handling exceptions if any\n- Variables hold intermediate steps of processing while returns nothing as it operates internally for each Python file\n2. In py2dataset():\n- Arguments control the overall behavior of dataset generation and storage. It adjusts logging levels based on quiet mode, sets output directory using get_output_dir if start is invalid or empty, retrieves questions dictionary with get_questions, searches for Python files recursively excluding specific directories, processes each file either sequentially or in parallel depending on LLM usage and single_process flag\n- Returns combined instruct.json datasets after combining json files using combine_json_files (HTML generation can also be controlled via html argument)\n3. In clone_github_repo():\n- url serves as the GitHub repository path, attempts to clone it or fetch latest changes if local copy exists already, and returns its local path after handling errors during operation\n- Variables are related to cloning operations like repo_name, repo_path while return value is the actual path of the cloned repository\n4. In main():\n- It handles command-line arguments parsing (with get_bool_from_input for interactive mode), adjusts parameters accordingly based on user input or defaults if needed, validates start directory, executes py2dataset with derived parameters, and invokes clone_github_repo if required\n- No explicit returns but interacts with various global variables defined in the script to execute the overall process\n5. In get_bool_from_input():\n- Two main arguments impact how current_value adjusts as user input comes: whether matching 'True', 'False' or just press Enter\n- It only modifies global values according to users input within interactive mode\n& returns updated current_values of either true, false"
            },
            {
                "from": "human",
                "value": "Output the Python code described by the code documentation."
            },
            {
                "from": "gpt",
                "value": "```python\n\"\"\"\nFor each Python file within a given directory, this module is designed to generate, save, \nand return datasets that include responses to questions about the code. \nRequirements:\n[req00] The process_single_python_file function shall:\n    a. Accept parameters for Python file path, start directory, model config \n       pathname, questions dict, use of LLM, and output dir.\n    b. If 'use_llm' is True, use 'get_model' to instantiate LLM model config.\n    c. Use 'get_python_file_details' to retrieve Python file info.\n    d. Use 'get_python_datasets' to acquire instruct.json datasets.\n    e. Use 'save_python_data' to store file details and instruct.json data.\n[req01] The py2dataset function shall:\n    a. Accept parameters for start directory, output dir, questions path, model\n       config path, use of LLM, and quiet mode.\n    b. Adjust logging level based on 'quiet'.\n    c. Use current working dir if no valid start dir is provided.\n    d. Get output dir with 'get_output_dir'.\n    e. Retrieve questions dict with 'get_questions'.\n    f. Search for Python files using 'rglob', excluding those starting with \"_\".\n    g. For each Python file, spawn a child process with 'process_single_python_file'\n       to get file details and instruct.json data, if single_process is False.\n    h. Combine instruct.json files with 'combine_json_files'.\n    i. Return datasets.\n[req02] The clone_github_repo function shall:\n    a. Accept a url.\n    b. Clone repository or fetch the latest changes.\n    c. Return local repository path.\n[req03] The main function shall:\n    a. Accept and process command-line args.\n    b. Determine py2dataset parameters based on processed arguments.\n    c. Call py2dataset with derived parameters.\n\"\"\"\nimport sys\nimport logging\nfrom pathlib import Path\nfrom typing import Dict, List\nfrom multiprocessing import Process\nimport os\nfrom git import Repo, GitCommandError\n\nfrom get_python_file_details import get_python_file_details\nfrom get_python_datasets import get_python_datasets\nfrom get_params import (\n    get_questions,\n    get_model,\n    get_output_dir,\n    get_start_dir,\n)\nfrom save_output import combine_json_files, save_python_data\n\n\ndef process_single_python_file(\n    python_pathname: str,\n    relative_path: Path,\n    output_dir: str,\n    model_config_pathname: str,\n    questions: Dict,\n    use_llm: bool,\n    model_config: Dict,\n    detailed: bool,\n) -> None:\n    \"\"\"\n    Processes a single Python file to generate question-answer pairs and instructions.\n    Args:\n        python_pathname (str): Path to the Python file.\n        start (str): Starting directory for Python files.\n        output_dir (str): Directory to write the output files.\n        model_config_pathname (str): Path and filename of the model configuration file.\n        questions (Dict): Dictionary of questions to answer about the Python file.\n        use_llm (bool): Use llm to answer code purpose question.\n        model_config (Dict): Configuration dictionary for the LLM.\n        detailed (bool): Perform detailed analysis if True.\n    \"\"\"\n    logging.info(f\"Processing file: {python_pathname}\")\n    if model_config is None and use_llm:\n        model_config = get_model(model_config_pathname)\n\n    file_details = get_python_file_details(python_pathname)\n    if not file_details:\n        logging.error(f\"Failed to get file details for {python_pathname}\")\n        return\n\n    instruct_data = get_python_datasets(\n        python_pathname,\n        file_details,\n        relative_path,\n        questions,\n        model_config,\n        detailed,\n    )\n\n    if instruct_data:\n        save_python_data(file_details, instruct_data, relative_path, output_dir)\n    else:\n        logging.error(f\"Failed getting {python_pathname} dataset\")\n\n    del instruct_data, file_details, model_config\n\n\ndef py2dataset(\n    start: str = \"\",\n    output_dir: str = \"\",\n    questions_pathname: str = \"\",\n    model_config_pathname: str = \"\",\n    use_llm: bool = False,\n    quiet: bool = False,\n    single_process: bool = False,\n    detailed: bool = False,\n    html: bool = False,\n    skip_regen: bool = False,\n) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Generates datasets by processing Python files within a specified directory.\n    Args:\n        start (str, optional): Starting directory for Python files or GitHub repository Python files. Default: current working directory.\n        output_dir (str, optional): Directory to write the output files. Default: ./dataset/.\n        questions_pathname (str, optional): Path and filename of the questions file. Default: ./py2dataset_questions.json.\n        model_config_pathname (str, optional): Path and filename of the model configuration file. Default: ./py2dataset_model_config.yaml.\n        use_llm (bool, optional): Use llm to answer code purpose question. Default: False.\n        quiet (bool, optional): Limit logging output. Default: False.\n        single_process (bool, optional): Use a single process to process Python files if --use_llm. Default: False.\n        detailed (bool, optional): Include detailed analysis. Default: False.\n        html (bool, optional): Generate HTML output. Default: False.\n        skip_regen (bool, optional): Skip regeneration of existing instruct.json files. Default: False.\n    Returns:\n        Dict[str, List[Dict]]: Generated datasets.\n    \"\"\"\n    if quiet:\n        logging.getLogger().setLevel(logging.WARNING)\n    else:\n        logging.getLogger().setLevel(logging.INFO)\n\n    sys.setrecursionlimit(3000)  # Set recursion limit higher for AST parsing\n\n    model_config = None\n    if use_llm and single_process:\n        model_config = get_model(model_config_pathname)\n\n    params = {\n        \"python_pathname\": \"\",\n        \"relative_path\": \"\",\n        \"output_dir\": get_output_dir(output_dir),\n        \"model_config_pathname\": model_config_pathname,\n        \"questions\": get_questions(questions_pathname),\n        \"use_llm\": use_llm,\n        \"model_config\": model_config,\n        \"detailed\": detailed,\n    }\n\n    for python_pathname in Path(start).rglob(\"*.py\"):     \n        exclude_dirs = [\"env\", \"venv\", \"__pycache__\", \"build\", \"dist\"]\n        if any([dir in python_pathname.parts for dir in exclude_dirs]):\n            continue\n        if python_pathname.name == \"__init__.py\":\n            continue\n        \n        params[\"python_pathname\"] = str(python_pathname)\n        params[\"relative_path\"] = Path(\n            os.path.relpath(python_pathname, os.path.dirname(get_start_dir(start)))\n        )\n\n        base_pathname = Path(params[\"output_dir\"]) / params[\"relative_path\"]\n        instruct_pathname = base_pathname.with_suffix(\".py.instruct.json\")\n        if instruct_pathname.exists() and skip_regen:\n            continue\n        \n        # process each python file in a separate process to manage memory\n        if params[\"model_config\"] is None and params[\"use_llm\"]:\n            proc = Process(target=process_single_python_file, kwargs=params)\n            proc.start()\n            proc.join()\n        else:  # or process all files using use a single process\n            process_single_python_file(**params)\n\n    return combine_json_files(output_dir, html, params[\"questions\"])\n\n\ndef clone_github_repo(url: str) -> str:\n    \"\"\"\n    Clone repository or fetch the latest changes and return local repository path.\n    Args:\n        url (str): The url of the GitHub repository.\n    Returns:\n        str: The path to the cloned repository.\n    \"\"\"\n    try:\n        repo_name = Path(url).stem\n        repo_path = Path.cwd() / \"githubrepos\" / repo_name\n        if repo_path.exists():\n            repo = Repo(repo_path)\n            repo.remote().fetch()\n            repo.git.reset('--hard', repo.heads[0].commit)\n        else:\n            Repo.clone_from(url, repo_path)\n        return str(repo_path)\n    except GitCommandError as e:\n        logging.info(f\"Error processing repository {url}: {e}\")\n        return \"\"\n\n\ndef main():\n    \"\"\"\n    Command-line entry point for processing Python files and generating datasets.\n    Optional command-line arguments:\n    --start (str, optional): Starting directory for Python files or GitHub repository Python files. Default: cwd.\n    --output_dir (str, optional): Directory to write the output files. Default: ./dataset/.\n    --questions_pathname (str, optional): Path and filename of the questions file. Default: ./py2dataset_questions.json.\n    --model_config_pathname (str, optional): Path and filename of the model configuration file. Default: ./py2dataset_model_config.yaml.\n    --use_llm (bool, optional): Use llm to answer code purpose question. Default: False.\n    --quiet (bool, optional): Limit logging output. Default: False.\n    --single_process (bool, optional): Use a single process to process Python files if --use_llm. Default: False.\n    --detailed (bool, optional): Include detailed analysis. Default: False.\n    --html (bool, optional): Generate HTML output. Default: False.\n    --I (str, optional): Enable interactive mode. Default: False.\n    --skip_regen (str, optional): Skip regeneration of existing instruct.json files. Default: False.\n    --help: Display help message.\n    \"\"\"\n    if len(sys.argv) == 1 or \"-h\" in sys.argv or \"--help\" in sys.argv:\n        print(__doc__)\n        sys.exit() \n\n    # return boolean value based on the user input\n    def get_bool_from_input(input_str: str, current_value: bool) -> bool:\n        if input_str.lower() in [\"t\", \"true\", \"y\", \"yes\"]:\n            return True\n        elif input_str.lower() in [\"f\", \"false\", \"n\", \"no\"]:\n            return False\n        return current_value\n\n    # Defaults\n    params = {\n        \"start\": \".\",\n        \"output_dir\": \"./dataset/\",\n        \"questions_pathname\": \"./py2dataset_questions.json\",\n        \"model_config_pathname\": \"./py2dataset_model_config.yaml\",\n        \"use_llm\": False,\n        \"quiet\": False,\n        \"single_process\": False,\n        \"detailed\": False,\n        \"html\": False,\n        \"skip_regen\": False,\n        \"I\": False,\n    }\n\n    arg_string = \" \".join(sys.argv[1:])\n    for arg in params:  # parse command-line arguments\n        if \"--\" + arg in arg_string:\n            if isinstance(params[arg], bool):\n                params[arg] = True\n                arg_string = arg_string.replace(\"--\" + arg, \"\")\n            else:\n                value_segment = arg_string.split(\"--\" + arg + \" \")[1]\n                params[arg] = value_segment.split(\" --\")[0].strip('\"')\n                arg_string = arg_string.replace(\"--\" + arg + \" \" + params[arg], \"\")\n\n    if params[\"I\"]:  # query user for parameters to change\n        print(\"Interactive mode, enter new values or press enter to keep.\")\n        for arg in params:\n            if arg != \"I\":\n                user_input = input(f\"{arg} [{params[arg]}]: \").strip()\n                if isinstance(params[arg], bool):\n                    params[arg] = get_bool_from_input(user_input, params[arg])\n                elif user_input:\n                    params[arg] = user_input\n                print(f\"{arg}: {params[arg]}\")\n    params.pop(\"I\")\n\n    if params[\"start\"].startswith(\"https://github.com/\"):\n        params[\"start\"] = clone_github_repo(params[\"start\"])\n    elif not os.path.isdir(params[\"start\"]):\n        print(f\"'{params['start']}' Invalid. Using current working directory.\")\n        params[\"start\"] = os.getcwd()\n\n    py2dataset(**params)\n\n\nif __name__ == \"__main__\":\n    main()\n\n```"
            }
        ],
        "nbytes": 18855,
        "source": "py2dataset/get_python_file_details.py"
    },
    {
        "conversation": [
            {
                "from": "system",
                "value": "code documentation: I) Purpose of py2dataset/save_output.py: The script encompasses utility functions essential for reading input data primarily in JSON and YAML formats, converting it to HTML files, processing JSONs, saving generated graphical images depicting code relationships as PNGs, handling Python file details extraction, and organizing output files systematically. It aims to facilitate the management of datasets related to programming tasks such as code documentation generation and analysis.\n\nII) Detailed Requirements, API Signatures & Logic Breakdown:\nA. read_file(): This function takes a file path (as Path type argument), detects whether the input file is JSON or YAML format by checking its extension, opens it using `with open()`, reads and returns the contents as a dictionary through `json.load` or `yaml.load`.\nAPI Signature: `read_file(file_path: Path) -> Dict`\n\nB. write_file(): Accepts a dictionary data along with a file path (both Path type arguments), writes the provided dictionary to JSON or YAML format by detecting the extension, manipulates some YAML specific behaviors like ignoring aliases and saving the result using `json.dump` or `yaml.Dumper`.\nAPI Signature: `write_file(data: Dict, file_path: Path) -> None`\n\nC. convert_json_to_html(): Targets a given directory containing JSON files; iterates through each JSON file excluding specified exceptions, reads their contents using read_file(), creates HTML content preserving spaces and tabs in tables for each dataset entry, writes the generated HTML content to a new file with .html extension.\nAPI Signature: `convert_json_to_html(directory: str) -> None`\nNotes: Includes calls like `pathlib`, string manipulations through functions like preserve_spacing().\n\nD. preserve_spacing(): Takes text input and tab width as arguments, replaces newlines with non-breaking spaces (&nbsp;) and tabs with a specific number of non-breaking spaces (tab_width).\nAPI Signature: `preserve_spacing(text: str, tab_width: int = 4) -> str`\n\nE. combine_json_files(): Processes JSON files within an input directory, merges them into 'instruct.json', removes duplicates, generates additional JSON files ('document_code.json' and 'shargpt.json'), handles YAML code_details.yaml file aggregation when `html` flag is true by calling convert_json_to_html().\nAPI Signature: `combine_json_files(directory: str, html: bool, questions: Dict) -> Dict[str, List[Dict]]`\nNotes: Uses logging functions like `logging.info`, pathlib methods (Path), file manipulation functions. Creates specific data lists during operations, performs conversion calls with YAML, JSON.\n\nF. create_code_graph(): Generates graph representations using Python code information gathered in 'file_details', creates a DiGraph object using networkx library, draws the graph using matplotlib's plt module, saves it as a PNG image in an output subdirectory.\nAPI Signature: `create_code_graph(file_details: dict, base_name: str, output_subdir: Path) -> None`\nNotes: Requires networkx imports; relies on plt methods like figure(), spring_layout(), draw(), draw_networkx_edge_labels(); logging error handling is done when creating graphs fails.\n\nG. save_python_data(): Takes Python file details, instruction list data, relative path, and output directory as arguments; saves the Python file details as YAML ('details.yaml'), instruction data as JSON ('instruct.json'), generates code graph images using create_code_graph().\nAPI Signature: `save_python_data(file_details: dict, instruct_list: list, relative_path: Path, output_dir: str) -> None`\nNotes: Involves pathlib operations like creating subdirectories; logging error handling is done when generating graphs fails.\n\nIII) Inputs, Variables & Returns Explanation:\n- read_file(): File path input ('file_path') returns dictionary contents after reading JSON or YAML data.\n- write_file(): Data and file path inputs (data, file_path) process output without a direct return value.\n- convert_json_to_html(): Directory input ('directory') returns nothing but writes HTML files with transformed content internally.\nInputs: column count derived from dictionary keys (column_count), dataset list extending through combine process, file name strings created with various Path manipulations operations ('json_file', 'code_filename'), HTML table content construction via multiple string concatenations.\n- preserve_spacing(): Text and tab width inputs create a modified string after applying specified replacements ('value').\n- combine_json_files(): Directory ('directory'), boolean flag ('html'), question dictionary ('questions') manage various data merging processes returning 'instruct_list' datasets.\n- create_code_graph(): File details, base name ('base_name'), output subdirectory path ('output_subdir') handle graph generation and saving as PNG images without explicit return value.\n- save_python_data(): Python file details ('file_details'), instruction list ('instruct_list'), relative path ('relative_path'), output directory path ('output_dir') execute write operations, call create_code_graph(), perform logging error handling for graph creation failures without explicit returns."
            },
            {
                "from": "human",
                "value": "Output the Python code described by the code documentation."
            },
            {
                "from": "gpt",
                "value": "```python\n\"\"\"\nUtility functions for reading the input and saving the output of the py2dataset script.\nRequirements:\n[req01] The `read_file` function shall:\n        a. Accept a file path as an argument.\n        b. Read and return the contents of a JSON or YAML file as a dictionary.\n[req02] The `write_file` function shall:\n        a. Accept a dictionary and a file path as arguments.\n        b. Write the dictionary to a file in either JSON or YAML format.\n[req03] The `convert_json_to_html` function shall:\n        a. Convert JSON files within a given directory to HTML format.\n        b. Save each converted file with a .html extension.\n        c. Preserve spacing and tabs for the 'input' field.\n[req04] The `combine_json_files` function shall:\n        a. Accept a directory path as an argument.\n        b. Merge all JSON files in the directory.\n        c. Remove duplicates from the combined JSON files.\n        d. Write the combined data to 'instruct.json' files.\n        e. Convert the merged JSON files to HTML format.\n        f. Return the 'instruct_list' datasets.\n[req05] The `create_code_graph` function shall:\n        a. Accept details of a Python file, a base name, and an output directory as arguments.\n        b. Generate code graphs based on the provided file details.\n        c. Save the graphs as PNG images in the specified output directory.\n[req06] The `save_python_data` function shall:\n        a. Accept details of a Python file, a base name, and an output directory as arguments.\n        b. Save the details of the Python file as a YAML file.\n        c. Save the instruction data as JSON files.\n        d. Generate and save code graphs.\n\"\"\"\n\nimport json\nimport logging\nfrom html import escape\nfrom pathlib import Path\nfrom typing import Dict, List\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport yaml\n\n\ndef read_file(file_path: Path) -> Dict:\n    \"\"\"\n    Reads a JSON or YAML file and returns its contents as a dictionary.\n    Args:\n        file_path (Path): The path to the file.\n    Returns:\n        The contents of the file as a dictionary.\n    \"\"\"\n    file_type = file_path.suffix[1:]\n    with file_path.open() as f:\n        if file_type == \"json\":\n            return json.load(f)\n        if file_type == \"yaml\":\n            return yaml.load(f, Loader=yaml.SafeLoader)\n        return {}\n\n\ndef write_file(data: Dict, file_path: Path) -> None:\n    \"\"\"\n    Writes a dictionary to a JSON or YAML file.\n    Args:\n        data (Dict): The data to write to the file.\n        file_path (Path): The path to the file.\n    Returns:\n        None\n    \"\"\"\n    file_type = file_path.suffix[1:]\n    with file_path.open(\"w\") as f:\n        if file_type == \"json\":\n            json.dump(data, f, indent=4)\n        elif file_type == \"yaml\":\n            # add this behavior: code_qa_text = re.sub(r\"\\n\\s*\\n\", \"\\n\", code_qa_text)\n            yaml.SafeDumper.ignore_aliases = lambda *args: True\n            yaml.dump(\n                data,\n                f,\n                Dumper=yaml.SafeDumper,\n                width=float(\"inf\"),\n                sort_keys=False,\n                default_flow_style=False,\n                indent=4,\n                allow_unicode=True,\n            )\n\n\ndef convert_json_to_html(directory: str) -> None:\n    \"\"\"\n    Convert JSON files within a given directory to HTML format and save .html file.\n    Args:\n        directory (str): The directory where the JSON files are located.\n    Returns:\n        None\n    \"\"\"\n\n    def preserve_spacing(text: str, tab_width: int = 4) -> str:\n        \"\"\"Preserve spaces and tabs in the provided text.\"\"\"\n        return text.replace(\" \", \"&nbsp;\").replace(\"\\t\", \"&nbsp;\" * tab_width)\n\n    for json_file in Path(directory).rglob(\"*.json\"):\n        try:\n            dataset = read_file(json_file)\n            if not dataset:\n                continue\n        except Exception:\n            continue\n\n        html_content = \"\"\"\n        <html>\n        <head>\n            <style>\n                table {border-collapse: collapse; width: 100%; table-layout: fixed;}\n                th, td {\n                    border: 1px solid black;\n                    padding: 8px;\n                    text-align: left;\n                    white-space: pre-line;\n                    vertical-align: top;\n                    word-wrap: break-word;\n                }\n            </style>\n        </head>\n        <body>\n            <table>\n                <thead>\n                    <tr>\n        \"\"\"\n        column_count = len(dataset[0].keys())\n        column_width = round(100 / column_count, 2)\n        for key in dataset[0].keys():\n            html_content += f\"<th style='width: {column_width}%;'>{key}</th>\"\n        html_content += \"\"\"\n                    </tr>\n                </thead>\n                <tbody>\n        \"\"\"\n        html_rows = []\n        for entry in dataset:\n            row_parts = [\"<tr>\"]\n            for key in entry:\n                value = escape(str(entry[key]))\n                value = preserve_spacing(value)\n                value = value.replace(\"\\n\", \"<br/>\")\n                row_parts.append(f\"<td>{value}</td>\")\n            row_parts.append(\"</tr>\")\n            html_rows.append(\"\".join(row_parts))\n        html_content += \"\".join(html_rows)\n\n        html_content += \"\"\"\n                </tbody>\n            </table>\n        </body>\n        </html>\n        \"\"\"\n        html_file_path = json_file.with_suffix(\".html\")\n        try:\n            with open(html_file_path, \"w\", encoding=\"utf-8\") as file:\n                file.write(html_content)\n        except Exception:\n            logging.info(f\"Failed saving: {html_file_path}\")\n\n\ndef combine_json_files(\n    directory: str, html: bool, questions: Dict\n) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Combine all JSON files in the output directory into 'instruct.json', and\n    then remove duplicates. Also generate a 'training.json' file.\n    Args:\n        directory (str): The directory where the output files are located.\n    Returns:\n        A dictionary containing the 'instruct_list' datasets.\n    \"\"\"\n    logging.info(f\"Combining JSON files in {directory}\")\n\n    # Save instruct.json file\n    combined_data, code_filename = [], []\n    skip_files = {\"instruct.json\", \"shargpt.json\", \"document_code.json\"}\n    for json_file in Path(directory).rglob(\"*.json\"):\n        if json_file.name in skip_files:\n            continue\n        try:\n            file_data = read_file(json_file)\n            if file_data:\n                combined_data.extend(file_data)\n                cleaned_name = (\n                    json_file.relative_to(directory)\n                    .with_suffix(\"\")\n                    .as_posix()\n                    .replace(\".instruct\", \"\")\n                )\n                code_filename.append(cleaned_name)\n        except Exception as e:\n            logging.info(f\"Failed reading: {json_file}. Error: {e}\")\n    write_file(combined_data, Path(directory) / \"instruct.json\")\n\n    # Generate document_code.json file\n    purpose_question = [\n        item[\"text\"] for item in questions if item[\"id\"] == \"file_purpose\"\n    ][0]\n    purpose_question = purpose_question.split(\"{filename}\")[0]\n    purpose_data = [\n        item\n        for item in combined_data\n        if item[\"instruction\"].startswith(purpose_question)\n    ]\n    document_code = [\n        {\n            \"document\": item[\"output\"],\n            \"code\": item[\"input\"],\n        }\n        for item in purpose_data\n    ]\n    for i, item in enumerate(document_code):\n        item[\"code filename\"] = code_filename[i]\n    write_file(document_code, Path(directory) / \"document_code.json\")\n\n    # save sharegpt.json file\n    sharegpt = [\n        {\n            \"conversation\": [\n                {\"from\": \"system\", \"value\": f\"code documentation: {item['document']}\"},\n                {\n                    \"from\": \"human\",\n                    \"value\": \"Output the Python code described by the code documentation.\",\n                },\n                {\"from\": \"gpt\", \"value\": item[\"code\"]},\n            ],\n            \"nbytes\": \"0\",\n            \"source\": item[\"code filename\"],\n        }\n        for item in document_code\n    ]\n    for item in sharegpt:\n        nbytes = 0\n        for conv in item[\"conversation\"]:\n            nbytes += len(conv[\"value\"].encode(\"utf-8\"))\n        item[\"nbytes\"] = nbytes\n    write_file(sharegpt, Path(directory) / \"shargpt.json\")\n\n    # save code_details.yaml file\n    code_details = []\n    logging.info(f\"Combining *.code_details.yaml files in {directory}\")\n    for yaml_file in Path(directory).rglob(\"*.code_details.yaml\"):\n        try:\n            with open(yaml_file, \"r\") as f:\n                file_data = f.read()\n                code_details.append(file_data)\n        except Exception as e:\n            logging.info(f\"Failed reading: {yaml_file}. Error: {e}\")\n    with open(Path(directory) / \"code_details.yaml\", \"w\") as f:\n        f.write(\"\\n\".join(code_details))\n\n    if html:\n        logging.info(\"Converting JSON files to HTML\")\n        convert_json_to_html(directory)\n\n    return {\"instruct_list\": combined_data}\n\n\ndef create_code_graph(file_details: Dict, base_name: str, output_subdir: Path) -> None:\n    \"\"\"\n    Generate graphs from the file_details and save them as PNG images.\n    Args:\n        file_details (dict): The details extracted from the Python file.\n        base_name (str): The base name of the output files.\n        output_subdir (Path): The subdirectory where the output files will be saved.\n    Returns:\n        None\n    \"\"\"\n    # create graph\n    graph_type = \"entire_code_graph\"\n    G = nx.DiGraph()\n    G.add_nodes_from(file_details[\"file_info\"][graph_type][\"nodes\"])\n    for edge in file_details[\"file_info\"][graph_type][\"edges\"]:\n        source, target = edge[\"source\"], edge[\"target\"]\n        if source in G.nodes and target in G.nodes:\n            G.add_edge(\n                source,\n                target,\n                **{\n                    k: v\n                    for k, v in edge.items()\n                    if k in [\"target_inputs\", \"target_returns\"]\n                },\n            )\n\n    # draw graph\n    plt.figure(figsize=(20, 20))\n    pos = nx.spring_layout(G)\n    nx.draw(\n        G,\n        pos,\n        with_labels=True,\n        font_weight=\"bold\",\n        font_size=8,\n        node_shape=\"s\",\n        node_size=500,\n        width=1,\n        arrowsize=12,\n    )\n    edge_labels = {}\n    for edge in G.edges(data=True):\n        label = []\n        if \"target_inputs\" in edge[2] and edge[2][\"target_inputs\"]:\n            label.append(f\"Inputs: {', '.join(edge[2]['target_inputs'])}\")\n        if \"target_returns\" in edge[2] and edge[2][\"target_returns\"]:\n            label.append(f\"\\nReturns: {', '.join(edge[2]['target_returns'])}\")\n        edge_labels[(edge[0], edge[1])] = \"\\n\".join(label)\n    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)\n\n    # save graph\n    try:\n        output_file = output_subdir / f\"{base_name}.{graph_type}.png\"\n        plt.savefig(output_file)\n        plt.close()\n    except Exception as e:\n        logging.error(f\"Error saving graph for {base_name}: {e}\", exc_info=True)\n\n\ndef save_python_data(\n    file_details: dict, instruct_list: list, relative_path: Path, output_dir: str\n) -> None:\n    \"\"\"\n    Save the details of the Python file as a YAML file, the instruction data as JSON files,\n    and generate and save code graphs.\n    Args:\n        file_details (dict): The details extracted from the Python file.\n        instruct_list (list): The instruction data extracted from the Python file.\n        relative_path (Path): The relative path of the Python file.\n        output_dir (str): The directory where the output files will be saved.\n    Returns:\n        None\n    \"\"\"\n    output_subdir = Path(output_dir) / relative_path.parent\n    output_subdir.mkdir(parents=True, exist_ok=True)\n    base_name = relative_path.name\n    write_file(instruct_list, output_subdir / f\"{base_name}.instruct.json\")\n    write_file(file_details, output_subdir / f\"{base_name}.details.yaml\")\n    output_text = file_details[\"file_info\"][\"code_qa_response\"]\n    with open(output_subdir / f\"{base_name}.code_details.yaml\", \"w\") as f:\n        f.write(output_text)\n\n    try:\n        create_code_graph(file_details, base_name, output_subdir)\n    except Exception as e:\n        logging.error(f\"Error creating graph for {base_name}: {e}\", exc_info=True)\n\n```"
            }
        ],
        "nbytes": 17591,
        "source": "py2dataset/py2dataset.py"
    },
    {
        "conversation": [
            {
                "from": "system",
                "value": "code documentation: I) Description:\nThe given context focuses on a Python file named `setup.py` within the `py2dataset` project directory using Setuptools library for package configuration and distribution management during software development. This script facilitates metadata generation required to distribute Python packages via platforms like PyPI (Python Package Index). It specifies details such as name, version, author, license, dependencies, entry points, and installation requirements.\n\nII) Detailed Requirements, API Signatures & Logic Breakdown:\na. setuptools - A widely used Python library to assist developers in packaging and distributing their Python projects using Distutils extensions for easier installation. It helps create installers (e.g., `.egg`, `bdist_wheel`, etc.), generate documentation, and manage metadata related to the project package structure.\n\nb. `open(\"README.md\", \"r\")` - Opens a file named 'README.md' in read mode to extract its content for long description usage during installation or distribution.\n\nc. `setup()` function - A core function from Setuptools that takes various keyword arguments to define package properties. In this context:\ni. name - Unique identifier of the project ('py2dataset')\nii. version - Version number of the package ('0.4')\niii. author & author_email - Developer's information ('Jeff Meloy', 'jeffmeloy@gmail.com')\niv. description - Brief explanation about the project ('A tool to generate structured datasets from Python source code')\nv. long_description - Detailed explanation read from README file using markdown format ('text/markdown')\nvi. url - Link pointing to GitHub repository for more details ('https://github.com/jeffmeloy/py2dataset')\nvii. py_modules - List of Python modules in the package ('get_code_graph', 'get_params', 'get_python_datasets', 'get_python_file_details', 'py2dataset', 'save_output')\nviii. classifiers - Specifies attributes like programming language ('Python 3'), license type (MIT License), and operating system compatibility (OS Independent)\nix. python_requires - Minimum Python version requirement ('>=3.8')\nx. install_requires - External dependencies needed to run the package ('matplotlib', 'networkx', 'ctransformers', 'PyYaml', 'GitPython')\nxi. entry_points - Defines console scripts accessible via command line ('py2dataset = py2dataset:main')\nxii. packages - Package structure ('py2dataset') with relative path mapping ('\\\\')\n\nIII) Inputs, Variables, Calls & Returns Explanation:\na. `install_requires` - A list containing names of required external libraries needed for package execution ('matplotlib', 'networkx', 'ctransformers', 'PyYaml', 'GitPython'). These dependencies are installed automatically when users install the `py2dataset` package using pip or similar tools.\nb. `entry_points` - A dictionary mapping console scripts to their respective modules and functions ('console_scripts': ['py2dataset = py2dataset:main']). This allows users to execute `py2dataset` as a command-line script pointing to the `main()` function in the `py2dataset` module.\nc. `packages` - A dictionary defining package structure with relative path mapping ('py2dataset': '.\\\\'). It helps Setuptools locate modules correctly during installation and import processes."
            },
            {
                "from": "human",
                "value": "Output the Python code described by the code documentation."
            },
            {
                "from": "gpt",
                "value": "```python\nfrom setuptools import setup\n\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\n\nsetup(\n    name=\"py2dataset\",\n    version=\"0.4\",\n    author=\"Jeff Meloy\",\n    author_email=\"jeffmeloy@gmail.com\",\n    description=\"A tool to generate structured datasets from Python source code\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/jeffmeloy/py2dataset\",\n    py_modules=[\"get_code_graph\", \"get_params\", \"get_python_datasets\", \"get_python_file_details\", \"py2dataset\", \"save_output\"],\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n    ],\n    python_requires=\">=3.8\",\n    install_requires=[\"matplotlib\", \"networkx\", \"ctransformers\", \"PyYaml\", \"GitPython\", ],\n    entry_points={\"console_scripts\": [\"py2dataset = py2dataset:main\"]},\n    packages=[\"py2dataset\"],\n    package_dir={\"py2dataset\": \".\\\\\"},\n)\n\n```"
            }
        ],
        "nbytes": 4326,
        "source": "py2dataset/save_output.py"
    }
]